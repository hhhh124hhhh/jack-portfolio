# 2026-01-31 日志

## 重要决策

### AI 提示词转换为 Skill 项目
**技术约束明确**：转换工具必须使用 Claude 的 skill 制作技能
- 时间：2026-01-31 08:19
- 来源：jack happy (Slack #clawdbot)
- 含义：转换工具本身就是一个 Clawdbot Skill，它使用 Claude 的能力来创建其他 Skills

### 技术架构
1. **转换工具作为 Skill**：不是独立脚本，而是一个完整的 Clawdbot Skill
2. **工作流程**：
   - 使用 twitter-search skill 从 X 抓取 AI 提示词
   - 使用 Claude 评估提示词质量
   - 使用 skill-creator 的方法生成新的 SKILL.md
   - 使用 package_skill.py 打包为 .skill 文件
   - 发布到 ClawdHub

3. **工具依赖**：
   - twitter-search-skill：抓取 X 内容
   - skill-creator：创建新技能的框架和方法
   - ClawdHub CLI：发布技能

## 工作流程规范

### 子代理结果上传规则
**时间**：2026-01-31 08:40
**来源**：jack happy (Slack #clawdbot)
**要求**：每个子代理运行成功后，把结果上传到私有仓库

**执行标准**：
1. 子代理完成任务后，提交所有生成的文件到 git
2. 提交信息要清晰描述变更内容
3. 推送到远程仓库：https://github.com/hhhh124hhhh/Clawdbot-Skills-Converter.git

**适用内容**：
- 文档（分析报告、技术文档、总结）
- Skill 文件或代码
- 数据分析结果
- 工作流程设计文档
- 重要的配置变更

## 下一步
设计并创建 `prompt-to-skill-converter` skill

## 工具使用认知
**时间**: 2026-01-31 10:29
**来源**: jack happy (Slack #clawdbot)
**认知**: **使用 coding-agent 就是使用 claude**
- 当需要编程任务时，应使用 coding-agent skill
- coding-agent 实际上就是调用 Claude 的编程能力
- 这与其他需要用 coding agent 的任务相同

## Skill 审核任务
**时间**: 2026-01-31 09:48
**任务**: 审核已生成的 skills
**状态**: 等待用户确认审核方式
**详情**:
- 发现 54 个 .skill 文件在 `/root/clawd/dist/skills/`
- 用户提到有 40 个 skill 需要用 coding agent 审核
- 脚本已写好，但需要确认具体审核方式
- 现有 `evaluate-skills-quality.js` 只处理特定前缀的文件，需要修改或创建新脚本

## coding-agent 使用规范强化
**时间**: 2026-01-31 12:17
**来源**: jack happy (Slack #clawdbot)
**用户反馈**: "你执行还是用 coding-agent 把 我发现你本身执行文件都能力很弱"
**重要性**: ⚠️ 高优先级
**规则**:
1. **所有文件操作和编程任务必须使用 coding-agent**，不要自己直接执行文件操作
2. coding-agent 使用的是 Claude，编程能力强于我自己直接操作
3. 这是用户的明确要求，必须严格遵守
4. 已更新 TOOLS.md 记录此规则

## 数据源分析和改进计划
**时间**: 2026-01-31 14:10
**任务**: 分析当前数据源问题并创建改进方案
**原因**: jack happy 要求"继续改进数据源吧 把教训记录入记忆"
**子代理**: data-source-improvement (运行中)

### 当前数据源问题分析

**问题 1：数据质量严重不足**
- 表现：大量 HTML 片段、网站导航元素被当作"提示词"
- 根本原因：提取逻辑过于宽松，缺乏语义验证
- 影响：大部分收集的数据无法使用

**问题 2：评分系统失效**
- 表现：垃圾内容得 40 分，无意义片段得 25 分
- 根本原因：基于关键词而非语义，规则无法理解上下文
- 影响：无法准确识别高质量提示词

**问题 3：数据源单一且质量参差**
- 表现：主要依赖 SearXNG 网络搜索，来源质量不可控
- 根本原因：缺乏高质量数据源，搜索关键词不够精准
- 影响：收集了很多低质量、碎片化的内容

**问题 4：Twitter API 限制**
- 表现：免费计划有严格速率限制（429 错误）
- 限制：每月 500,000 条推文，每 15 分钟 300 条请求
- 解决方案：考虑升级付费计划、添加代理池、优化查询策略

### 关键教训

1. **数据清洗比数据收集更重要**
   - 收集阶段就要有严格过滤规则
   - 收集后必须人工抽样验证
   - 宁可少收集，也要保证质量

2. **LLM 比规则更适合内容评估**
   - 使用 Claude/GPT 等 LLM 进行语义评估
   - 基于规则的评分系统无法理解上下文
   - 保留 AI 的评估理由，便于调试

3. **需要分层的数据源策略**
   - Tier 1（高质量）：专业提示词网站（PromptBase、LearnPrompting）
   - Tier 2（中等质量）：技术博客、GitHub 仓库
   - Tier 3（补充）：社交媒体、论坛、Reddit

4. **自动化的边界**
   - 定期人工抽查自动化结果
   - 建立"黄金数据集"作为质量基准
   - 发现问题后快速调整自动化流程

### 输出文档

- **教训记录**: `/root/clawd/data/prompts/data-source-lessons.md`
- **改进方案**: 子代理正在创建 `/root/clawd/data-prompts-improvement-plan.md`

### 改进方案

**短期改进（1-2 周）**：
1. 改进数据提取逻辑，添加严格过滤规则
2. 使用 LLM 重新评估已有数据
3. 优化搜索关键词，提高精准度

**中期改进（2-4 周）**：
1. 添加高质量数据源（PromptBase、GitHub awesome-prompts）
2. 建立质量监控，每周人工抽查 50 条数据
3. 改进评分系统，使用 LLM 进行语义评估

**长期改进（1-3 个月）**：
1. 建立自动化质量保证系统
2. 数据源多样化
3. 建立提示词分类体系

---

## 评估和收集改进方案实施

**时间**: 2026-01-31 14:55
**来源**: jack happy (Slack #clawdbot)
**要求**:
1. LLM 评估使用系统级 agent 评估，不用 Claude API key
2. Twitter API 配置不了，使用 searXNG 增强
3. 看看提取质量怎么提高

### 实施方案

#### 1. 系统级 Agent 评估脚本
**文件**: `/root/clawd/scripts/evaluate-prompts-agent.py`

**特点**:
- 使用 `sessions_spawn` 调用系统内置 LLM（无需外部 API key）
- 评估维度：质量（35%）、实用性（30%）、完整性（20%）、创新性（15%）
- 批量处理支持
- 降级评估机制（规则评分作为后备）

**使用方法**:
```bash
python3 /root/clawd/scripts/evaluate-prompts-agent.py <input-file> [output-file]
```

#### 2. SearXNG 收集脚本
**文件**: `/root/clawd/scripts/collect-prompts-via-searxng.py`

**特点**:
- 使用本地 SearXNG 实例（http://149.13.91.232:8080）
- 多源搜索：GitHub、专业网站、技术博客
- 高质量域名白名单和黑名单
- 改进的提取逻辑（更严格的过滤）
- 自动质量评分

**搜索来源**:
- 专业网站：PromptBase, LearnPrompting
- GitHub 仓库：awesome-chatgpt-prompts 等
- 技术博客：Medium, Dev.to, Hashnode
- 官方文档：Midjourney, OpenAI, Stability AI

**质量过滤规则**:
- 长度：40-800 字符
- 字母数字比例：≥70%
- 必须包含动作动词（generate, create, write 等）
- 排除截断标记
- 排除低质量域名

**使用方法**:
```bash
python3 /root/clawd/scripts/collect-prompts-via-searxng.py
```

#### 3. 提取质量改进

**多层过滤**:
```
长度过滤 → 内容质量过滤 → 动作动词过滤 → 截断标记过滤
```

**质量评分增强**:
- 长度评分（30 分）
- 质量关键词（20 分）
- 动作动词（15 分）
- 结构评分（25 分）
- 描述性词汇（10 分）

#### 4. 技术对比

| 特性 | 原方案 | 新方案 |
|------|--------|--------|
| LLM 评估 | Claude API (需要 key) | 系统级 Agent (无需 key) |
| 搜索来源 | Twitter API (配置困难) | SearXNG (多源搜索) |
| 提取质量 | 宽松，大量垃圾数据 | 严格过滤，高质量 |
| 数据源 | 单一 (Twitter) | 多样化 (GitHub, 博客, 官方文档) |
| API 依赖 | Anthropic API | 无外部 API 依赖 |
| 成本 | 需要付费 API | 免费 |

#### 5. 预期效果

**数据质量提升**:
- 垃圾数据比例：从 ~60% 降至 <10%
- 高质量提示词：从 ~15% 提升至 ~40%
- 平均质量分数：从 ~50 提升至 ~65

**效率提升**:
- 无需 API key：零额外成本
- 多源收集：数据多样性提升 3x
- 自动化程度：全流程自动化

#### 6. 文档

- **完整方案**: `/root/clawd/data/prompts/evaluation-and-collection-improvement.md`

#### 7. 下一步

1. 测试脚本功能
2. 运行收集和评估流程
3. 分析结果质量
4. 创建 wrapper 脚本，一键执行完整流程
