---
name: prompt-to-skill-converter
description: "Automated end-to-end workflow to discover AI prompts from multiple sources (Twitter/X, Reddit, GitHub, Hacker News, SearXNG, Firecrawl), evaluate their commercial potential, and convert high-quality prompts into Clawdbot Skills using Claude's skill creation methodology. Use when building a profitable skills marketplace by mining social media, code repositories, and web content for prompt patterns and turning them into distributable skills. The workflow includes: (1) collecting prompts from diverse sources (Twitter API, Reddit API, GitHub search, Hacker News, SearXNG metasearch, Firecrawl web scraping), (2) analyzing prompt quality and commercial viability, (3) transforming prompts into structured SKILL.md files, (4) packaging skills for ClawdHub distribution, and (5) publishing to the marketplace with registry configuration."
---

# Prompt To Skill Converter

## Overview

**è½¬æ¢å‘å¸ƒå±‚** - è‡ªåŠ¨åŒ–å·¥ä½œæµï¼Œå°†é«˜è´¨é‡æç¤ºè¯è½¬æ¢ä¸º Clawdbot Skills å¹¶å‘å¸ƒåˆ° ClawdHubã€‚

**æ¶æ„å®šä½**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ x-prompt-hunter     â”‚ â† æ•°æ®å‘ç°å±‚ï¼ˆå»é‡+è¯„ä¼°ï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ é«˜è´¨é‡æç¤ºè¯
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prompt-to-skill-    â”‚ â† è½¬æ¢å‘å¸ƒå±‚ï¼ˆSKILL.md + ClawdHubï¼‰
â”‚ converter          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ³¨æ„**ï¼šæ­¤æŠ€èƒ½ä¾èµ– **x-prompt-hunter** æ•°æ®å‘ç°å±‚ã€‚å»ºè®®å…ˆä½¿ç”¨ x-prompt-hunter è¿›è¡Œæç¤ºè¯å»é‡å’Œè¯„ä¼°ï¼Œç„¶åä½¿ç”¨æœ¬æŠ€èƒ½è¿›è¡Œè½¬æ¢å’Œå‘å¸ƒã€‚

## Core Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Load High   â”‚â”€â”€â”€â–¶â”‚  2. Convert     â”‚â”€â”€â”€â–¶â”‚  3. Package     â”‚
â”‚  Quality Promptsâ”‚    â”‚  to Skills      â”‚    â”‚  & Test        â”‚
â”‚  (from x-       â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚   prompt-hunter)â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Publish to  â”‚â—€â”€â”€â”€â”‚  4. Validate     â”‚â—€â”€â”€â”€â”‚  Quality Check  â”‚
â”‚  ClawdHub       â”‚    â”‚  & Document     â”‚    â”‚                 â”‚
â”‚  (with --registry)â”‚   â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Sources

### Recommended Workflow (Two-Stage Architecture)

**Stage 1: Data Discovery & Quality Control (x-prompt-hunter)**
```bash
# ä½¿ç”¨ x-prompt-hunter è¿›è¡Œå»é‡å’Œè¯„ä¼°
cd /root/clawd/skills/x-prompt-hunter

# å®Œæ•´æµç¨‹ï¼šæŠ“å– â†’ å»é‡ â†’ è¯„ä¼° â†’ ç”ŸæˆæŠ¥å‘Š
python3 main.py pipeline --query "AI prompts" --limit 100 --evaluate-limit 30

# é«˜è´¨é‡æç¤ºè¯è¾“å‡ºåˆ°: data/prompts_deduplicated.json
# è¯„ä¼°ç»“æœè¾“å‡ºåˆ°: data/evaluation_results.json
```

**Stage 2: Conversion & Publishing (prompt-to-skill-converter)**
```bash
# åŠ è½½é«˜è´¨é‡æç¤ºè¯å¹¶è½¬æ¢ä¸º Skills
cd /root/clawd/skills/prompt-to-skill-converter

# è½¬æ¢ä¸º Skills
python3 scripts/convert-prompts-to-skills.py \
  --input /root/clawd/skills/x-prompt-hunter/data/evaluation_results.json \
  --quality-threshold 80

# æ‰“åŒ…å¹¶å‘å¸ƒ
python3 /usr/lib/node_modules/clawdbot/skills/skill-creator/scripts/package_skill.py /root/clawd/skills/<skill-name>
clawdhub publish <skill-name>.skill --registry https://www.clawhub.ai/api
```

### Legacy Data Sources (Direct Collection)

**æ³¨æ„**ï¼šä»¥ä¸‹æ”¶é›†æ–¹æ³•ä¸ºé—ç•™åŠŸèƒ½ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨ **x-prompt-hunter** çš„æ•°æ®å‘ç°å±‚ã€‚

**Social Media:**
- **Twitter/X**: Real-time prompt discovery via API (bird CLI)
- **Reddit**: Community-driven prompt collections and discussions

**Developer Platforms:**
- **GitHub**: Prompt libraries in code repositories, README files, issues

**News & Discussion:**
- **Hacker News**: Tech-focused prompt discussions and resources

**Web Search & Scraping:**
- **SearXNG**: Privacy-respecting metasearch across multiple engines
- **Firecrawl**: AI-powered web scraping for JavaScript-heavy sites

### One-Command Full Workflow (Legacy)

**æ³¨æ„**ï¼šæ­¤ä¸ºé—ç•™å·¥ä½œæµï¼Œå»ºè®®ä½¿ç”¨ä¸Šè¿°ä¸¤é˜¶æ®µæ¶æ„ã€‚

```bash
# Run complete workflow (collect â†’ evaluate â†’ convert â†’ package â†’ publish)
bash scripts/full-prompt-workflow.sh

# With options:
bash scripts/full-prompt-workflow.sh --quality-threshold 60 --test-mode
```

This script integrates all components automatically and provides end-to-end automation.

## Prerequisites

### API Keys & Tokens
1. **Twitter API Key**: Configure in `~/.bashrc` (see twitter-search skill) - Used for Twitter/X prompt collection
2. **Reddit API Credentials**: Required for Reddit data collection (create app at reddit.com/prefs/apps)
3. **GitHub Personal Access Token**: For GitHub API access (optional, increases rate limits)
4. **ClawdHub Token**: Set up for publishing (already configured: `clh_Ki_M1Xiws5Qzi83gqdZhYG3jXSuZOnEfQOxhaRsjHcw`)
   - **Important**: Registry URL must be `https://www.clawhub.ai/api`

### Software Requirements
5. **Python 3.8+**: Required for automation scripts
6. **SearXNG Instance**: Local or remote metasearch instance (optional, see searxng skill)
7. **Firecrawl API Key**: For advanced web scraping (optional, see firecrawl skill)
8. **Skill Creation Scripts**: Available from skill-creator (`init_skill.py`, `package_skill.py`)

### CLI Tools
- **bird CLI**: `npm install -g @sugarcube/cli` (for Twitter API)
- **ClawdHub CLI**: Included with Clawdbot (for publishing)

## Step 1: Collect Prompts from Multiple Sources

Collect AI prompts from diverse sources for comprehensive coverage and quality.

### Source 1: Twitter/X (Social Media)

Use the twitter-search skill to discover high-quality prompts with engagement metrics.

### Search Queries

Use these patterns to find prompts:

```bash
# AI prompts in general
./scripts/run_search_improved.sh --smart-query prompts --lang en --min-likes 20 --min-retweets 10 --max-results 200

# Specific prompt types
./scripts/run_search_improved.sh "\"prompt engineering\" OR \"ChatGPT prompts\" OR \"Claude prompts\"" \
  --lang en --min-likes 30 --min-retweets 15 --max-results 100

# Prompt libraries/resources
./scripts/run_search_improved.sh "prompt library OR \"prompt collection\" OR \"prompt template\"" \
  --lang en --min-likes 15 --max-results 150
```

### Data Collection Strategy

**What to look for:**
- Prompt templates with clear structure
- Actionable prompts with specific outputs
- Domain-specific prompts (coding, writing, design, etc.)
- High engagement (likes/retweets) indicates quality/demand
- Reposted or "saved" prompts suggest value

**Red flags:**
- Generic/vague prompts
- Prompts requiring paid tools
- NSFW or unethical content
- Overly long prompts (>500 words)
- Prompts requiring manual setup

**Output:** Save results to JSON file for analysis
```bash
./scripts/run_search_improved.sh --smart-query prompts --format json > /tmp/prompts.json
```

### ğŸ”¥ æ”¹è¿›æ–¹æ¡ˆï¼šä½¿ç”¨ collect-prompts-twitter.sh

æ¨èä½¿ç”¨æ”¹è¿›çš„ Twitter æ”¶é›†è„šæœ¬ï¼Œå®ƒæä¾›æ›´å¥½çš„æ•°æ®è´¨é‡å’Œè‡ªåŠ¨åŒ–ç¨‹åº¦ï¼š

```bash
# è¿è¡Œæ”¹è¿›çš„ Twitter æ”¶é›†è„šæœ¬
bash scripts/collect-prompts-twitter.sh

# æ•°æ®è‡ªåŠ¨ä¿å­˜åˆ°ï¼š/root/clawd/data/prompts/twitter-prompts.jsonl

# æŸ¥çœ‹æ”¶é›†çš„æ•°æ®
cat /root/clawd/data/prompts/twitter-prompts.jsonl | jq '.'
```

**ä¼˜åŠ¿ï¼š**
- âœ… è‡ªåŠ¨æå–æç¤ºè¯ï¼ˆæ— éœ€æ‰‹åŠ¨ç­›é€‰ï¼‰
- âœ… åŒ…å«å®Œæ•´çš„äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€è½¬å‘ã€è¯„è®ºï¼‰
- âœ… ä¸­è‹±æ–‡åŒè¯­æœç´¢è¦†ç›–
- âœ… æ™ºèƒ½æ•°æ®å¤„ç†å’Œå»é‡
- âœ… JSONL æ ¼å¼ä¾¿äºåç»­å¤„ç†

**æ•°æ®ç¤ºä¾‹ï¼š**
```json
{
  "timestamp": "2026-02-01T12:00:00",
  "source": "twitter",
  "search_query": "AI prompt engineering",
  "tweet_id": "1234567890",
  "tweet_url": "https://twitter.com/user/status/1234567890",
  "author_name": "AI Researcher",
  "author_handle": "airesearcher",
  "text": "Here's a great prompt for coding assistants...",
  "prompts_found": 2,
  "prompts": ["prompt 1", "prompt 2"],
  "likes": 150,
  "retweets": 45,
  "replies": 23
}
```

### Source 2: Reddit (Community Content)

Collect prompts from Reddit communities focused on AI, prompt engineering, and specific domains.

```bash
# Run Reddit collection script
bash scripts/collect-prompts-reddit.sh

# Data saved to: /root/clawd/data/prompts/reddit-prompts.jsonl
```

**Target Subreddits:**
- r/ChatGPT, r/PromptEngineering, r/artificial
- Domain-specific: r/datasets, r/MachineLearning, r/LocalLLaMA

**Advantages:**
- Community-vetted quality (upvotes = engagement)
- Detailed discussions and refinements
- Diverse perspectives and use cases

### Source 3: GitHub (Developer Resources)

Search for prompt libraries and prompt-related code repositories.

```bash
# Run GitHub collection script
bash scripts/collect-prompts-github.sh

# Data saved to: /root/clawd/data/prompts/github-prompts.jsonl
```

**Search Patterns:**
- Repository names: "prompt-library", "awesome-prompts", "prompt-templates"
- File patterns: `README.md`, `prompts.md`, `PROMPTS.md`
- Code comments and documentation

**Advantages:**
- High-quality, developer-focused prompts
- Well-documented and structured
- Often includes usage examples

### Source 4: Hacker News (Tech Discussions)

Extract prompts from HN discussions and comments.

```bash
# Run Hacker News collection script
bash scripts/collect-prompts-hn.sh

# Data saved to: /root/clawd/data/prompts/hn-prompts.jsonl
```

**Search Criteria:**
- Stories with "prompt" or "prompt engineering"
- Comments mentioning prompt techniques
- Show HN discussions about AI tools

**Advantages:**
- Tech-savvy audience
- Informed discussions
- Trend detection

### Source 5: SearXNG (Metasearch)

Use privacy-respecting metasearch to find prompt-related content across multiple search engines.

```bash
# Run SearXNG collection script
bash scripts/collect-prompts-searxng.sh

# Data saved to: /root/clawd/data/prompts/searxng-prompts.jsonl
```

**Configuration:**
```bash
# Set SearXNG instance URL (in .env.d/)
export SEARXNG_URL=http://localhost:8080

# Or use a public instance
export SEARXNG_URL=https://searx.be
```

**Advantages:**
- No API rate limits
- Multiple search engines in one query
- Privacy-focused
- Customizable search filters

### Source 6: Firecrawl (Advanced Web Scraping)

Use AI-powered web scraping for JavaScript-heavy sites and complex web pages.

```bash
# Run Firecrawl collection script
bash scripts/collect-prompts-firecrawl.sh

# Data saved to: /root/clawd/data/prompts/firecrawl-prompts.jsonl
```

**Configuration:**
```bash
# Set Firecrawl API key (in .env.d/)
export FIRECRAWL_API_KEY=your_api_key_here
```

**Advantages:**
- Handles JavaScript-rendered content
- Bypasses anti-bot measures
- Extracts clean, LLM-ready data
- Supports crawling entire sites

**Use Cases:**
- Scrape prompt library websites
- Extract prompts from documentation sites
- Collect from specialized AI platforms

### Unified Collection Workflow

For comprehensive collection, use the integrated multi-source collector:

```bash
# Collect from all configured sources
bash scripts/collect-prompts-all.sh

# Or run the full workflow (includes collection)
bash scripts/full-prompt-workflow.sh --collect-only
```

**Output:** All sources save to unified format in `/root/clawd/data/prompts/`

## Step 2: Evaluate & Filter Prompts

Load the captured prompts and evaluate them against commercial viability criteria.

### Evaluation Criteria

Use the evaluation framework in `references/evaluation-criteria.md`:

1. **Clarity & Completeness** (1-10):
   - Clear objective?
   - Complete instructions?
   - Easy to follow?

2. **Uniqueness** (1-10):
   - Novel approach?
   - Different from existing skills?
   - Solves a real problem?

3. **Market Potential** (1-10):
   - High engagement?
   - Reusable workflow?
   - Clear audience?

4. **Technical Feasibility** (1-10):
   - Can be automated?
   - Within Clawdbot capabilities?
   - Reasonable complexity?

**Scoring Threshold:** Only convert prompts with total score â‰¥ 30/40

### Evaluation Process

```python
# Load and evaluate prompts
python3 scripts/evaluate_prompts.py /tmp/prompts.json --threshold 30
```

This script:
- Loads the JSON data
- Applies evaluation criteria
- Scores each prompt
- Outputs ranked list with scores
- Filters by threshold

**Output:** `/tmp/evaluated_prompts.json` with scores and rankings

## Step 3: Convert to Skill Structure

For each high-scoring prompt, use Claude to transform it into a proper Clawdbot Skill structure.

### Manual Conversion Workflow (Interactive)

For the first few conversions, work interactively to establish patterns:

```bash
# Initialize a new skill
python3 /usr/lib/node_modules/clawdbot/skills/skill-creator/scripts/init_skill.py <skill-name> --path /root/clawd/skills

# Claude will:
# 1. Analyze the original prompt
# 2. Extract the core workflow
# 3. Design the skill structure (task-based, workflow-based, etc.)
# 4. Write SKILL.md with proper frontmatter and instructions
# 5. Create necessary scripts/ or references/ as needed
```

### Conversion Guidelines

When transforming a prompt into a skill:

**1. Identify the Core Pattern**
- What is the prompt doing?
- What tools/resources are used?
- What are the inputs and outputs?

**2. Choose Skill Structure**
- **Task-Based**: If prompt provides multiple operations
- **Workflow-Based**: If prompt is a sequential process
- **Reference/Guidelines**: If prompt is about standards/templates

**3. Write Frontmatter**
- `name`: Descriptive, kebab-case (e.g., `email-drafter`)
- `description`: Include what it does + when to use it + trigger scenarios

**4. Draft SKILL.md Body**
- Overview: 1-2 sentences
- Workflow/Tasks: Step-by-step instructions
- Examples: Concrete use cases
- Resources: Link to scripts/references as needed

**5. Create Supporting Resources**
- `scripts/`: Automatable code
- `references/`: Documentation to load on-demand
- `assets/`: Templates or output files

### Conversion Template

Use the template in `references/conversion-template.md` as a starting point:

```markdown
---
name: [skill-name]
description: [What it does + when to use it + trigger scenarios]
---

# [Skill Title]

## Overview
[Brief explanation]

## [Structure: Workflow / Tasks / Guidelines]
[Step-by-step instructions or task categories]

## Quick Start
[How to use immediately]

## Resources (as needed)
### scripts/
[Scripts and their purpose]

### references/
[Reference documentation]
```

## Step 4: Package & Test

Once SKILL.md and resources are complete, package the skill for distribution.

### Packaging

```bash
# Validate and package
python3 /usr/lib/node_modules/clawdbot/skills/skill-creator/scripts/package_skill.py /root/clawd/skills/<skill-name>
```

This:
- Validates the skill structure
- Checks frontmatter format
- Creates `.skill` file (zip)
- Reports any errors

### Testing

Before publishing, test the skill:

1. **Load the skill**: Open a new session and use it
2. **Test workflows**: Follow the steps in SKILL.md
3. **Verify outputs**: Ensure expected results
4. **Check edge cases**: Try unusual inputs
5. **Document issues**: Fix before publishing

### Troubleshooting

**Packaging fails?**
- Check YAML frontmatter format
- Ensure `name` and `description` are present
- Verify SKILL.md is valid markdown

**Testing reveals bugs?**
- Update SKILL.md instructions
- Fix scripts if needed
- Re-package and re-test

## Step 5: Publish to ClawdHub

Publish packaged skills to the marketplace with proper registry configuration.

### Publishing Workflow

```bash
# Login to ClawdHub (first time only)
clawdhub login
# Enter token: clh_Ki_M1Xiws5Qzi83gqdZhYG3jXSuZOnEfQOxhaRsjHcw

# Publish skill with explicit registry URL (recommended)
clawdhub publish <skill-name>.skill --registry https://www.clawhub.ai/api
```

### Important: Registry Configuration

**Critical**: Always specify the registry URL when publishing:

```bash
# âœ… Correct: Explicit registry
clawdhub publish my-skill.skill --registry https://www.clawhub.ai/api

# âŒ Wrong: May publish to wrong registry
clawdhub publish my-skill.skill
```

**Why This Matters:**
- ClawdHub has changed registry URLs over time
- Using explicit `--registry` ensures publication to the correct destination
- Old URLs like `clawdhub.com` or `clawhub.ai` may redirect incorrectly

### Publishing Script (Automation)

The automated publishing script includes proper registry configuration:

```bash
# Use the automated publishing script
bash scripts/batch-upload-skills-v3.sh

# This script:
# - Scans for packaged skills
# - Validates each .skill file
# - Publishes with --registry https://www.clawhub.ai/api
# - Generates a detailed report
```

**Script Features:**
- âœ… Batch publishing of multiple skills
- âœ… Automatic registry URL injection
- âœ… Error handling and retry logic
- âœ… Progress tracking and logging
- âœ… Report generation

### Skill Metadata Preparation

Before publishing, prepare skill metadata:

1. **Category**: Choose appropriate category
   - `productivity`, `development`, `design`, `business`, etc.

2. **Tags**: Add relevant tags
   - `ai`, `automation`, `prompts`, `workflow`, etc.

3. **Price**: Set pricing (free/paid)
   - Start with free for testing
   - Adjust based on demand

4. **Description**: Write compelling marketplace description
   - Focus on value/benefits
   - Include use case examples
   - Mention features

### Post-Publishing

- Monitor download stats
- Collect user feedback
- Update based on suggestions
- Version control changes

## Automation Scripts

### scripts/collect-prompts-twitter.sh ğŸ”¥

æ”¹è¿›çš„ Twitter/X æç¤ºè¯æ”¶é›†è„šæœ¬ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰ï¼š

```bash
bash scripts/collect-prompts-twitter.sh
```

**ç‰¹æ€§ï¼š**
- ä½¿ç”¨ Twitter API è¿›è¡Œæ•°æ®æ”¶é›†ï¼ˆé€šè¿‡ bird CLIï¼‰
- ä¸­è‹±æ–‡åŒè¯­æœç´¢ï¼ˆ12 ä¸ªæŸ¥è¯¢è¯ï¼‰
- è‡ªåŠ¨æå–æç¤ºè¯ï¼ˆä»£ç å—ã€å¼•ç”¨æ–‡æœ¬ã€æŒ‡ä»¤ï¼‰
- è®°å½•äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€è½¬å‘ã€è¯„è®ºï¼‰
- æ™ºèƒ½æ•°æ®å¤„ç†å’Œå»é‡
- ä¿å­˜ä¸º JSONL æ ¼å¼ä¾¿äºåç»­å¤„ç†

**æ•°æ®è¾“å‡ºï¼š**
- æ–‡ä»¶ï¼š`/root/clawd/data/prompts/twitter-prompts.jsonl`
- æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡
- åŒ…å«å­—æ®µï¼štimestamp, source, tweet_id, tweet_url, author_name, author_handle, text, prompts_found, prompts, likes, retweets, replies

**æœç´¢æŸ¥è¯¢ï¼š**
- è‹±æ–‡ï¼šAI prompt engineering, ChatGPT prompts, Claude prompts, midjourney prompts, AI art prompts, prompt engineering tips, best AI prompts, prompt templates
- ä¸­æ–‡ï¼šAI æç¤ºè¯, ChatGPT æŒ‡ä»¤, AI ç»˜ç”»æç¤ºè¯, æç¤ºè¯å·¥ç¨‹

**ä¾èµ–ï¼š**
- bird CLIï¼š`npm install -g @sugarcube/cli`
- Python 3
- TWITTER_API_KEY ç¯å¢ƒå˜é‡ï¼ˆå·²é…ç½®ï¼‰

### scripts/collect_prompts.py

Automates prompt discovery from X:

```bash
python3 scripts/collect_prompts.py --query "prompts" --max-results 200 --output /tmp/prompts.json
```

**Features:**
- Uses twitter-search skill internally
- Applies engagement filters automatically
- Saves structured JSON output
- Supports scheduled runs (cron)

### scripts/collect_prompts_enhanced.py ğŸ”¥

å¢å¼ºç‰ˆ AI æç¤ºè¯æ”¶é›†ç³»ç»Ÿï¼ˆæœ€æ–°æ¨èç‰ˆæœ¬ï¼‰ï¼š

```bash
# åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
python3 scripts/collect_prompts_enhanced.py

# æŒ‡å®šè¾“å‡ºç›®å½•
python3 scripts/collect_prompts_enhanced.py --output-dir /custom/path

# å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆ2 ä¸ªæŸ¥è¯¢ï¼Œæ¯ä¸ªæœ€å¤š 3 ä¸ªç»“æœï¼‰
python3 scripts/collect_prompts_enhanced.py --quick-test

# æŸ¥çœ‹å¸®åŠ©
python3 scripts/collect_prompts_enhanced.py --help
```

**Phase 1 æ ¸å¿ƒç‰¹æ€§ï¼š**
- âœ… **æ‰©å±•çš„æœç´¢å…³é”®è¯åº“**ï¼š50+ æŸ¥è¯¢ç»„åˆ
- âœ… **æ™ºèƒ½å…³é”®è¯ç»„åˆç­–ç•¥**ï¼šè‡ªåŠ¨ç”Ÿæˆæœ‰æ•ˆæŸ¥è¯¢
- âœ… **é«˜çº§æœç´¢ç»“æœè¿‡æ»¤**ï¼šåŸºäºåŸŸåã€URL æ¨¡å¼
- âœ… **å¢å¼ºçš„æç¤ºè¯æå–ç®—æ³•**ï¼šæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
- âœ… **ä¸­è‹±æ–‡åŒè¯­æœç´¢**ï¼šè¦†ç›–æ›´å¹¿çš„å†…å®¹æº
- âœ… **è‡ªåŠ¨åˆ†ç±»å’Œè´¨é‡è¯„åˆ†**ï¼š0-100 åˆ†è´¨é‡è¯„ä¼°
- âœ… **å®Œæ•´çš„é”™è¯¯å¤„ç†**ï¼šæ—¥å¿—è®°å½•å’Œä¼˜é›…é€€å‡º
- âœ… **å¹¶å‘å¤„ç†æ”¯æŒ**ï¼šæœ€å¤š 3 ä¸ªå¹¶å‘è¯·æ±‚
- âœ… **JSONL æ ¼å¼è¾“å‡º**ï¼šä¾¿äºåç»­å¤„ç†

**æ•°æ®è¾“å‡ºï¼š**
- æ–‡ä»¶ï¼š`/root/clawd/data/prompts/collected/prompts-enhanced-{timestamp}.jsonl`
- æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡
- åŒ…å«å­—æ®µï¼š
  - `timestamp`: æ”¶é›†æ—¶é—´
  - `query`: æœç´¢æŸ¥è¯¢
  - `url`: æ¥æº URL
  - `domain`: åŸŸå
  - `content`: æå–çš„å†…å®¹
  - `prompts`: æå–çš„æç¤ºè¯åˆ—è¡¨
  - `prompt_count`: æç¤ºè¯æ•°é‡
  - `type`: æç¤ºè¯ç±»å‹ï¼ˆimage-generation, text-generation, video-generation, generalï¼‰
  - `quality_score`: è´¨é‡åˆ†æ•°ï¼ˆ0-100ï¼‰
  - `is_truncated`: æ˜¯å¦è¢«æˆªæ–­

**æœç´¢å…³é”®è¯åˆ†ç±»ï¼š**
- åŸºç¡€å…³é”®è¯ç»„åˆï¼ˆprompt + AI + type + actionï¼‰
- ä¸“ä¸šæç¤ºè¯ç½‘ç«™ï¼ˆPromptBase, LearnPrompting ç­‰ï¼‰
- å¹³å°ç‰¹å®šæç¤ºè¯ï¼ˆMidjourney, DALL-E, Stable Diffusionï¼‰
- ä»»åŠ¡ç‰¹å®šæŸ¥è¯¢ï¼ˆä»£ç ã€å†™ä½œã€è®¾è®¡ç­‰ï¼‰
- è´¨é‡å¯¼å‘æŸ¥è¯¢ï¼ˆbest, top, high-qualityï¼‰

**ä¾èµ–ï¼š**
- Python 3.8+
- `requests` åº“
- SearXNG å®ä¾‹ï¼ˆç¯å¢ƒå˜é‡ `SEARXNG_URL`ï¼‰

**é…ç½®ï¼š**
- `SEARXNG_URL`: SearXNG æœåŠ¡åœ°å€ï¼ˆé»˜è®¤ï¼šhttp://localhost:8080ï¼‰
- `MAX_RESULTS_PER_QUERY`: æ¯ä¸ªæŸ¥è¯¢çš„æœ€å¤§ç»“æœæ•°ï¼ˆé»˜è®¤ï¼š10ï¼‰
- `MAX_WORKERS`: å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
- `REQUEST_DELAY`: è¯·æ±‚å»¶è¿Ÿï¼ˆé»˜è®¤ï¼š1.5 ç§’ï¼‰

**æ”¹è¿›ç‚¹ï¼ˆç›¸æ¯”æ—§è„šæœ¬ï¼‰ï¼š**
1. æ›´å‡†ç¡®çš„æç¤ºè¯æå–ï¼ˆå‡å°‘å¯¼èˆªæ ã€é¡µè„šå¹²æ‰°ï¼‰
2. æ›´æ™ºèƒ½çš„è´¨é‡è¯„åˆ†ç®—æ³•
3. æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
4. æ”¯æŒå¿«é€Ÿæµ‹è¯•æ¨¡å¼
5. è‡ªåŠ¨åˆ†ç±»æç¤ºè¯ç±»å‹
6. æ£€æµ‹æç¤ºè¯æˆªæ–­

**ä½¿ç”¨å»ºè®®ï¼š**
- é¦–æ¬¡ä½¿ç”¨å»ºè®®å…ˆç”¨ `--quick-test` éªŒè¯é…ç½®
- æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´æŸ¥è¯¢è¯å’Œè¿‡æ»¤è§„åˆ™
- å°†æ”¶é›†çš„æç¤ºè¯ç”¨äºåç»­çš„è¯„ä¼°å’Œè½¬æ¢æµç¨‹

### scripts/evaluate_prompts.py

Scores and ranks prompts:

```bash
python3 scripts/evaluate_prompts.py /tmp/prompts.json --threshold 30 --output /tmp/ranked.json
```

**Features:**
- Loads JSON data from collection
- Applies scoring criteria
- Filters by threshold
- Outputs ranked list

### scripts/convert-prompts-to-skills.py ğŸ”¥

å°†æ”¶é›†çš„æç¤ºè¯æ‰¹é‡è½¬æ¢ä¸º Clawdbot Skillsï¼š

```bash
# åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨é»˜è®¤è¾“å…¥æ–‡ä»¶ï¼‰
python3 scripts/convert-prompts-to-skills.py

# æŒ‡å®šè¾“å…¥æ–‡ä»¶
python3 scripts/convert-prompts-to-skills.py --input /path/to/prompts.jsonl

# æŒ‡å®šè´¨é‡é˜ˆå€¼ï¼ˆåªè½¬æ¢é«˜è´¨é‡æç¤ºè¯ï¼‰
python3 scripts/convert-prompts-to-skills.py --quality-threshold 60

# æŒ‡å®šè¾“å‡ºç›®å½•
python3 scripts/convert-prompts-to-skills.py --output-dir /root/clawd/skills

# æŸ¥çœ‹å¸®åŠ©
python3 scripts/convert-prompts-to-skills.py --help
```

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- âœ… **æ‰¹é‡è½¬æ¢**ï¼šå¤„ç† JSONL æ ¼å¼çš„æç¤ºè¯æ•°æ®
- âœ… **æ™ºèƒ½åˆ†ç±»**ï¼šæ ¹æ®æç¤ºè¯ç±»å‹è‡ªåŠ¨åˆ†ç±»
- âœ… **è´¨é‡è¿‡æ»¤**ï¼šåªè½¬æ¢é«˜è´¨é‡æç¤ºè¯
- âœ… **è‡ªåŠ¨å‘½å**ï¼šç”Ÿæˆç¬¦åˆè§„èŒƒçš„ skill åç§°
- âœ… **SKILL.md ç”Ÿæˆ**ï¼šè‡ªåŠ¨åˆ›å»ºç»“æ„åŒ–çš„æŠ€èƒ½æ–‡æ¡£
- âœ… **è¿›åº¦è·Ÿè¸ª**ï¼šæ˜¾ç¤ºè½¬æ¢è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯
- âœ… **é”™è¯¯å¤„ç†**ï¼šè·³è¿‡æ— æ•ˆæç¤ºè¯ï¼Œè®°å½•é”™è¯¯æ—¥å¿—

**è½¬æ¢æµç¨‹ï¼š**
1. è¯»å–è¾“å…¥æ–‡ä»¶ï¼ˆJSONL æ ¼å¼ï¼‰
2. è§£ææ¯ä¸ªæç¤ºè¯å¯¹è±¡
3. æ ¹æ®è´¨é‡åˆ†æ•°è¿‡æ»¤ï¼ˆé»˜è®¤é˜ˆå€¼ï¼š50ï¼‰
4. ç”Ÿæˆå”¯ä¸€çš„ skill åç§°ï¼ˆkebab-caseï¼‰
5. åˆ›å»º skill ç›®å½•ç»“æ„
6. ç”Ÿæˆ SKILL.md æ–‡ä»¶ï¼ˆåŒ…å« frontmatter å’Œå†…å®¹ï¼‰
7. è®°å½•è½¬æ¢ç»“æœåˆ°æ—¥å¿—

**è¾“å‡ºç»“æ„ï¼š**
```
/root/clawd/skills/
â”œâ”€â”€ example-prompt-skill/
â”‚   â”œâ”€â”€ SKILL.md
â”‚   â””â”€â”€ (optional scripts/ or references/)
â”œâ”€â”€ another-prompt-skill/
â”‚   â”œâ”€â”€ SKILL.md
â”‚   â””â”€â”€ (optional scripts/ or references/)
...
```

**ç”Ÿæˆçš„ SKILL.md åŒ…å«ï¼š**
- `name`: skill åç§°ï¼ˆkebab-caseï¼‰
- `description`: åŸºäº prompt å†…å®¹è‡ªåŠ¨ç”Ÿæˆ
- Overview: ç®€è¦è¯´æ˜
- Workflow: ä½¿ç”¨æ­¥éª¤
- Examples: ä½¿ç”¨ç¤ºä¾‹
- Resources: ç›¸å…³èµ„æºï¼ˆå¦‚æœ‰ï¼‰

**é…ç½®é€‰é¡¹ï¼š**
- `--input`: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ prompts æ–‡ä»¶ï¼‰
- `--output-dir`: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š/root/clawd/skillsï¼‰
- `--quality-threshold`: è´¨é‡é˜ˆå€¼ï¼ˆé»˜è®¤ï¼š50ï¼‰
- `--dry-run`: é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…åˆ›å»ºæ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```bash
# 1. ä½¿ç”¨ enhanced æ”¶é›†è„šæœ¬æ”¶é›†æç¤ºè¯
python3 scripts/collect_prompts_enhanced.py

# 2. è½¬æ¢ä¸º skillsï¼ˆåªè½¬æ¢è´¨é‡ >= 60 çš„æç¤ºè¯ï¼‰
python3 scripts/convert-prompts-to-skills.py --quality-threshold 60

# 3. é¢„è§ˆæ¨¡å¼ï¼ˆæŸ¥çœ‹ä¼šåˆ›å»ºå“ªäº› skillsï¼Œä½†ä¸å®é™…åˆ›å»ºï¼‰
python3 scripts/convert-prompts-to-skills.py --dry-run

# 4. æŸ¥çœ‹è½¬æ¢ç»Ÿè®¡
python3 scripts/convert-prompts-to-skills.py --stats
```

**è¾“å‡ºç»Ÿè®¡ï¼š**
- å¤„ç†çš„æç¤ºè¯æ€»æ•°
- è½¬æ¢æˆåŠŸçš„ skills æ•°
- è·³è¿‡çš„æç¤ºè¯æ•°ï¼ˆè´¨é‡ä¸è¶³ï¼‰
- é”™è¯¯æ•°
- è½¬æ¢è€—æ—¶

**ä¾èµ–ï¼š**
- Python 3.8+
- `json`ã€`pathlib`ã€`re` ç­‰æ ‡å‡†åº“
- å·²æ”¶é›†çš„æç¤ºè¯æ•°æ®ï¼ˆJSONL æ ¼å¼ï¼‰

**æ³¨æ„äº‹é¡¹ï¼š**
- ç”Ÿæˆçš„ SKILL.md éœ€è¦äººå·¥å®¡æŸ¥å’Œä¼˜åŒ–
- å»ºè®®å…ˆä½¿ç”¨ `--dry-run` é¢„è§ˆ
- è½¬æ¢åéœ€è¦ä½¿ç”¨ `package_skill.py` æ‰“åŒ…
- å‘å¸ƒå‰éœ€è¦å……åˆ†æµ‹è¯•

### scripts/batch_convert.py

Batch converts high-scoring prompts to skills (semi-automated):

```bash
python3 scripts/batch_convert.py /tmp/ranked.json --interactive
```

**Features:**
- Iterates through ranked prompts
- Initializes skill for each
- Generates initial SKILL.md draft
- Requires human review before packaging

**Note:** Full automation is not recommended - Claude should guide conversion interactively for quality.

## Reference Documentation

### references/evaluation-criteria.md

Detailed rubric for scoring prompts:

```markdown
# Prompt Evaluation Criteria

## Scoring Guide

### Clarity & Completeness (10 points)
- 10: Crystal clear, complete, no ambiguity
- 8-9: Minor ambiguities, mostly complete
- 5-7: Some missing steps, moderately clear
- 3-4: Vague, incomplete
- 1-2: Confusing, unusable

### Uniqueness (10 points)
- 10: Novel, unlike any existing skill
- 8-9: Unique approach to common problem
- 5-7: Good but not groundbreaking
- 3-4: Similar to existing skills
- 1-2: Duplicate or generic

### Market Potential (10 points)
- 10: High demand, viral engagement
- 8-9: Clear niche audience
- 5-7: Moderate interest
- 3-4: Small audience
- 1-2: Little/no demand

### Technical Feasibility (10 points)
- 10: Easily automatable, fits Clawdbot perfectly
- 8-9: Requires some tools, feasible
- 5-7: Complex but possible
- 3-4: Very difficult, may not work
- 1-2: Impossible or requires external services

## Total Score Calculation
Total = Clarity + Uniqueness + Market + Feasibility (max 40)

**Threshold**: 30/40 (75%) recommended for conversion
```

### references/conversion-template.md

Standardized template for converting prompts to skills.

### references/skill-naming-conventions.md

Guidelines for naming skills consistently:

```markdown
# Skill Naming Conventions

## General Rules
- Use kebab-case (lowercase with hyphens)
- Max 3-5 words
- Be descriptive but concise
- Avoid generic names (e.g., "ai-helper")
- Use domain-specific terms when appropriate

## Examples

âœ… Good Names:
- email-drafter
- code-reviewer
- twitter-scanner
- prompt-optimizer

âŒ Bad Names:
- AI-helper (too generic)
- the-best-email-writer (too long)
- CodeReviewTool (not kebab-case)
- skill123 (not descriptive)
```

## Best Practices

### Quality Over Quantity

- **1 great skill > 10 mediocre skills**
- Focus on high-scoring prompts only
- Test thoroughly before publishing
- Update regularly based on feedback

### Interactive vs. Automated

**What should be automated:**
- Prompt collection from X
- Initial scoring and filtering
- Skill initialization
- Packaging

**What should be interactive (Claude-guided):**
- Quality evaluation judgments
- Skill structure design
- SKILL.md writing
- Resource creation

### Iterative Improvement

1. Start with manual conversion to understand patterns
2. Document successful conversion patterns
3. Gradually automate repeatable steps
4. Always review AI-generated content
5. Learn from published skills' performance

## Integration with Cron

Schedule regular prompt discovery:

```bash
# Add to crontab
crontab -e

# Daily prompt collection at 9 AM
0 9 * * * cd /root/clawd/skills/prompt-to-skill-converter && python3 scripts/collect_prompts.py --query "prompts" --max-results 200 --output /tmp/prompts_$(date +\%Y\%m\%d).json
```

## Example: End-to-End Workflow

### Traditional Manual Workflow

```bash
# 1. Collect prompts
python3 scripts/collect_prompts.py --query "prompts" --max-results 200 --output /tmp/prompts.json

# 2. Evaluate
python3 scripts/evaluate_prompts.py /tmp/prompts.json --threshold 30 --output /tmp/ranked.json

# 3. Convert (interactive)
python3 scripts/batch_convert.py /tmp/ranked.json --interactive

# 4. For each created skill:
python3 /usr/lib/node_modules/clawdbot/skills/skill-creator/scripts/package_skill.py /root/clawd/skills/<skill-name>

# 5. Publish
clawdhub publish <skill-name>.skill --registry https://www.clawhub.ai/api
```

### Full Automated Workflow (Recommended) ğŸ”¥

Use the integrated workflow script for complete automation:

```bash
# Run complete workflow with default settings
bash scripts/full-prompt-workflow.sh

# With custom quality threshold
bash scripts/full-prompt-workflow.sh --quality-threshold 70

# Test mode (no publishing)
bash scripts/full-prompt-workflow.sh --test-mode

# Verbose output
bash scripts/full-prompt-workflow.sh --verbose

# Show help
bash scripts/full-prompt-workflow.sh --help
```

**What It Does:**

1. **Phase 1: Data Collection**
   - Collects from all configured sources (Twitter, Reddit, GitHub, HN, SearXNG, Firecrawl)
   - Saves unified JSONL format to `/root/clawd/data/prompts/collected/`
   - Removes duplicates across sources

2. **Phase 2: Evaluation & Filtering**
   - Applies quality scoring (0-100)
   - Filters by threshold (default: 60)
   - Categorizes prompts by type

3. **Phase 3: Conversion to Skills**
   - Generates unique skill names
   - Creates SKILL.md files with proper structure
   - Generates supporting documentation

4. **Phase 4: Packaging**
   - Validates each skill
   - Creates `.skill` packages
   - Checks for errors

5. **Phase 5: Publishing**
   - Publishes to ClawdHub with `--registry https://www.clawhub.ai/api`
   - Generates detailed report
   - Skips if test mode enabled

**Output:**

```
/root/clawd/
â”œâ”€â”€ data/prompts/
â”‚   â”œâ”€â”€ collected/           # Collected data (JSONL)
â”‚   â””â”€â”€ processed/           # Processed and filtered
â”œâ”€â”€ skills/                  # Generated skills
â”‚   â”œâ”€â”€ prompt-skill-1/
â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â””â”€â”€ prompt-skill-2/
â”‚       â””â”€â”€ SKILL.md
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ workflow-<timestamp>.txt
```

**Report Contents:**
- Collection statistics (per source)
- Quality distribution
- Skills created
- Packaging results
- Publishing status
- Errors and warnings

**Schedule with Cron:**

```bash
# Run daily at 9 AM
0 9 * * * cd /root/clawd && bash scripts/full-prompt-workflow.sh

# Run every 6 hours
0 */6 * * * cd /root/clawd && bash scripts/full-prompt-workflow.sh --quality-threshold 70

# Run weekly on Monday 8 AM
0 8 * * 1 cd /root/clawd && bash scripts/full-prompt-workflow.sh --test-mode
```

## Troubleshooting

### Twitter API Issues
- Verify API key in `~/.bashrc`
- Check rate limits
- Try reduced result count

### Low-Quality Prompts
- Adjust evaluation thresholds
- Refine search queries
- Add more engagement filters

### Packaging Errors
- Check YAML syntax
- Verify frontmatter fields
- Ensure SKILL.md is not empty

### Publishing Failures
- Verify ClawdHub token
- Check internet connection
- Validate .skill file format
- **Important**: Ensure `--registry https://www.clawhub.ai/api` is specified

## scripts/full-prompt-workflow.sh ğŸ”¥

å®Œæ•´çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–å·¥ä½œæµè„šæœ¬ï¼Œæ•´åˆäº†æ•°æ®æ”¶é›†ã€è¯„ä¼°ã€è½¬æ¢ã€æ‰“åŒ…å’Œå‘å¸ƒã€‚

### åŠŸèƒ½æ¦‚è¿°

æ­¤è„šæœ¬æä¾›äº†ä¸€é”®å¼è‡ªåŠ¨åŒ–ï¼Œå°†æ•´ä¸ªæç¤ºè¯è½¬æ¢ä¸º Skill çš„æµç¨‹æ•´åˆä¸ºä¸€ä¸ªå‘½ä»¤ï¼š

```bash
bash scripts/full-prompt-workflow.sh [OPTIONS]
```

### å‘½ä»¤é€‰é¡¹

| é€‰é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--quality-threshold` | 60 | è´¨é‡é˜ˆå€¼ï¼ˆ0-100ï¼‰ï¼Œåªè½¬æ¢é«˜äºæ­¤åˆ†æ•°çš„æç¤ºè¯ |
| `--test-mode` | false | æµ‹è¯•æ¨¡å¼ï¼Œä¸å®é™…å‘å¸ƒåˆ° ClawdHub |
| `--verbose` | false | è¯¦ç»†è¾“å‡ºæ¨¡å¼ |
| `--dry-run` | false | é¢„è§ˆæ¨¡å¼ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œ |
| `--help` | - | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ |

### å·¥ä½œæµé˜¶æ®µ

**Phase 1: æ•°æ®æ”¶é›†**
- æ”¶é›†æ¥è‡ª Twitter, Reddit, GitHub, HN, SearXNG, Firecrawl çš„æç¤ºè¯
- ä¿å­˜åˆ° `/root/clawd/data/prompts/collected/`
- è‡ªåŠ¨å»é‡

**Phase 2: è¯„ä¼°å’Œè¿‡æ»¤**
- åº”ç”¨è´¨é‡è¯„åˆ†ï¼ˆ0-100ï¼‰
- æ ¹æ®é˜ˆå€¼è¿‡æ»¤
- ä¿å­˜åˆ° `/root/clawd/data/prompts/processed/`

**Phase 3: è½¬æ¢ä¸º Skills**
- ç”Ÿæˆ SKILL.md æ–‡ä»¶
- åˆ›å»º skill ç›®å½•ç»“æ„
- ä¿å­˜åˆ° `/root/clawd/skills/`

**Phase 4: æ‰“åŒ…**
- éªŒè¯æ¯ä¸ª skill
- åˆ›å»º `.skill` åŒ…
- æ£€æŸ¥å®Œæ•´æ€§

**Phase 5: å‘å¸ƒ**
- å‘å¸ƒåˆ° ClawdHubï¼ˆå¸¦ `--registry https://www.clawhub.ai/api`ï¼‰
- ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
- æµ‹è¯•æ¨¡å¼ä¸‹è·³è¿‡

### ä½¿ç”¨ç¤ºä¾‹

```bash
# åŸºæœ¬ä½¿ç”¨
bash scripts/full-prompt-workflow.sh

# æé«˜è´¨é‡é˜ˆå€¼
bash scripts/full-prompt-workflow.sh --quality-threshold 80

# æµ‹è¯•æ¨¡å¼ï¼ˆä¸å‘å¸ƒï¼‰
bash scripts/full-prompt-workflow.sh --test-mode --verbose
```

### è¾“å‡ºæŠ¥å‘Š

ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šåˆ° `/root/clawd/reports/workflow-<timestamp>.txt`ï¼ŒåŒ…å«ï¼š

- æ¯ä¸ªé˜¶æ®µçš„ç»Ÿè®¡ä¿¡æ¯
- æ”¶é›†çš„æç¤ºè¯æ•°é‡
- è´¨é‡åˆ†å¸ƒ
- åˆ›å»ºçš„ skills æ•°é‡
- å‘å¸ƒçŠ¶æ€
- é”™è¯¯å’Œè­¦å‘Š

### Cron é›†æˆ

```bash
# æ¯å¤©æ—©ä¸Š 9 ç‚¹è¿è¡Œ
0 9 * * * cd /root/clawd && bash scripts/full-prompt-workflow.sh >> /root/clawd/logs/cron-workflow.log 2>&1
```

## Resources

### Required Skills
- **twitter-search-skill**: For Twitter/X prompt discovery
- **skill-creator**: For skill creation framework
- **searxng**: For privacy-respecting metasearch
- **firecrawl-scraper**: For advanced web scraping
- **twitter-reader**: For fetching Twitter post content
- **firecrawl**: For web search and scraping via Firecrawl API

### External Dependencies
- **Twitter API Key**: From twitterapi.io (configured in `~/.bashrc`)
- **Reddit API Credentials**: From reddit.com/prefs/apps (for Reddit data collection)
- **GitHub Personal Access Token**: From github.com/settings/tokens (optional, increases rate limits)
- **SearXNG Instance**: Local or remote metasearch instance (optional)
- **Firecrawl API Key**: From firecrawl.dev (optional, for advanced scraping)
- **ClawdHub Token**: Already configured (`clh_Ki_M1Xiws5Qzi83gqdZhYG3jXSuZOnEfQOxhaRsjHcw`)
  - **Registry URL**: `https://www.clawhub.ai/api` (critical for publishing)

### CLI Tools
- **bird CLI**: `npm install -g @sugarcube/cli` (for Twitter API)
- **ClawdHub CLI**: Included with Clawdbot (for publishing)
- **Python 3.8+**: Required for automation scripts

### Documentation
- Skill Creator Guide: `/usr/lib/node_modules/clawdbot/skills/skill-creator/SKILL.md`
- ClawdHub CLI: Run `clawdhub --help`
- Twitter Search Skill: `/root/clawd/skills/twitter-search-skill/SKILL.md`
