# AI æç¤ºè¯è½¬ Skill å®æˆ˜æ•™ç¨‹

> ä»é›¶å¼€å§‹æ‰“é€ è‡ªåŠ¨åŒ– AI æç¤ºè¯æ”¶é›†ã€è¯„ä¼°ã€è½¬æ¢å’Œå‘å¸ƒç³»ç»Ÿ

**ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¶é—´**: 2026-01-31
**ç›®æ ‡**: æ‰‹æŠŠæ‰‹æ•™ä½ å»ºç«‹å®Œæ•´çš„ AI æç¤ºè¯å•†ä¸šåŒ–æµç¨‹

---

## ğŸ“‹ ç›®å½•

- [ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¦‚è§ˆ](#ç¬¬ä¸€éƒ¨åˆ†é¡¹ç›®æ¦‚è§ˆ)
- [ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®æ”¶é›†ï¼ˆå®æˆ˜æ ¸å¿ƒï¼‰](#ç¬¬äºŒéƒ¨åˆ†æ•°æ®æ”¶é›†å®æˆ˜æ ¸å¿ƒ)
- [ç¬¬ä¸‰éƒ¨åˆ†ï¼šæç¤ºè¯è½¬æ¢](#ç¬¬ä¸‰éƒ¨åˆ†æç¤ºè¯è½¬æ¢)
- [ç¬¬å››éƒ¨åˆ†ï¼šå‘å¸ƒåˆ° ClawdHub](#ç¬¬å››éƒ¨åˆ†å‘å¸ƒåˆ°-clawdhub)
- [ç¬¬äº”éƒ¨åˆ†ï¼šç»éªŒæ•™è®­](#ç¬¬äº”éƒ¨åˆ†ç»éªŒæ•™è®­)
- [é™„å½•ï¼šå¸¸è§é—®é¢˜](#é™„å½•å¸¸è§é—®é¢˜)

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¦‚è§ˆ

### 1.1 å•†ä¸šæ¨¡å¼è¯´æ˜

#### ä»€ä¹ˆæ˜¯ AI æç¤ºè¯è½¬ Skillï¼Ÿ

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
- ä» Twitter/Xã€Redditã€GitHub ç­‰å¹³å°æ”¶é›†é«˜è´¨é‡ AI æç¤ºè¯
- ä½¿ç”¨å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿè¯„ä¼°æç¤ºè¯è´¨é‡
- è‡ªåŠ¨è½¬æ¢ä¸º Clawdbot Skill æ ¼å¼
- å‘å¸ƒåˆ° ClawdHub å¹³å°å”®å–

**å¸‚åœºå®šä½**ï¼š
- âŒ ä¸æ˜¯å–åŸç”Ÿæç¤ºè¯ï¼ˆåƒ PromptBaseï¼‰
- âœ… å–**å¯æ‰§è¡Œçš„ã€æ ¼å¼åŒ–çš„ Clawdbot Skills**
- âœ… ç›®æ ‡ç”¨æˆ·ï¼šClawdbot ç”¨æˆ·ç¾¤ä½“

#### æ”¶å…¥æ¨¡å‹

**å®šä»·ç­–ç•¥**ï¼ˆåŸºäºè¯„åˆ†ç­‰çº§ï¼‰ï¼š

| ç­‰çº§ | åˆ†æ•°èŒƒå›´ | å®šä»· | é¢„æœŸæœˆé”€é‡ |
|------|---------|------|-----------|
| A+ | 90-100 | $9.99 | 30-50ä»½ |
| A | 85-89 | $4.99 | 50-100ä»½ |
| B+ | 80-84 | $2.99 | 100-200ä»½ |
| B | 70-79 | $1.99 | 200-300ä»½ |
| C+ | 60-69 | $0.99 | 300-500ä»½ |
| C | 50-59 | å…è´¹ | ä¸é™é‡ |
| D | 0-49 | ä¸æ”¶å½• | - |

**æ”¶å…¥é¢„æµ‹**ï¼š
- ä¿å®ˆä¼°è®¡ï¼ˆç¬¬1å¹´ï¼‰ï¼š$3,600
- ä¹è§‚ä¼°è®¡ï¼ˆç¬¬1å¹´ï¼‰ï¼š$10,500

### 1.2 å¸‚åœºåˆ†æ

#### ç«äº‰å¯¹æ‰‹åˆ†æ

| å¹³å° | å®šä»·æ¨¡å¼ | äº§å“ç±»å‹ | æˆ‘ä»¬çš„å·®å¼‚åŒ– |
|------|---------|---------|-------------|
| PromptBase | å•æ¬¡è´­ä¹° $1.99-$9.99 | åŸç”Ÿæç¤ºè¯ | âœ… è‡ªåŠ¨è½¬æ¢ä¸º Skill |
| LearnPrompting | ä¼šå‘˜åˆ¶ $15/æœˆ | æ•™ç¨‹è¯¾ç¨‹ | âœ… å³ç”¨å‹äº§å“ |
| SnackPrompt | å…è´¹+è®¢é˜… | ç¤¾åŒºåˆ†äº« | âœ… è´¨é‡ç­›é€‰ + æ ¼å¼åŒ– |
| FlowGPT | å…è´¹ä¸ºä¸» | ç”¨æˆ·ç”Ÿæˆ | âœ… ä¸“ä¸šè¯„ä¼° + å•†ä¸šåŒ– |

#### ç›®æ ‡ç”¨æˆ·ç”»åƒ

**ä¸»è¦ç”¨æˆ·ç¾¤ä½“**ï¼š
1. **Clawdbot ç”¨æˆ·**ï¼ˆ30%ï¼‰
   - å·²å®‰è£… Clawdbot
   - éœ€è¦æ‰©å±•åŠŸèƒ½
   - æ„¿æ„ä»˜è´¹æå‡æ•ˆç‡

2. **AI å·¥å…·çˆ±å¥½è€…**ï¼ˆ40%ï¼‰
   - å°è¯•å„ç§ AI å·¥å…·
   - çƒ­è¡·äºæ–°æŠ€å·§
   - åˆ†äº«å’Œä½¿ç”¨é«˜è´¨é‡æç¤ºè¯

3. **ä¸“ä¸šåˆ›ä½œè€…**ï¼ˆ20%ï¼‰
   - å†…å®¹åˆ›ä½œè€…
   - è¥é”€äººå‘˜
   - éœ€è¦ç‰¹å®šé¢†åŸŸçš„ AI è¾…åŠ©

4. **ä¼ä¸šç”¨æˆ·**ï¼ˆ10%ï¼‰
   - å¯»æ‰¾è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆ
   - éœ€è¦ç¨³å®šçš„ AI å·¥ä½œæµ
   - æ„¿æ„ä¸ºè´¨é‡ä»˜è´¹

### 1.3 æŠ€æœ¯æ¶æ„

#### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ•°æ®æ”¶é›†å±‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Twitter/X  â”‚  Reddit  â”‚  GitHub  â”‚  SearXNG  â”‚  HN       â”‚
â”‚  (API/RSS)   â”‚  (PRAW)  â”‚  (API)   â”‚  (æœ¬åœ°)   â”‚  (API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚          â”‚          â”‚          â”‚
              â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å¤„ç†å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æå–ä¸   â”‚â†’ â”‚ è´¨é‡è¯„ä¼° â”‚â†’ â”‚ å»é‡ä¸   â”‚â†’ â”‚ åˆ†ç±»ä¸   â”‚   â”‚
â”‚  â”‚ æ¸…æ´—     â”‚  â”‚ (5ç»´åº¦)  â”‚  â”‚ åˆå¹¶     â”‚  â”‚ æ ‡ç­¾     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Skill è½¬æ¢å±‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ æ¨¡æ¿åŒ¹é… â”‚â†’ â”‚ å†…å®¹å¢å¼º â”‚â†’ â”‚ æ ¼å¼åŒ–   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‘å¸ƒå±‚                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ éªŒè¯ä¸   â”‚â†’ â”‚ è‡ªåŠ¨æ‰“åŒ… â”‚â†’ â”‚ ClawdHub â”‚                   â”‚
â”‚  â”‚ æ ¼å¼æ£€æŸ¥ â”‚  â”‚ (.skill) â”‚  â”‚ å‘å¸ƒ     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æŠ€æœ¯æ ˆ

**åç«¯**ï¼š
- Python 3.9+
- Cron å®šæ—¶ä»»åŠ¡
- GitHub Actionsï¼ˆå¯é€‰ï¼‰

**å·¥å…·åº“**ï¼š
- `twitter-api-v2` - Twitter API å®¢æˆ·ç«¯
- `praw` - Reddit API å®¢æˆ·ç«¯
- `PyGithub` - GitHub API å®¢æˆ·ç«¯
- `requests` - HTTP è¯·æ±‚
- `clawdhub-cli` - ClawdHub å‘½ä»¤è¡Œå·¥å…·

**æ•°æ®å­˜å‚¨**ï¼š
- æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼ˆJSONL æ ¼å¼ï¼‰
- Git ä»“åº“ï¼ˆç‰ˆæœ¬æ§åˆ¶ï¼‰

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®æ”¶é›†ï¼ˆå®æˆ˜æ ¸å¿ƒï¼‰

### 2.1 å¤šæ•°æ®æºé‡‡é›†

#### 2.1.1 Twitter/X API é›†æˆ

**ç¯å¢ƒé…ç½®**ï¼š

```bash
# 1. å®‰è£…ä¾èµ–
pip install twitter-api-v2 requests

# 2. é…ç½® API Key
export TWITTER_API_KEY="your_api_key_here"
export TWITTER_API_SECRET="your_api_secret_here"
export TWITTER_ACCESS_TOKEN="your_access_token_here"
export TWITTER_ACCESS_SECRET="your_access_secret_here"
```

**è„šæœ¬ç¤ºä¾‹**ï¼š`search-x-prompts.py`

```python
#!/usr/bin/env python3
import os
import json
import requests
from datetime import datetime

# Twitter API Keyï¼ˆä» ~/.bashrc åŠ è½½ï¼‰
TWITTER_API_KEY = os.environ.get('TWITTER_API_KEY', '')

def search_x_prompts():
    """
    ä½¿ç”¨ Twitter API æœç´¢ AI æç¤ºè¯
    æ³¨æ„ï¼šå…è´¹è®¡åˆ’æœ‰é€Ÿç‡é™åˆ¶
    """
    if not TWITTER_API_KEY:
        print("âŒ Twitter API Key æœªé…ç½®")
        return []

    # æœç´¢æŸ¥è¯¢ï¼ˆä½¿ç”¨æ ‡ç­¾è¿‡æ»¤ï¼Œæé«˜è´¨é‡ï¼‰
    queries = [
        "#AIPrompts -is:retweet lang:en min_faves:10",
        "#promptengineering -is:retweet lang:en min_faves:10",
        "(#ChatGPT OR #ClaudeAI OR #GPT4) prompts -is:retweet lang:en min_faves:10",
        "Midjourney prompts -is:retweet lang:en",
        '"prompt template" AI -is:retweet lang:en',
        '"system prompt" LLM -is:retweet lang:en',
        '(Claude OR ChatGPT) act as -is:retweet lang:en min_faves:20',
        '"prompt engineering" guide tutorial -is:retweet lang:en min_faves:10'
    ]

    all_tweets = []

    for query in queries:
        try:
            # ä½¿ç”¨ twitterapi.io æœåŠ¡
            url = f"https://api.twitterapi.io/v2/search?query={query}&max_results=10"
            headers = {
                "Authorization": f"Bearer {TWITTER_API_KEY}",
                "Content-Type": "application/json"
            }

            response = requests.get(url, headers=headers, timeout=30)

            if response.status_code == 200:
                data = response.json()
                tweets = data.get('data', [])
                all_tweets.extend(tweets)
                print(f"âœ… æŸ¥è¯¢æˆåŠŸ: {query} - è·å– {len(tweets)} æ¡æ¨æ–‡")
            elif response.status_code == 429:
                print(f"âš ï¸ é€Ÿç‡é™åˆ¶: {query} - è¯·æ±‚è¿‡äºé¢‘ç¹")
                break
            else:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {query} - {response.status_code}")

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¼‚å¸¸: {query} - {str(e)}")

    return all_tweets

def save_tweets(tweets, output_dir="/root/clawd/data/x-scraping"):
    """
    ä¿å­˜æ¨æ–‡åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(output_dir, f"prompts-{today}.jsonl")

    with open(output_file, 'a', encoding='utf-8') as f:
        for tweet in tweets:
            # æ ‡å‡†åŒ–æ ¼å¼
            standardized = {
                'tweet_id': tweet.get('id'),
                'author_handle': tweet.get('username'),
                'author_followers': tweet.get('followers_count', 0),
                'content': tweet.get('text', ''),
                'likes': tweet.get('likes_count', 0),
                'retweets': tweet.get('retweets_count', 0),
                'replies': tweet.get('replies_count', 0),
                'quotes': tweet.get('quotes_count', 0),
                'created_at': tweet.get('created_at'),
                'url': f"https://twitter.com/i/web/status/{tweet.get('id')}",
                'source': 'twitter',
                'collected_at': datetime.now().isoformat()
            }
            f.write(json.dumps(standardized, ensure_ascii=False) + '\n')

    print(f"âœ… ä¿å­˜ {len(tweets)} æ¡æ¨æ–‡åˆ° {output_file}")

if __name__ == "__main__":
    tweets = search_x_prompts()
    save_tweets(tweets)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
# æ·»åŠ æ‰§è¡Œæƒé™
chmod +x /root/clawd/scripts/search-x-prompts.py

# è¿è¡Œè„šæœ¬
python3 /root/clawd/scripts/search-x-prompts.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ… æŸ¥è¯¢æˆåŠŸ: #AIPrompts -is:retweet lang:en min_faves:10 - è·å– 10 æ¡æ¨æ–‡
âœ… æŸ¥è¯¢æˆåŠŸ: #promptengineering -is:retweet lang:en min_faves:10 - è·å– 10 æ¡æ¨æ–‡
âš ï¸ é€Ÿç‡é™åˆ¶: (#ChatGPT OR #ClaudeAI OR #GPT4) prompts -is:retweet lang:en min_faves:10 - è¯·æ±‚è¿‡äºé¢‘ç¹
âœ… ä¿å­˜ 20 æ¡æ¨æ–‡åˆ° /root/clawd/data/x-scraping/prompts-20260131.jsonl
```

#### 2.1.2 Reddit æ•°æ®æŠ“å–

**ç¯å¢ƒé…ç½®**ï¼š

```bash
# 1. å®‰è£…ä¾èµ–
pip install praw

# 2. é…ç½® Reddit API
# è®¿é—® https://www.reddit.com/prefs/apps åˆ›å»ºåº”ç”¨
```

**è„šæœ¬ç¤ºä¾‹**ï¼š`collect-reddit-prompts.py`

```python
#!/usr/bin/env python3
import praw
import json
import os
from datetime import datetime

# Reddit API é…ç½®
reddit = praw.Reddit(
    client_id="your_client_id",
    client_secret="your_client_secret",
    user_agent="ClawdbotPromptCollector/1.0 by /u/your_username"
)

# å­ç‰ˆå—é…ç½®
SUBREDDITS = {
    "ChatGPTPromptGenius": {"limit": 25, "score_threshold": 100},
    "PromptEngineering": {"limit": 25, "score_threshold": 50},
    "ChatGPT": {"limit": 50, "score_threshold": 500},
    "Claude": {"limit": 25, "score_threshold": 50},
}

def collect_reddit_prompts():
    """
    ä» Reddit æ”¶é›† AI æç¤ºè¯
    """
    all_posts = []

    for subreddit_name, config in SUBREDDITS.items():
        try:
            subreddit = reddit.subreddit(subreddit_name)

            # è·å–çƒ­é—¨å¸–å­
            for post in subreddit.hot(limit=config["limit"]):
                # è¿‡æ»¤ä½è´¨é‡å†…å®¹
                if post.score < config["score_threshold"]:
                    continue

                # æå–æç¤ºè¯ï¼ˆä»ä»£ç å—æˆ–é•¿æ–‡æœ¬ï¼‰
                content = post.selftext or ""

                # å¦‚æœæœ‰è¯„è®ºï¼Œä¹Ÿæ£€æŸ¥è¯„è®º
                if post.num_comments > 10:
                    comment_keywords = ["prompt", "here's", "try this", "i use"]
                    content += " " + " ".join([
                        comment.body
                        for comment in post.comments.list()[:10]
                        if any(kw in comment.body.lower() for kw in comment_keywords)
                    ])

                standardized = {
                    'post_id': post.id,
                    'author': str(post.author),
                    'content': content,
                    'title': post.title,
                    'score': post.score,
                    'upvotes': post.ups,
                    'num_comments': post.num_comments,
                    'url': f"https://reddit.com{post.permalink}",
                    'subreddit': subreddit_name,
                    'source': 'reddit',
                    'collected_at': datetime.now().isoformat()
                }

                all_posts.append(standardized)
                print(f"âœ… æ”¶é›†: r/{subreddit_name} - {post.title[:50]}...")

        except Exception as e:
            print(f"âŒ å¤±è´¥: r/{subreddit_name} - {str(e)}")

    return all_posts

def save_posts(posts, output_dir="/root/clawd/data/reddit"):
    """
    ä¿å­˜ Reddit å¸–å­åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(output_dir, f"prompts-{today}.jsonl")

    with open(output_file, 'a', encoding='utf-8') as f:
        for post in posts:
            f.write(json.dumps(post, ensure_ascii=False) + '\n')

    print(f"âœ… ä¿å­˜ {len(posts)} æ¡å¸–å­åˆ° {output_file}")

if __name__ == "__main__":
    posts = collect_reddit_prompts()
    save_posts(posts)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/collect-reddit-prompts.py
```

#### 2.1.3 GitHub Awesome Prompts è·å–

**è„šæœ¬ç¤ºä¾‹**ï¼š`collect-github-prompts.py`

```python
#!/usr/bin/env python3
from github import Github
import json
import os
from datetime import datetime
import re

# GitHub Tokenï¼ˆç”¨äºå¢åŠ  API é™åˆ¶ï¼‰
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN', '')

# é«˜è´¨é‡ä»“åº“åˆ—è¡¨
REPOS = [
    {"owner": "f", "repo": "awesome-chatgpt-prompts", "file": "README.md", "quality": 90},
    {"owner": "dair-ai", "repo": "Prompt-Engineering-Guide", "file": "README.md", "quality": 85},
    {"owner": "microsoft", "repo": "prompt-engine", "file": "README.md", "quality": 85},
]

def extract_prompts_from_readme(content):
    """
    ä» README ä¸­æå–æç¤ºè¯
    """
    prompts = []

    # åŒ¹é…æ ¼å¼ï¼š- **Role**: Description
    role_pattern = r'-\s*\*\*([^*]+)\*\*:\s*(.+)'

    for match in re.finditer(role_pattern, content):
        role = match.group(1)
        description = match.group(2)

        prompts.append({
            'role': role.strip(),
            'description': description.strip(),
            'content': f"You are a {role}. {description}",
            'quality': 'high'
        })

    return prompts

def collect_github_prompts():
    """
    ä» GitHub æ”¶é›†æç¤ºè¯
    """
    g = Github(GITHUB_TOKEN)
    all_prompts = []

    for repo_config in REPOS:
        try:
            repo = g.get_repo(f"{repo_config['owner']}/{repo_config['repo']}")

            # è·å– README æ–‡ä»¶
            readme = repo.get_contents(repo_config['file'])
            content = readme.decoded_content.decode('utf-8')

            # æå–æç¤ºè¯
            prompts = extract_prompts_from_readme(content)

            for prompt in prompts:
                standardized = {
                    'content': prompt['content'],
                    'role': prompt['role'],
                    'description': prompt['description'],
                    'source': 'github',
                    'repo': f"{repo_config['owner']}/{repo_config['repo']}",
                    'url': f"https://github.com/{repo_config['owner']}/{repo_config['repo']}",
                    'quality_score': repo_config['quality'],
                    'collected_at': datetime.now().isoformat()
                }
                all_prompts.append(standardized)

            print(f"âœ… æ”¶é›†: {repo_config['owner']}/{repo_config['repo']} - {len(prompts)} æ¡æç¤ºè¯")

        except Exception as e:
            print(f"âŒ å¤±è´¥: {repo_config['owner']}/{repo_config['repo']} - {str(e)}")

    return all_prompts

def save_prompts(prompts, output_dir="/root/clawd/data/github"):
    """
    ä¿å­˜æç¤ºè¯åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(output_dir, f"prompts-{today}.jsonl")

    with open(output_file, 'a', encoding='utf-8') as f:
        for prompt in prompts:
            f.write(json.dumps(prompt, ensure_ascii=False) + '\n')

    print(f"âœ… ä¿å­˜ {len(prompts)} æ¡æç¤ºè¯åˆ° {output_file}")

if __name__ == "__main__":
    prompts = collect_github_prompts()
    save_prompts(prompts)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
export GITHUB_TOKEN="your_github_token_here"
python3 /root/clawd/scripts/collect-github-prompts.py
```

#### 2.1.4 ä¸“ä¸šç½‘ç«™çˆ¬å–ï¼ˆSearXNGï¼‰

**ä½¿ç”¨è‡ªå»º SearXNG å®ä¾‹**ï¼ˆæ¨èï¼‰ï¼š

```bash
# SearXNG å·²åœ¨ localhost:8080 è¿è¡Œ
export SEARXNG_URL="http://localhost:8080"
```

**è„šæœ¬ç¤ºä¾‹**ï¼š`collect-searxng-prompts.py`

```python
#!/usr/bin/env python3
import requests
import json
import os
from datetime import datetime

SEARXNG_URL = os.environ.get('SEARXNG_URL', 'http://localhost:8080')

# æœç´¢å…³é”®è¯
SEARCH_KEYWORDS = [
    "AI prompt engineering tips 2026",
    "best ChatGPT prompts for work",
    "Claude AI prompt examples",
    "AI prompt templates free",
    "effective AI prompts guide",
    "Midjourney prompt guide",
    "GPT-4 system prompt examples",
]

def search_searxng(query):
    """
    ä½¿ç”¨ SearXNG æœç´¢
    """
    params = {
        'q': query,
        'format': 'json',
        'engines': 'google,duckduckgo,bing',  # å¤šæœç´¢å¼•æ“
        'language': 'en',
        'time_range': None,  # æ— æ—¶é—´é™åˆ¶
        'safesearch': 0,     # ä¸å¼€å¯å®‰å…¨æœç´¢
    }

    try:
        response = requests.get(
            f"{SEARXNG_URL}/search",
            params=params,
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            results = data.get('results', [])
            return results
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {query} - {response.status_code}")
            return []

    except Exception as e:
        print(f"âŒ æœç´¢å¼‚å¸¸: {query} - {str(e)}")
        return []

def collect_web_prompts():
    """
    ä»ç½‘ç»œæœç´¢æ”¶é›†æç¤ºè¯
    """
    all_prompts = []

    for keyword in SEARCH_KEYWORDS:
        results = search_searxng(keyword)

        for result in results:
            # æå–æç¤ºè¯ç›¸å…³å†…å®¹
            content = result.get('content', '')
            title = result.get('title', '')
            url = result.get('url', '')

            # è¿‡æ»¤æ‰éæç¤ºè¯å†…å®¹
            if len(content) < 50:
                continue

            # æ ‡å‡†åŒ–æ ¼å¼
            standardized = {
                'content': content[:2000],  # é™åˆ¶é•¿åº¦
                'title': title,
                'url': url,
                'score': result.get('score', 0),
                'source': 'searxng',
                'engine': result.get('engine', 'unknown'),
                'collected_at': datetime.now().isoformat()
            }

            all_prompts.append(standardized)

        print(f"âœ… æœç´¢: {keyword} - è·å– {len(results)} æ¡ç»“æœ")

    return all_prompts

def save_prompts(prompts, output_dir="/root/clawd/data/searxng"):
    """
    ä¿å­˜æç¤ºè¯åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(output_dir, f"prompts-{today}.jsonl")

    with open(output_file, 'a', encoding='utf-8') as f:
        for prompt in prompts:
            f.write(json.dumps(prompt, ensure_ascii=False) + '\n')

    print(f"âœ… ä¿å­˜ {len(prompts)} æ¡æç¤ºè¯åˆ° {output_file}")

if __name__ == "__main__":
    prompts = collect_web_prompts()
    save_prompts(prompts)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/collect-searxng-prompts.py
```

### 2.2 æ•°æ®è´¨é‡è¯„ä¼°

#### 2.2.1 5 ç»´åº¦è¯„åˆ†ç³»ç»Ÿè¯¦è§£

**è¯„åˆ†ç»´åº¦**ï¼ˆ100 åˆ†åˆ¶ï¼‰ï¼š

| ç»´åº¦ | æƒé‡ | è¯´æ˜ | è¯„åˆ†æ ‡å‡† |
|------|------|------|---------|
| ğŸ¯ å®ç”¨æ€§ | 30% | å…·ä½“ä½¿ç”¨åœºæ™¯ã€æ­¥éª¤ã€å‚æ•° | 10-15: åŸºæœ¬æ€è·¯<br>16-25: æœ‰æ­¥éª¤<br>26-30: å®Œæ•´æ•™ç¨‹ |
| ğŸ¨ åˆ›æ–°æ€§ | 20% | æ–¹æ³•ç‹¬ç‰¹æ€§ã€è§’åº¦æ–°é¢– | 10-15: å¸¸è§æ€è·¯<br>16-18: ç‹¬ç‰¹è§’åº¦<br>19-20: å‰æ‰€æœªè§ |
| ğŸ“– å®Œæ•´æ€§ | 20% | è¯¦ç»†ç¨‹åº¦ã€ç¤ºä¾‹æ•°é‡ | 10-15: éƒ¨åˆ†ä¿¡æ¯<br>16-18: å¤§éƒ¨åˆ†å®Œæ•´<br>19-20: éå¸¸è¯¦ç»† |
| ğŸ”¥ çƒ­åº¦ | 25% | ç‚¹èµã€è½¬å‘ã€è¯„è®ºæ•° | æ ‡å‡†åŒ–ç®—æ³• |
| ğŸ‘¨â€ğŸ’¼ ä½œè€…å½±å“åŠ› | 5% | ç²‰ä¸æ•°ã€è®¤è¯çŠ¶æ€ | log10(followers) * 0.8 |

**å®ç°ä»£ç **ï¼š`evaluate-prompts.py`

```python
#!/usr/bin/env python3
import json
import re
import math
from datetime import datetime
import os

def evaluate_practicality(content):
    """
    è¯„ä¼°å®ç”¨æ€§ï¼ˆ30åˆ†ï¼‰
    """
    score = 0
    content_lower = content.lower()

    # 1. é•¿åº¦è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
    length = len(content)
    if 50 <= length <= 500:
        score += 10
    elif length > 500:
        score += 8
    elif length < 30:
        score += 0
    else:
        score += 5

    # 2. ç»“æ„è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
    if '\n' in content:
        score += 3
    if '```' in content:
        score += 3
    if re.search(r'(step|æ­¥éª¤|é¦–å…ˆ|å…¶æ¬¡|æœ€å)', content_lower):
        score += 4

    # 3. å…·ä½“æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
    specific_keywords = ['specific', 'detailed', 'for example', 'such as', 'include',
                         'å…·ä½“', 'è¯¦ç»†', 'ä¾‹å¦‚', 'åŒ…æ‹¬']
    for kw in specific_keywords:
        if kw in content_lower:
            score += 2
            if score >= 10:
                break

    return min(30, score)

def evaluate_innovation(content):
    """
    è¯„ä¼°åˆ›æ–°æ€§ï¼ˆ20åˆ†ï¼‰
    """
    score = 10  # åŸºç¡€åˆ†

    content_lower = content.lower()

    # æ£€æŸ¥ç‹¬ç‰¹çš„è§’åº¦æˆ–æ–¹æ³•
    unique_patterns = [
        r'first\s+time', r'never\s+seen', r'unique',
        r'novel\s+approach', r'innovative', r'cutting\s+edge'
    ]

    for pattern in unique_patterns:
        if re.search(pattern, content_lower):
            score += 3
            break

    # æ£€æŸ¥ç»„åˆå¤šä¸ªé¢†åŸŸ
    if re.search(r'(combine|merge|integrate|èåˆ|ç»“åˆ)', content_lower):
        score += 2

    return min(20, score)

def evaluate_completeness(content):
    """
    è¯„ä¼°å®Œæ•´æ€§ï¼ˆ20åˆ†ï¼‰
    """
    score = 0

    # 1. ä¸Šä¸‹æ–‡è¯´æ˜ï¼ˆ0-5åˆ†ï¼‰
    context_keywords = ['context', 'background', 'assume', 'given',
                       'èƒŒæ™¯', 'å‡è®¾', 'ç»™å®š']
    for kw in context_keywords:
        if kw in content.lower():
            score += 2
            if score >= 5:
                break

    # 2. ç¤ºä¾‹æ•°é‡ï¼ˆ0-5åˆ†ï¼‰
    example_count = content.count('example') + content.count('ç¤ºä¾‹')
    score += min(5, example_count)

    # 3. è¾“å‡ºè¯´æ˜ï¼ˆ0-5åˆ†ï¼‰
    output_keywords = ['output', 'result', 'return',
                      'è¾“å‡º', 'ç»“æœ', 'è¿”å›']
    for kw in output_keywords:
        if kw in content.lower():
            score += 2
            if score >= 15:
                break

    # 4. å‚æ•°è¯´æ˜ï¼ˆ0-5åˆ†ï¼‰
    if re.search(r'(parameter|argument|variable|å‚æ•°|å˜é‡)', content.lower()):
        score += 5

    return min(20, score)

def evaluate_popularity(item):
    """
    è¯„ä¼°çƒ­åº¦ï¼ˆ25åˆ†ï¼‰
    """
    score = 0

    # æ ‡å‡†åŒ–ç®—æ³•
    metrics = item.get('metrics', {})

    # Twitter
    if 'likes' in item:
        score += min(15, item['likes'] / 100)
    if 'retweets' in item:
        score += min(5, item['retweets'] / 50)
    if 'comments' in item:
        score += min(5, item['comments'] / 20)

    # Reddit
    if 'score' in item:
        score += min(20, item['score'] / 100)
    if 'upvotes' in item:
        score += min(20, item['upvotes'] / 100)

    # Hacker News
    if 'points' in item:
        score += min(20, item['points'] / 20)

    return min(25, score)

def evaluate_influence(item):
    """
    è¯„ä¼°ä½œè€…å½±å“åŠ›ï¼ˆ5åˆ†ï¼‰
    """
    followers = item.get('author_followers', 0)
    return min(5, math.log10(max(1, followers)) * 0.8)

def evaluate_prompt(item):
    """
    ç»¼åˆè¯„åˆ†
    """
    content = item.get('content', '')

    # å„ç»´åº¦è¯„åˆ†
    scores = {
        'practicality': evaluate_practicality(content),
        'innovation': evaluate_innovation(content),
        'completeness': evaluate_completeness(content),
        'popularity': evaluate_popularity(item),
        'influence': evaluate_influence(item)
    }

    # åŠ æƒæ€»åˆ†
    total_score = (
        scores['practicality'] * 0.30 +
        scores['innovation'] * 0.20 +
        scores['completeness'] * 0.20 +
        scores['popularity'] * 0.25 +
        scores['influence'] * 0.05
    )

    # ç¡®å®šç­‰çº§
    if total_score >= 90:
        grade = 'A+'
    elif total_score >= 85:
        grade = 'A'
    elif total_score >= 80:
        grade = 'B+'
    elif total_score >= 70:
        grade = 'B'
    elif total_score >= 60:
        grade = 'C+'
    elif total_score >= 50:
        grade = 'C'
    else:
        grade = 'D'

    return {
        'total_score': round(total_score, 2),
        'grade': grade,
        'scores': scores,
        'evaluated_at': datetime.now().isoformat()
    }

def batch_evaluate(input_dir="/root/clawd/data", output_dir="/root/clawd/data/evaluation"):
    """
    æ‰¹é‡è¯„ä¼°
    """
    os.makedirs(output_dir, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(output_dir, f"scored-prompts-{today}.jsonl")

    all_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if file.endswith('.jsonl'):
                all_files.append(os.path.join(root, file))

    with open(output_file, 'w', encoding='utf-8') as outfile:
        for input_file in all_files:
            with open(input_file, 'r', encoding='utf-8') as infile:
                for line in infile:
                    item = json.loads(line)

                    # è¯„ä¼°
                    evaluation = evaluate_prompt(item)

                    # åˆå¹¶
                    evaluated_item = {**item, **evaluation}

                    # ä¿å­˜
                    outfile.write(json.dumps(evaluated_item, ensure_ascii=False) + '\n')

    print(f"âœ… è¯„ä¼°å®Œæˆï¼Œä¿å­˜åˆ° {output_file}")

if __name__ == "__main__":
    batch_evaluate()
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/evaluate-prompts.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ… è¯„ä¼°å®Œæˆï¼Œä¿å­˜åˆ° /root/clawd/data/evaluation/scored-prompts-20260131.jsonl
```

**æŸ¥çœ‹è¯„åˆ†ç»“æœ**ï¼š

```bash
# æŸ¥çœ‹é«˜åˆ†æç¤ºè¯
jq -r 'select(.grade == "A+" or .grade == "A")' /root/clawd/data/evaluation/scored-prompts-20260131.jsonl | head -5

# ç»Ÿè®¡å„ç­‰çº§æ•°é‡
jq -r '.grade' /root/clawd/data/evaluation/scored-prompts-20260131.jsonl | sort | uniq -c
```

#### 2.2.2 AI è¯­ä¹‰è¯„ä¼°å®ç°

**ä½¿ç”¨ Claude API è¿›è¡Œè¯­ä¹‰è¯„ä¼°**ï¼š

```python
#!/usr/bin/env python3
import anthropic
import json
import os
from datetime import datetime

# Claude API Key
ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', '')
client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

EVALUATION_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI æç¤ºè¯è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°è¿™ä¸ªæç¤ºè¯çš„è´¨é‡ï¼ˆ0-100åˆ†ï¼‰ï¼š

1. **å®ç”¨æ€§ï¼ˆ30åˆ†ï¼‰**ï¼š
   - æ˜¯å¦æœ‰å…·ä½“çš„ä½¿ç”¨åœºæ™¯ï¼Ÿ
   - æ˜¯å¦æœ‰æ¸…æ™°çš„æ­¥éª¤è¯´æ˜ï¼Ÿ
   - æ˜¯å¦æœ‰å¿…è¦çš„å‚æ•°è®¾ç½®ï¼Ÿ

2. **åˆ›æ–°æ€§ï¼ˆ20åˆ†ï¼‰**ï¼š
   - è§’åº¦æ˜¯å¦æ–°é¢–ç‹¬ç‰¹ï¼Ÿ
   - æ˜¯å¦æœ‰ç‹¬ç‰¹çš„æŠ€å·§æˆ–æ–¹æ³•ï¼Ÿ
   - æ˜¯å¦ç»„åˆäº†å¤šä¸ªé¢†åŸŸçš„çŸ¥è¯†ï¼Ÿ

3. **å®Œæ•´æ€§ï¼ˆ20åˆ†ï¼‰**ï¼š
   - ä¸Šä¸‹æ–‡æ˜¯å¦å……åˆ†ï¼Ÿ
   - æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç¤ºä¾‹ï¼Ÿ
   - è¾“å‡ºè¯´æ˜æ˜¯å¦æ¸…æ™°ï¼Ÿ

4. **å…·ä½“æ€§ï¼ˆ15åˆ†ï¼‰**ï¼š
   - æ˜¯å¦é¿å…äº†æ¨¡ç³Šçš„è¡¨è¿°ï¼Ÿ
   - æ˜¯å¦ä½¿ç”¨äº†å…·ä½“çš„ä¾‹å­ï¼Ÿ
   - æ˜¯å¦æœ‰æ˜ç¡®çš„è¾“å‡ºæ ¼å¼ï¼Ÿ

5. **æ¸…æ™°åº¦ï¼ˆ15åˆ†ï¼‰**ï¼š
   - é€»è¾‘æ˜¯å¦æ¸…æ™°ï¼Ÿ
   - æ˜¯å¦æœ‰æ­§ä¹‰ï¼Ÿ
   - æ˜¯å¦å®¹æ˜“ç†è§£å’Œæ‰§è¡Œï¼Ÿ

**æç¤ºè¯å†…å®¹**ï¼š
{prompt}

**è¯·ä»¥ JSON æ ¼å¼è¿”å›è¯„åˆ†ç»“æœ**ï¼š
{{
  "practicality": åˆ†æ•°,
  "innovation": åˆ†æ•°,
  "completeness": åˆ†æ•°,
  "specificity": åˆ†æ•°,
  "clarity": åˆ†æ•°,
  "total_score": æ€»åˆ†,
  "grade": "A+/A/B+/B/C+/C/D",
  "reasoning": "ç®€çŸ­çš„è¯„åˆ†ç†ç”±",
  "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"]
}}
"""

def ai_evaluate_prompt(content):
    """
    ä½¿ç”¨ Claude è¿›è¡Œ AI è¯­ä¹‰è¯„ä¼°
    """
    try:
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1024,
            messages=[
                {
                    "role": "user",
                    "content": EVALUATION_PROMPT.format(prompt=content)
                }
            ]
        )

        # æå– JSON ç»“æœ
        content_text = response.content[0].text
        result = json.loads(content_text)

        return {
            'ai_evaluated': True,
            'ai_evaluation': result,
            'evaluated_at': datetime.now().isoformat()
        }

    except Exception as e:
        print(f"âŒ AI è¯„ä¼°å¤±è´¥: {str(e)}")
        return {
            'ai_evaluated': False,
            'error': str(e)
        }

def batch_ai_evaluate(input_file, output_file):
    """
    æ‰¹é‡ AI è¯„ä¼°
    """
    with open(input_file, 'r', encoding='utf-8') as infile, \
         open(output_file, 'w', encoding='utf-8') as outfile:

        for line in infile:
            item = json.loads(line)

            # åªè¯„ä¼°é«˜åˆ†æç¤ºè¯ï¼ˆâ‰¥60åˆ†ï¼‰
            if item.get('total_score', 0) >= 60:
                print(f"ğŸ¤– AI è¯„ä¼°ä¸­: {item.get('content', '')[:50]}...")
                ai_result = ai_evaluate_prompt(item.get('content', ''))
                item = {**item, **ai_result}

            outfile.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"âœ… AI è¯„ä¼°å®Œæˆï¼Œä¿å­˜åˆ° {output_file}")

if __name__ == "__main__":
    input_file = "/root/clawd/data/evaluation/scored-prompts-20260131.jsonl"
    output_file = "/root/clawd/data/evaluation/ai-scored-prompts-20260131.jsonl"

    batch_ai_evaluate(input_file, output_file)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
export ANTHROPIC_API_KEY="your_anthropic_api_key_here"
python3 /root/clawd/scripts/ai-evaluate-prompts.py
```

#### 2.2.3 å»é‡å’Œæ¸…æ´—æµç¨‹

**å»é‡è„šæœ¬**ï¼š`deduplicate-prompts.py`

```python
#!/usr/bin/env python3
import json
import hashlib
from difflib import SequenceMatcher

def content_hash(content):
    """
    ç”Ÿæˆå†…å®¹ hash
    """
    return hashlib.md5(content.encode('utf-8')).hexdigest()

def semantic_similarity(text1, text2, threshold=0.85):
    """
    è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
    """
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()

def deduplicate_prompts(input_file, output_file, similarity_threshold=0.85):
    """
    å»é‡
    """
    seen_hashes = set()
    unique_prompts = []

    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            content = item.get('content', '')

            # 1. Hash å»é‡ï¼ˆå®Œå…¨ç›¸åŒï¼‰
            h = content_hash(content)
            if h in seen_hashes:
                continue
            seen_hashes.add(h)

            # 2. è¯­ä¹‰å»é‡ï¼ˆç›¸ä¼¼ï¼‰
            is_duplicate = False
            for existing in unique_prompts:
                existing_content = existing.get('content', '')
                similarity = semantic_similarity(content, existing_content)
                if similarity >= similarity_threshold:
                    # ä¿ç•™è¯„åˆ†æ›´é«˜çš„
                    if item.get('total_score', 0) > existing.get('total_score', 0):
                        unique_prompts.remove(existing)
                        unique_prompts.append(item)
                    is_duplicate = True
                    break

            if not is_duplicate:
                unique_prompts.append(item)

    # ä¿å­˜å»é‡ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in unique_prompts:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"âœ… å»é‡å®Œæˆ: {len(unique_prompts)} æ¡å”¯ä¸€æç¤ºè¯")

if __name__ == "__main__":
    input_file = "/root/clawd/data/evaluation/scored-prompts-20260131.jsonl"
    output_file = "/root/clawd/data/evaluation/deduplicated-prompts-20260131.jsonl"

    deduplicate_prompts(input_file, output_file)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/deduplicate-prompts.py
```

**æ¸…æ´—è„šæœ¬**ï¼š`clean-prompts.py`

```python
#!/usr/bin/env python3
import json
import re

def clean_content(content):
    """
    æ¸…æ´—å†…å®¹
    """
    # 1. ç§»é™¤ HTML æ ‡ç­¾
    content = re.sub(r'<[^>]+>', '', content)

    # 2. ç§»é™¤å¤šä½™çš„ç©ºç™½
    content = re.sub(r'\s+', ' ', content)
    content = content.strip()

    # 3. ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™åŸºæœ¬æ ‡ç‚¹ï¼‰
    content = re.sub(r'[^\w\s.,!?;:\-\'"()]', '', content)

    # 4. ç§»é™¤æ˜æ˜¾çš„åƒåœ¾å†…å®¹
    spam_patterns = [
        r'click here', r'subscribe', r'follow me',
        r'buy now', r'sign up', r'limited time offer'
    ]
    for pattern in spam_patterns:
        if re.search(pattern, content, re.IGNORECASE):
            return None

    return content

def apply_filters(item):
    """
    åº”ç”¨è¿‡æ»¤è§„åˆ™
    """
    content = item.get('content', '')
    score = item.get('total_score', 0)

    # è¿‡æ»¤è§„åˆ™
    if len(content) < 30:
        return False
    if len(content) > 2000:
        return False
    if score < 50:
        return False

    return True

def clean_prompts(input_file, output_file):
    """
    æ¸…æ´—æç¤ºè¯
    """
    cleaned = []

    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)

            # æ¸…æ´—å†…å®¹
            cleaned_content = clean_content(item.get('content', ''))
            if not cleaned_content:
                continue

            # åº”ç”¨è¿‡æ»¤
            if not apply_filters(item):
                continue

            # æ›´æ–°å†…å®¹
            item['content'] = cleaned_content
            item['cleaned'] = True
            item['cleaned_at'] = datetime.now().isoformat()

            cleaned.append(item)

    # ä¿å­˜æ¸…æ´—ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in cleaned:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"âœ… æ¸…æ´—å®Œæˆ: {len(cleaned)} æ¡æ¸…æ´æç¤ºè¯")

if __name__ == "__main__":
    from datetime import datetime

    input_file = "/root/clawd/data/evaluation/deduplicated-prompts-20260131.jsonl"
    output_file = "/root/clawd/data/evaluation/cleaned-prompts-20260131.jsonl"

    clean_prompts(input_file, output_file)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/clean-prompts.py
```

### 2.3 å®æˆ˜è„šæœ¬ä½¿ç”¨

#### 2.3.1 Twitter æœç´¢å®æˆ˜

**æ­¥éª¤ 1ï¼šé…ç½®ç¯å¢ƒ**

```bash
# åŠ è½½ API Key
source ~/.bashrc

# éªŒè¯é…ç½®
echo $TWITTER_API_KEY
```

**æ­¥éª¤ 2ï¼šè¿è¡Œæœç´¢è„šæœ¬**

```bash
# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p /root/clawd/logs

# è¿è¡Œæœç´¢ï¼ˆå¸¦æ—¥å¿—ï¼‰
python3 /root/clawd/scripts/search-x-prompts.py 2>&1 | tee /root/clawd/logs/twitter-search-$(date +%Y%m%d-%H%M%S).log
```

**æ­¥éª¤ 3ï¼šæŸ¥çœ‹ç»“æœ**

```bash
# æŸ¥çœ‹æœ€æ–°çš„æ¨æ–‡æ–‡ä»¶
ls -lt /root/clawd/data/x-scraping/ | head -3

# æŸ¥çœ‹æ¨æ–‡å†…å®¹
cat /root/clawd/data/x-scraping/prompts-20260131.jsonl | jq -r '.content' | head -5
```

**æ­¥éª¤ 4ï¼šç»Ÿè®¡æ•°æ®**

```bash
# ç»Ÿè®¡æ¨æ–‡æ•°é‡
wc -l /root/clawd/data/x-scraping/prompts-20260131.jsonl

# ç»Ÿè®¡ç‚¹èµæ•°åˆ†å¸ƒ
cat /root/clawd/data/x-scraping/prompts-20260131.jsonl | jq -r '.likes' | sort -n | uniq -c
```

#### 2.3.2 SearXNG é›†æˆä½¿ç”¨

**æ­¥éª¤ 1ï¼šéªŒè¯ SearXNG çŠ¶æ€**

```bash
# æ£€æŸ¥ SearXNG æ˜¯å¦è¿è¡Œ
docker ps | grep searxng

# æµ‹è¯•æœç´¢
curl "http://localhost:8080/search?q=test&format=json" | jq .
```

**æ­¥éª¤ 2ï¼šè¿è¡Œæœç´¢è„šæœ¬**

```bash
# è®¾ç½® SearXNG URL
export SEARXNG_URL="http://localhost:8080"

# è¿è¡Œæœç´¢
python3 /root/clawd/scripts/collect-searxng-prompts.py
```

**æ­¥éª¤ 3ï¼šæŸ¥çœ‹ç»“æœè´¨é‡**

```bash
# æŸ¥çœ‹æœç´¢ç»“æœ
cat /root/clawd/data/searxng/prompts-20260131.jsonl | jq -r '.title, .score'

# è¿‡æ»¤é«˜è´¨é‡ç»“æœ
cat /root/clawd/data/searxng/prompts-20260131.jsonl | jq 'select(.score > 50)' | head -20
```

#### 2.3.3 Cron è‡ªåŠ¨åŒ–ä»»åŠ¡é…ç½®

**é…ç½® Cron ä»»åŠ¡**ï¼š

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹ä»»åŠ¡

# æ¯ 6 å°æ—¶æ”¶é›† Twitter æç¤ºè¯
0 */6 * * * cd /root/clawd && python3 /root/clawd/scripts/search-x-prompts.py >> /root/clawd/logs/cron-twitter.log 2>&1

# æ¯ 6 å°æ—¶æ”¶é›† Reddit æç¤ºè¯
30 */6 * * * cd /root/clawd && python3 /root/clawd/scripts/collect-reddit-prompts.py >> /root/clawd/logs/cron-reddit.log 2>&1

# æ¯ 4 å°æ—¶æœç´¢ç½‘ç»œèµ„æº
0 */4 * * * cd /root/clawd && python3 /root/clawd/scripts/collect-searxng-prompts.py >> /root/clawd/logs/cron-searxng.log 2>&1

# æ¯ 8 å°æ—¶è¯„ä¼°æç¤ºè¯
0 */8 * * * cd /root/clawd && python3 /root/clawd/scripts/evaluate-prompts.py >> /root/clawd/logs/cron-evaluate.log 2>&1

# æ¯å¤©æ—©ä¸Š 9 ç‚¹ç”ŸæˆæŠ¥å‘Š
0 9 * * * cd /root/clawd && bash /root/clawd/scripts/generate-daily-report.sh >> /root/clawd/logs/cron-report.log 2>&1
```

**æŸ¥çœ‹ Cron ä»»åŠ¡**ï¼š

```bash
# åˆ—å‡ºå½“å‰ crontab
crontab -l

# æŸ¥çœ‹ Cron æ—¥å¿—
tail -f /root/clawd/logs/cron-*.log
```

**æµ‹è¯• Cron ä»»åŠ¡**ï¼š

```bash
# æ‰‹åŠ¨è§¦å‘ä»»åŠ¡ï¼ˆæµ‹è¯•ï¼‰
cd /root/clawd && python3 /root/clawd/scripts/search-x-prompts.py

# æŸ¥çœ‹æ‰§è¡Œç»“æœ
ls -lt /root/clawd/data/x-scraping/
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæç¤ºè¯è½¬æ¢

### 3.1 æç¤ºè¯åˆ° Skill çš„è‡ªåŠ¨è½¬æ¢æµç¨‹

#### 3.1.1 Skill ç»“æ„è¯´æ˜

**æ ‡å‡† Skill ç›®å½•ç»“æ„**ï¼š

```
skill-name/
â”œâ”€â”€ SKILL.md           # ä¸»æ–‡æ¡£ï¼ˆå¿…éœ€ï¼‰
â”œâ”€â”€ README.md          # ç®€ä»‹ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ examples/          # ç¤ºä¾‹ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ example1.md
â”‚   â””â”€â”€ example2.md
â”œâ”€â”€ references/        # å‚è€ƒèµ„æ–™ï¼ˆå¯é€‰ï¼‰
â”‚   â””â”€â”€ prompts.md
â”œâ”€â”€ config/            # é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
â”‚   â””â”€â”€ settings.yaml
â””â”€â”€ package.json       # å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
```

**SKILL.md æ¨¡æ¿**ï¼š

```markdown
# Skill åç§°

ç®€çŸ­æè¿°ï¼ˆ1-2å¥ï¼‰

## æè¿°
è¯¦ç»†æè¿° Skill çš„åŠŸèƒ½å’Œç”¨é€”

## ç±»åˆ«
[category]

## ä½¿ç”¨æ–¹æ³•
è¯¦ç»†æ­¥éª¤...

## ç¤ºä¾‹
[examples]

## æœ€ä½³å®è·µ
[best practices]

## ä¾èµ–
[dependencies]

## æ•°æ®æº
- æ¥æº: [source]
- åŸå§‹é“¾æ¥: [url]
- ä½œè€…: [author]
- é‡‡é›†æ—¶é—´: [date]
```

#### 3.1.2 è‡ªåŠ¨è½¬æ¢è„šæœ¬

**è½¬æ¢è„šæœ¬**ï¼š`convert-prompt-to-skill.py`

```python
#!/usr/bin/env python3
import json
import os
import re
from datetime import datetime
import shutil

# Skill æ¨¡æ¿
SKILL_TEMPLATE = """# {skill_name}

{short_description}

## æè¿°
{description}

## ç±»åˆ«
{category}

## è¯„åˆ†
æ€»åˆ†: {total_score}/100 ({grade})

## ä½¿ç”¨æ–¹æ³•
{usage}

## ç¤ºä¾‹
{examples}

## æœ€ä½³å®è·µ
{best_practices}

## æ•°æ®æº
- æ¥æº: {source}
- åŸå§‹é“¾æ¥: {url}
- ä½œè€…: {author}
- é‡‡é›†æ—¶é—´: {collected_at}
- è¯„åˆ†æ—¶é—´: {evaluated_at}
"""

README_TEMPLATE = """# {skill_name}

{short_description}

## å®‰è£…

```bash
clawdhub install {skill_slug}
```

## å¿«é€Ÿå¼€å§‹

{quick_start}

## æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ [SKILL.md](./SKILL.md)

## è´¡çŒ®

æ­¤ Skill ç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œæ¥æºäºï¼š
- åŸå§‹æ¥æº: {source}
- åŸå§‹é“¾æ¥: {url}

## è®¸å¯

MIT License
"""

def generate_skill_name(content):
    """
    ç”Ÿæˆ Skill åç§°
    """
    # æå–å…³é”®è¯
    keywords = re.findall(r'\b\w{4,}\b', content)

    # é€‰æ‹©å‰3ä¸ªå…³é”®è¯
    top_keywords = keywords[:3]

    # ç”Ÿæˆåç§°ï¼ˆkebab-caseï¼‰
    skill_name = '-'.join([kw.lower() for kw in top_keywords])

    return skill_name[:50]  # é™åˆ¶é•¿åº¦

def generate_skill_slug(name):
    """
    ç”Ÿæˆ Skill slug
    """
    # å°å†™ï¼Œæ›¿æ¢ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ä¸ºè¿å­—ç¬¦
    slug = re.sub(r'[^a-z0-9]+', '-', name.lower())
    slug = slug.strip('-')

    return slug

def extract_category(content):
    """
    æå–ç±»åˆ«
    """
    content_lower = content.lower()

    # åˆ†ç±»è§„åˆ™
    categories = {
        'coding': ['code', 'python', 'javascript', 'programming', 'debug'],
        'writing': ['write', 'blog', 'article', 'content', 'copy'],
        'analysis': ['analyze', 'data', 'statistics', 'insight'],
        'creative': ['create', 'generate', 'art', 'image', 'design'],
        'education': ['teach', 'learn', 'explain', 'tutorial'],
        'business': ['marketing', 'sales', 'business', 'strategy']
    }

    for category, keywords in categories.items():
        if any(kw in content_lower for kw in keywords):
            return category

    return 'general'

def generate_usage(content):
    """
    ç”Ÿæˆä½¿ç”¨æ–¹æ³•
    """
    usage_lines = []

    # æå–æ­¥éª¤
    steps = re.findall(r'(?:step|æ­¥éª¤)\s*\d*:?\s*([^\n]+)', content, re.IGNORECASE)
    if steps:
        usage_lines.append("### æ­¥éª¤\n")
        for i, step in enumerate(steps, 1):
            usage_lines.append(f"{i}. {step}\n")

    # æå–å‚æ•°
    params = re.findall(r'(?:parameter|å‚æ•°)\s*:?\s*([^\n]+)', content, re.IGNORECASE)
    if params:
        usage_lines.append("### å‚æ•°\n")
        for param in params:
            usage_lines.append(f"- {param}\n")

    return '\n'.join(usage_lines) if usage_lines else content

def generate_examples(content):
    """
    ç”Ÿæˆç¤ºä¾‹
    """
    examples = []

    # æå–ä»£ç å—
    code_blocks = re.findall(r'```[\s\S]*?```', content)
    if code_blocks:
        examples.append("### ä»£ç ç¤ºä¾‹\n")
        examples.extend(code_blocks)
        examples.append("\n")

    # æå– "For example" åçš„å†…å®¹
    for_examples = re.findall(r'(?:for example|ä¾‹å¦‚)[:ï¼š]\s*([^\n]+)', content, re.IGNORECASE)
    if for_examples:
        examples.append("### æ–‡æœ¬ç¤ºä¾‹\n")
        for ex in for_examples:
            examples.append(f"- {ex}\n")

    return '\n'.join(examples) if examples else "æš‚æ— ç¤ºä¾‹"

def generate_best_practices(content):
    """
    ç”Ÿæˆæœ€ä½³å®è·µ
    """
    practices = []

    # é€šç”¨çš„æœ€ä½³å®è·µ
    practices.append("- æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´æç¤ºè¯å‚æ•°")
    practices.append("- æµ‹è¯•å¹¶ä¼˜åŒ–æç¤ºè¯ä»¥è·å¾—æœ€ä½³æ•ˆæœ")
    practices.append("- å‚è€ƒç¤ºä¾‹ä»¥ç†è§£æ­£ç¡®çš„ä½¿ç”¨æ–¹å¼")
    practices.append("- å®šæœŸæ£€æŸ¥æ›´æ–°ä»¥è·å–æ”¹è¿›å’Œä¿®å¤")

    # ä»å†…å®¹ä¸­æå–ç‰¹å®šå»ºè®®
    tips = re.findall(r'(?:tip|å»ºè®®|note)[:ï¼š]\s*([^\n]+)', content, re.IGNORECASE)
    practices.extend(tips)

    return '\n'.join(practices)

def convert_prompt_to_skill(item, output_dir="/root/clawd/generated-skills"):
    """
    è½¬æ¢æç¤ºè¯ä¸º Skill
    """
    # åªè½¬æ¢é«˜åˆ†æç¤ºè¯ï¼ˆâ‰¥70åˆ†ï¼‰
    if item.get('total_score', 0) < 70:
        print(f"â­ï¸  è·³è¿‡ä½åˆ†æç¤ºè¯: {item.get('total_score', 0)}")
        return None

    content = item.get('content', '')
    source = item.get('source', 'unknown')

    # ç”Ÿæˆ Skill åç§°
    skill_name = generate_skill_name(content)
    skill_slug = generate_skill_slug(skill_name)

    # ç”Ÿæˆç›®å½•
    skill_dir = os.path.join(output_dir, skill_slug)
    os.makedirs(skill_dir, exist_ok=True)

    # ç”Ÿæˆ SKILL.md
    skill_md = SKILL_TEMPLATE.format(
        skill_name=skill_name.title(),
        short_description=content[:100] + "...",
        description=content[:500],
        category=extract_category(content),
        total_score=item.get('total_score', 0),
        grade=item.get('grade', 'N/A'),
        usage=generate_usage(content),
        examples=generate_examples(content),
        best_practices=generate_best_practices(content),
        source=source,
        url=item.get('url', 'N/A'),
        author=item.get('author', item.get('author_handle', 'unknown')),
        collected_at=item.get('collected_at', 'N/A'),
        evaluated_at=item.get('evaluated_at', 'N/A')
    )

    with open(os.path.join(skill_dir, 'SKILL.md'), 'w', encoding='utf-8') as f:
        f.write(skill_md)

    # ç”Ÿæˆ README.md
    readme_md = README_TEMPLATE.format(
        skill_name=skill_name.title(),
        short_description=content[:100] + "...",
        skill_slug=skill_slug,
        quick_start=content[:300],
        source=source,
        url=item.get('url', 'N/A')
    )

    with open(os.path.join(skill_dir, 'README.md'), 'w', encoding='utf-8') as f:
        f.write(readme_md)

    # ä¿å­˜åŸå§‹æç¤ºè¯åˆ° references
    refs_dir = os.path.join(skill_dir, 'references')
    os.makedirs(refs_dir, exist_ok=True)

    with open(os.path.join(refs_dir, 'original-prompt.json'), 'w', encoding='utf-8') as f:
        json.dump(item, f, ensure_ascii=False, indent=2)

    print(f"âœ… ç”Ÿæˆ Skill: {skill_slug}")

    return skill_dir

def batch_convert(input_file, output_dir="/root/clawd/generated-skills"):
    """
    æ‰¹é‡è½¬æ¢
    """
    os.makedirs(output_dir, exist_ok=True)

    count = 0
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)

            # è½¬æ¢
            skill_dir = convert_prompt_to_skill(item, output_dir)

            if skill_dir:
                count += 1

    print(f"\nâœ… è½¬æ¢å®Œæˆ: {count} ä¸ª Skills")

if __name__ == "__main__":
    input_file = "/root/clawd/data/evaluation/cleaned-prompts-20260131.jsonl"

    batch_convert(input_file)
```

**æ‰§è¡Œè„šæœ¬**ï¼š

```bash
python3 /root/clawd/scripts/convert-prompt-to-skill.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
â­ï¸  è·³è¿‡ä½åˆ†æç¤ºè¯: 45
â­ï¸  è·³è¿‡ä½åˆ†æç¤ºè¯: 52
âœ… ç”Ÿæˆ Skill: prompt-engineering-guide
âœ… ç”Ÿæˆ Skill: content-creation-assistant
âœ… ç”Ÿæˆ Skill: code-generation-tool

âœ… è½¬æ¢å®Œæˆ: 3 ä¸ª Skills
```

### 3.2 æ‰‹åŠ¨ä¼˜åŒ–å’Œç¼–è¾‘æŠ€å·§

#### 3.2.1 SKILL.md ä¼˜åŒ–

**ä¼˜åŒ–è¦ç‚¹**ï¼š

1. **æ ‡é¢˜æ¸…æ™°**
   - ä½¿ç”¨ç®€æ´ã€æè¿°æ€§çš„æ ‡é¢˜
   - é¿å…è¿‡é•¿çš„æ ‡é¢˜

2. **æè¿°å®Œæ•´**
   - ç¬¬ä¸€æ®µï¼šç®€çŸ­æè¿°ï¼ˆ1-2å¥ï¼‰
   - ç¬¬äºŒæ®µï¼šè¯¦ç»†åŠŸèƒ½è¯´æ˜
   - ç¬¬ä¸‰æ®µï¼šé€‚ç”¨åœºæ™¯

3. **ä½¿ç”¨æ–¹æ³•æ˜ç¡®**
   - åˆ†æ­¥éª¤è¯´æ˜
   - æä¾›å…·ä½“å‘½ä»¤æˆ–ç¤ºä¾‹
   - æ ‡æ³¨å¿…è¦å‚æ•°

4. **ç¤ºä¾‹ä¸°å¯Œ**
   - è‡³å°‘ 2-3 ä¸ªç¤ºä¾‹
   - æ¶µç›–å¸¸è§ä½¿ç”¨åœºæ™¯
   - åŒ…å«é¢„æœŸè¾“å‡º

**ä¼˜åŒ–ç¤ºä¾‹**ï¼š

**ä¼˜åŒ–å‰**ï¼š
```markdown
# Content Writer

Write content using AI.

## æè¿°
This skill helps you write content.

## ä½¿ç”¨æ–¹æ³•
Just ask it to write.
```

**ä¼˜åŒ–å**ï¼š
```markdown
# Content Writer

ä¸“ä¸šçš„ AI å†…å®¹å†™ä½œåŠ©æ‰‹ï¼Œæ”¯æŒåšå®¢ã€æ–‡ç« ã€è¥é”€æ–‡æ¡ˆç­‰å¤šç§å†…å®¹åˆ›ä½œã€‚

## æè¿°
Content Writer æ˜¯ä¸€ä¸ªåŸºäº AI çš„å†…å®¹åˆ›ä½œå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„æ–‡å­—å†…å®¹ã€‚å®ƒæ”¯æŒå¤šç§å†…å®¹ç±»å‹ï¼ŒåŒ…æ‹¬åšå®¢æ–‡ç« ã€ç¤¾äº¤åª’ä½“æ–‡æ¡ˆã€ç”µå­é‚®ä»¶ã€äº§å“æè¿°ç­‰ã€‚

### ä¸»è¦åŠŸèƒ½
- ğŸ“ åšå®¢æ–‡ç« ç”Ÿæˆ
- ğŸ“§ ç”µå­é‚®ä»¶æ’°å†™
- ğŸ“± ç¤¾äº¤åª’ä½“æ–‡æ¡ˆ
- ğŸ“„ äº§å“æè¿°ä¼˜åŒ–
- ğŸ¯ è¥é”€å†…å®¹åˆ›ä½œ

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨
1. ç¡®è®¤ Skill å·²å®‰è£…
2. åœ¨å¯¹è¯ä¸­ç›´æ¥æå‡ºå†™ä½œéœ€æ±‚
3. æŒ‡å®šå†…å®¹ç±»å‹å’Œé•¿åº¦
4. ç­‰å¾… AI ç”Ÿæˆå†…å®¹

### ç¤ºä¾‹å‘½ä»¤
```
å†™ä¸€ç¯‡å…³äº AI çš„ 500 å­—åšå®¢æ–‡ç« 
å¸®æˆ‘å†™ä¸€å°äº§å“å‘å¸ƒçš„ç”µå­é‚®ä»¶
ä¸º Instagram åˆ›ä½œä¸€æ®µç¾é£Ÿç…§ç‰‡çš„æ–‡æ¡ˆ
```

## ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šåšå®¢æ–‡ç« 
**ç”¨æˆ·è¾“å…¥**ï¼š
```
å†™ä¸€ç¯‡å…³äº"è¿œç¨‹å·¥ä½œä¼˜åŠ¿"çš„ 500 å­—åšå®¢æ–‡ç« 
```

**AI è¾“å‡º**ï¼š
ï¼ˆç”Ÿæˆçš„åšå®¢æ–‡ç« å†…å®¹ï¼‰

### ç¤ºä¾‹ 2ï¼šç”µå­é‚®ä»¶
**ç”¨æˆ·è¾“å…¥**ï¼š
```
å¸®æˆ‘å†™ä¸€å°ç»™å®¢æˆ·çš„æ„Ÿè°¢ä¿¡ï¼Œæ„Ÿè°¢ä»–ä»¬è´­ä¹°æˆ‘ä»¬çš„äº§å“
```

**AI è¾“å‡º**ï¼š
ï¼ˆç”Ÿæˆçš„ç”µå­é‚®ä»¶å†…å®¹ï¼‰

## æœ€ä½³å®è·µ
- ğŸ“Œ æ˜ç¡®æŒ‡å®šå†…å®¹ç±»å‹å’Œé•¿åº¦
- ğŸ“Œ æä¾›è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- ğŸ“Œ å¯ä»¥è¦æ±‚ AI ä½¿ç”¨ç‰¹å®šé£æ ¼ï¼ˆæ­£å¼ã€å¹½é»˜ã€ä¸“ä¸šç­‰ï¼‰
- ğŸ“Œ å¯¹ç”Ÿæˆçš„å†…å®¹è¿›è¡Œäººå·¥å®¡æ ¸å’Œä¿®æ”¹
- ğŸ“Œ å¤šæ¬¡è¿­ä»£ä¼˜åŒ–å†…å®¹è´¨é‡
```

#### 3.2.2 æ·»åŠ ä¾èµ–å’Œé…ç½®

**æ·»åŠ  config/settings.yaml**ï¼š

```yaml
# Content Writer é…ç½®

# é»˜è®¤è®¾ç½®
defaults:
  content_type: "blog"      # é»˜è®¤å†…å®¹ç±»å‹
  word_count: 500            # é»˜è®¤å­—æ•°
  tone: "professional"       # é»˜è®¤è¯­æ°”

# å†…å®¹ç±»å‹
content_types:
  blog:
    word_count: 500-1000
    tone: professional
  social_media:
    word_count: 50-200
    tone: casual
  email:
    word_count: 200-500
    tone: professional

# è¯­æ°”é€‰é¡¹
tones:
  professional: "ä¸“ä¸šã€æ­£å¼"
  casual: "è½»æ¾ã€å‹å¥½"
  humorous: "å¹½é»˜ã€æœ‰è¶£"
  creative: "åˆ›æ„ã€ç‹¬ç‰¹"
```

**æ·»åŠ  package.json**ï¼š

```json
{
  "name": "content-writer",
  "version": "1.0.0",
  "description": "ä¸“ä¸šçš„ AI å†…å®¹å†™ä½œåŠ©æ‰‹",
  "category": "writing",
  "author": "Clawdbot Community",
  "license": "MIT",
  "dependencies": [],
  "keywords": [
    "writing",
    "content",
    "blog",
    "email",
    "social-media"
  ],
  "rating": {
    "score": 85,
    "grade": "A"
  },
  "data_source": {
    "platform": "twitter",
    "url": "https://twitter.com/i/web/status/1234567890",
    "author": "@username",
    "collected_at": "2026-01-31T10:00:00Z"
  }
}
```

### 3.3 SKILL.md æœ€ä½³å®è·µ

#### 3.3.1 ç»“æ„æœ€ä½³å®è·µ

**æ ‡å‡†ç»“æ„**ï¼š

```markdown
# [Skill åç§°]

[ç®€çŸ­æè¿°ï¼Œ1-2å¥è¯]

## æè¿°
[è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬åŠŸèƒ½ã€ç”¨é€”ã€é€‚ç”¨åœºæ™¯]

## ç±»åˆ«
[category]

## è¯„åˆ†
æ€»åˆ†: [score]/100 ([grade])

## ä½¿ç”¨æ–¹æ³•
[åˆ†æ­¥éª¤è¯´æ˜ï¼ŒåŒ…æ‹¬å‘½ä»¤ç¤ºä¾‹]

## ç¤ºä¾‹
[è‡³å°‘2-3ä¸ªç¤ºä¾‹ï¼Œæ¶µç›–å¸¸è§åœºæ™¯]

## æœ€ä½³å®è·µ
[ä½¿ç”¨æŠ€å·§ã€æ³¨æ„äº‹é¡¹]

## ä¾èµ–
[å¦‚æœæœ‰ä¾èµ–ï¼Œåˆ—å‡ºä¾èµ–é¡¹]

## æ•°æ®æº
- æ¥æº: [source]
- åŸå§‹é“¾æ¥: [url]
- ä½œè€…: [author]
- é‡‡é›†æ—¶é—´: [date]
```

#### 3.3.2 å†…å®¹æœ€ä½³å®è·µ

**1. ç®€æ´æ˜äº†**
- ä½¿ç”¨ç®€æ´çš„è¯­è¨€
- é¿å…å†—é•¿çš„æè¿°
- ç›´æ¥ç»™å‡ºè§£å†³æ–¹æ¡ˆ

**2. ç¤ºä¾‹ä¸°å¯Œ**
- æä¾›å…·ä½“çš„å‘½ä»¤ç¤ºä¾‹
- å±•ç¤ºé¢„æœŸè¾“å‡º
- æ¶µç›–å¸¸è§ä½¿ç”¨åœºæ™¯

**3. ç»“æ„æ¸…æ™°**
- ä½¿ç”¨æ¸…æ™°çš„å±‚çº§ç»“æ„
- ä½¿ç”¨åˆ—è¡¨å’Œè¡¨æ ¼
- æ·»åŠ é€‚å½“çš„åˆ†éš”ç¬¦

**4. é”™è¯¯å¤„ç†**
- è¯´æ˜å¸¸è§çš„é”™è¯¯
- æä¾›è§£å†³æ–¹æ¡ˆ
- ç»™å‡ºè°ƒè¯•æŠ€å·§

#### 3.3.3 ç‰ˆæœ¬æ§åˆ¶æœ€ä½³å®è·µ

**ä½¿ç”¨ Git ç®¡ç†**ï¼š

```bash
# åˆå§‹åŒ– Git ä»“åº“
cd /root/clawd/generated-skills/skill-name
git init

# æ·»åŠ æ‰€æœ‰æ–‡ä»¶
git add .

# æäº¤
git commit -m "Initial commit: Content Writer Skill v1.0.0"

# æ·»åŠ è¿œç¨‹ä»“åº“
git remote add origin https://github.com/your-username/your-repo.git

# æ¨é€
git push -u origin master
```

**ç‰ˆæœ¬å·ç®¡ç†**ï¼š

```json
{
  "version": "1.0.0",
  "changelog": [
    {
      "version": "1.0.0",
      "date": "2026-01-31",
      "changes": [
        "åˆå§‹ç‰ˆæœ¬å‘å¸ƒ",
        "åŸºäº Twitter æç¤ºè¯è‡ªåŠ¨ç”Ÿæˆ"
      ]
    }
  ]
}
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šå‘å¸ƒåˆ° ClawdHub

### 4.1 æ‰“åŒ…å’Œæ ¼å¼åŒ–

#### 4.1.1 æ‰“åŒ…ä¸º .skill æ–‡ä»¶

**æ‰“åŒ…è„šæœ¬**ï¼š`pack-skill.sh`

```bash
#!/bin/bash

SKILL_DIR="$1"
OUTPUT_DIR="/root/clawd/packed-skills"

if [ -z "$SKILL_DIR" ]; then
    echo "Usage: $0 <skill-directory>"
    exit 1
fi

if [ ! -d "$SKILL_DIR" ]; then
    echo "Error: Directory $SKILL_DIR does not exist"
    exit 1
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$OUTPUT_DIR"

# è·å– Skill åç§°
SKILL_NAME=$(basename "$SKILL_DIR")

# æ‰“åŒ…ä¸º .skill æ–‡ä»¶
tar -czf "$OUTPUT_DIR/$SKILL_NAME.skill" -C "$SKILL_DIR" .

echo "âœ… æ‰“åŒ…å®Œæˆ: $OUTPUT_DIR/$SKILL_NAME.skill"
```

**æ‰§è¡Œæ‰“åŒ…**ï¼š

```bash
# æ·»åŠ æ‰§è¡Œæƒé™
chmod +x /root/clawd/scripts/pack-skill.sh

# æ‰“åŒ…æ‰€æœ‰ Skills
for skill_dir in /root/clawd/generated-skills/*/; do
    bash /root/clawd/scripts/pack-skill.sh "$skill_dir"
done

# æŸ¥çœ‹æ‰“åŒ…ç»“æœ
ls -lh /root/clawd/packed-skills/
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ… æ‰“åŒ…å®Œæˆ: /root/clawd/packed-skills/content-writer.skill (4.2KB)
âœ… æ‰“åŒ…å®Œæˆ: /root/clawd/packed-skills/prompt-engineering-guide.skill (5.1KB)
âœ… æ‰“åŒ…å®Œæˆ: /root/clawd/packed-skills/code-generation-tool.skill (3.8KB)
```

#### 4.1.2 æ ¼å¼éªŒè¯

**éªŒè¯è„šæœ¬**ï¼š`validate-skill.sh`

```bash
#!/bin/bash

SKILL_DIR="$1"

if [ -z "$SKILL_DIR" ]; then
    echo "Usage: $0 <skill-directory>"
    exit 1
fi

# æ£€æŸ¥å¿…éœ€æ–‡ä»¶
if [ ! -f "$SKILL_DIR/SKILL.md" ]; then
    echo "âŒ é”™è¯¯: ç¼ºå°‘ SKILL.md"
    exit 1
fi

# æ£€æŸ¥æ–‡ä»¶å¤§å°
if [ $(stat -f%z "$SKILL_DIR/SKILL.md" 2>/dev/null || stat -c%s "$SKILL_DIR/SKILL.md") -lt 100 ]; then
    echo "âŒ é”™è¯¯: SKILL.md å¤ªå°ï¼ˆ<100 å­—èŠ‚ï¼‰"
    exit 1
fi

echo "âœ… æ ¼å¼éªŒè¯é€šè¿‡: $SKILL_DIR"
```

**æ‰§è¡ŒéªŒè¯**ï¼š

```bash
chmod +x /root/clawd/scripts/validate-skill.sh

# éªŒè¯æ‰€æœ‰ Skills
for skill_dir in /root/clawd/generated-skills/*/; do
    bash /root/clawd/scripts/validate-skill.sh "$skill_dir"
done
```

### 4.2 ClawdHub CLI ä½¿ç”¨

#### 4.2.1 å®‰è£… ClawdHub CLI

```bash
# ä½¿ç”¨ ClawdHub Skill
clawdhub install clawdhub

# æˆ–è€…å…¨å±€å®‰è£…
npm install -g @clawdhub/cli
```

#### 4.2.2 ç™»å½• ClawdHub

```bash
# ç™»å½•
clawdhub login

# è¾“å…¥ tokenï¼ˆä» https://clawdhub.com è·å–ï¼‰
```

#### 4.2.3 å‘å¸ƒ Skill

**å‘å¸ƒå•ä¸ª Skill**ï¼š

```bash
# å‘å¸ƒ
clawdhub publish /root/clawd/packed-skills/content-writer.skill \
    --slug "content-writer" \
    --version "1.0.0" \
    --name "Content Writer" \
    --description "ä¸“ä¸šçš„ AI å†…å®¹å†™ä½œåŠ©æ‰‹" \
    --category "writing" \
    --price "4.99" \
    --changelog "Initial release"
```

**æ‰¹é‡å‘å¸ƒ**ï¼š

```bash
#!/bin/bash

# æ‰¹é‡å‘å¸ƒè„šæœ¬
for skill_file in /root/clawd/packed-skills/*.skill; do
    slug=$(basename "$skill_file" .skill)

    # è¯»å– package.json è·å–å…ƒæ•°æ®
    if [ -f "/root/clawd/generated-skills/$slug/package.json" ]; then
        name=$(jq -r '.name' "/root/clawd/generated-skills/$slug/package.json")
        version=$(jq -r '.version' "/root/clawd/generated-skills/$slug/package.json")
        category=$(jq -r '.category' "/root/clawd/generated-skills/$slug/package.json")
        description=$(jq -r '.description' "/root/clawd/generated-skills/$slug/package.json")
        score=$(jq -r '.rating.score' "/root/clawd/generated-skills/$slug/package.json")

        # æ ¹æ®è¯„åˆ†å®šä»·
        if [ "$score" -ge 90 ]; then
            price="9.99"
        elif [ "$score" -ge 85 ]; then
            price="4.99"
        elif [ "$score" -ge 80 ]; then
            price="2.99"
        elif [ "$score" -ge 70 ]; then
            price="1.99"
        elif [ "$score" -ge 60 ]; then
            price="0.99"
        else
            price="0.00"
        fi

        # å‘å¸ƒ
        clawdhub publish "$skill_file" \
            --slug "$slug" \
            --version "$version" \
            --name "$name" \
            --description "$description" \
            --category "$category" \
            --price "$price" \
            --changelog "Auto-generated from prompt collection"

        echo "âœ… å‘å¸ƒå®Œæˆ: $slug (ä»·æ ¼: $price)"
    fi
done
```

**æ‰§è¡Œæ‰¹é‡å‘å¸ƒ**ï¼š

```bash
chmod +x /root/clawd/scripts/batch-publish.sh
bash /root/clawd/scripts/batch-publish.sh
```

#### 4.2.4 ç®¡ç†å·²å‘å¸ƒçš„ Skills

**æŸ¥çœ‹å·²å‘å¸ƒçš„ Skills**ï¼š

```bash
clawdhub list
```

**æ›´æ–° Skill**ï¼š

```bash
clawdhub update content-writer \
    --version "1.1.0" \
    --changelog "ä¼˜åŒ–äº†å†…å®¹ç”Ÿæˆçš„è´¨é‡"
```

**ä¸‹æ¶ Skill**ï¼š

```bash
clawdhub unpublish content-writer
```

### 4.3 å®šä»·ç­–ç•¥åº”ç”¨

#### 4.3.1 å®šä»·çŸ©é˜µ

| è¯„åˆ† | åˆ†æ•°èŒƒå›´ | å®šä»· | ç­–ç•¥ |
|------|---------|------|------|
| A+ | 90-100 | $9.99 | é«˜ç«¯å®šä»·ï¼Œä¼˜è´¨å†…å®¹ |
| A | 85-89 | $4.99 | ä¸­é«˜ç«¯ï¼Œä¸“ä¸šå†…å®¹ |
| B+ | 80-84 | $2.99 | ä¸­ç«¯ï¼Œå®ç”¨å†…å®¹ |
| B | 70-79 | $1.99 | å…¥é—¨ï¼ŒåŸºç¡€å†…å®¹ |
| C+ | 60-69 | $0.99 | ä½ä»·ï¼Œè¡¥å……å†…å®¹ |
| C | 50-59 | å…è´¹ | å…è´¹ï¼Œå¼•æµå†…å®¹ |
| D | 0-49 | ä¸å‘å¸ƒ | ä½è´¨é‡ï¼Œä¸æ”¶å½• |

#### 4.3.2 åŠ¨æ€å®šä»·ç­–ç•¥

**æ ¹æ®å¸‚åœºåé¦ˆè°ƒæ•´ä»·æ ¼**ï¼š

```python
#!/usr/bin/env python3
import json
import requests

def get_sales_data(skill_slug):
    """
    è·å–é”€å”®æ•°æ®ï¼ˆå‡è®¾ ClawdHub æä¾› APIï¼‰
    """
    response = requests.get(f"https://api.clawdhub.com/skills/{skill_slug}/sales")
    return response.json()

def adjust_price(skill_slug, current_sales, current_price):
    """
    æ ¹æ®é”€å”®æ•°æ®è°ƒæ•´ä»·æ ¼
    """
    # é”€é‡ä½ï¼Œé™ä»·ä¿ƒé”€
    if current_sales < 10:
        new_price = max(current_price * 0.8, 0.99)
        return new_price

    # é”€é‡é«˜ï¼Œä¿æŒä»·æ ¼
    if current_sales > 50:
        return current_price

    # æ­£å¸¸é”€é‡ï¼Œä¿æŒåŸä»·
    return current_price

def update_pricing(skill_slug, new_price):
    """
    æ›´æ–°ä»·æ ¼
    """
    response = requests.put(
        f"https://api.clawdhub.com/skills/{skill_slug}/price",
        json={"price": new_price}
    )

    if response.status_code == 200:
        print(f"âœ… ä»·æ ¼å·²æ›´æ–°: {skill_slug} - ${new_price:.2f}")
    else:
        print(f"âŒ æ›´æ–°å¤±è´¥: {skill_slug}")

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šæ›´æ–°æ‰€æœ‰å·²å‘å¸ƒ Skills çš„ä»·æ ¼
    skills = ["content-writer", "prompt-engineering-guide", "code-generation-tool"]

    for skill in skills:
        sales_data = get_sales_data(skill)
        current_price = sales_data.get('price', 4.99)
        current_sales = sales_data.get('sales', 0)

        new_price = adjust_price(skill, current_sales, current_price)

        if new_price != current_price:
            update_pricing(skill, new_price)
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šç»éªŒæ•™è®­

### 5.1 æ•°æ®è´¨é‡é™·é˜±

#### 5.1.1 å¸¸è§é™·é˜±

**é™·é˜± 1ï¼šè¿‡åº¦ä¾èµ–è‡ªåŠ¨åŒ–**
- **é—®é¢˜**ï¼šå®Œå…¨ä¾èµ–è‡ªåŠ¨æå–ï¼Œå¯¼è‡´å¤§é‡ä½è´¨é‡å†…å®¹
- **æ•™è®­**ï¼šè‡ªåŠ¨åŒ–æ˜¯è¾…åŠ©ï¼Œä¸æ˜¯æ›¿ä»£ã€‚å®šæœŸäººå·¥æŠ½æŸ¥ 10-20 æ¡ç»“æœã€‚

**é™·é˜± 2ï¼šå¿½è§†æ¸…æ´—**
- **é—®é¢˜**ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ï¼ŒåŒ…å«å¤§é‡å™ªéŸ³
- **æ•™è®­**ï¼šæ•°æ®æ¸…æ´—æ¯”æ•°æ®æ”¶é›†æ›´é‡è¦ã€‚å»ºç«‹ä¸¥æ ¼çš„è¿‡æ»¤è§„åˆ™ã€‚

**é™·é˜± 3ï¼šå•ä¸€æ•°æ®æº**
- **é—®é¢˜**ï¼šåªä¾èµ– Twitter æˆ– Redditï¼Œæ•°æ®é‡æœ‰é™
- **æ•™è®­**ï¼šå¤šæ•°æ®æºæ•´åˆï¼ˆTwitterã€Redditã€GitHubã€SearXNG ç­‰ï¼‰ã€‚

**é™·é˜± 4ï¼šå¿½ç•¥ä¸Šä¸‹æ–‡**
- **é—®é¢˜**ï¼šæå–æç¤ºè¯æ—¶ä¸¢å¤±äº†é‡è¦ä¸Šä¸‹æ–‡
- **æ•™è®­**ï¼šä¿ç•™åŸå§‹æ¥æºé“¾æ¥å’Œå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œä¾¿äºéªŒè¯ã€‚

#### 5.1.2 è§£å†³æ–¹æ¡ˆ

**è§£å†³æ–¹æ¡ˆ 1ï¼šå»ºç«‹è´¨é‡ç›‘æ§**
```bash
# æ¯å‘¨äººå·¥æŠ½æŸ¥ 50 æ¡æ•°æ®
python3 /root/clawd/scripts/weekly-quality-check.py
```

**è§£å†³æ–¹æ¡ˆ 2ï¼šå¤šè½®æ¸…æ´—**
```bash
# ç¬¬ä¸€è½®ï¼šè¿‡æ»¤æ˜æ˜¾åƒåœ¾å†…å®¹
python3 /root/clawd/scripts/clean-prompts.py

# ç¬¬äºŒè½®ï¼šå»é‡
python3 /root/clawd/scripts/deduplicate-prompts.py

# ç¬¬ä¸‰è½®ï¼šAI è¯­ä¹‰è¯„ä¼°
python3 /root/clawd/scripts/ai-evaluate-prompts.py
```

**è§£å†³æ–¹æ¡ˆ 3ï¼šæ•°æ®æºä¼˜å…ˆçº§**
```yaml
data_sources:
  tier1:  # é«˜è´¨é‡
    - github
    - promptbase
  tier2:  # ä¸­ç­‰è´¨é‡
    - reddit
    - searxng
  tier3:  # è¡¥å……
    - twitter
```

### 5.2 API é™åˆ¶è§£å†³æ–¹æ¡ˆ

#### 5.2.1 Twitter API é™åˆ¶

**é—®é¢˜**ï¼š
- å…è´¹è®¡åˆ’ï¼šæ¯æœˆ 500,000 æ¡æ¨æ–‡
- æ¯ 15 åˆ†é’Ÿï¼š300 æ¡è¯·æ±‚
- è¶…é™è¿”å› 429 é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨å¤šä¸ª API Key**
```python
TWITTER_API_KEYS = [
    "key1",
    "key2",
    "key3"
]

current_key_index = 0

def get_next_api_key():
    global current_key_index
    key = TWITTER_API_KEYS[current_key_index]
    current_key_index = (current_key_index + 1) % len(TWITTER_API_KEYS)
    return key
```

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ RSS ç«¯ç‚¹ï¼ˆNitterï¼‰**
```python
import feedparser

# Nitter å®ä¾‹
NITTER_INSTANCES = [
    "https://nitter.net",
    "https://nitter.poast.org",
    "https://nitter.fdn.fr"
]

def fetch_twitter_rss(query):
    """
    ä½¿ç”¨ Nitter RSS ç«¯ç‚¹
    """
    url = f"{NITTER_INSTANCES[0]}/search?q={query}&f=tweets&src=typed_query"

    try:
        feed = feedparser.parse(url)
        return feed.entries
    except Exception as e:
        print(f"âŒ RSS è·å–å¤±è´¥: {str(e)}")
        return []
```

**æ–¹æ¡ˆ 3ï¼šç¼“å­˜å’Œå»é‡**
```python
import hashlib
import json
import os

CACHE_DIR = "/root/clawd/cache/twitter"

def get_cached_result(query):
    """
    è·å–ç¼“å­˜ç»“æœ
    """
    cache_file = os.path.join(CACHE_DIR, hashlib.md5(query).hexdigest() + ".json")

    if os.path.exists(cache_file):
        # æ£€æŸ¥ç¼“å­˜æ—¶é—´ï¼ˆ24å°æ—¶æœ‰æ•ˆæœŸï¼‰
        age = time.time() - os.path.getmtime(cache_file)
        if age < 86400:
            with open(cache_file) as f:
                return json.load(f)

    return None

def cache_result(query, data):
    """
    ç¼“å­˜ç»“æœ
    """
    os.makedirs(CACHE_DIR, exist_ok=True)
    cache_file = os.path.join(CACHE_DIR, hashlib.md5(query).hexdigest() + ".json")

    with open(cache_file, 'w') as f:
        json.dump(data, f)
```

#### 5.2.2 Reddit API é™åˆ¶

**é—®é¢˜**ï¼š
- è®¤è¯ç”¨æˆ·ï¼š60 è¯·æ±‚/åˆ†é’Ÿ
- æœªè®¤è¯ï¼š30 è¯·æ±‚/åˆ†é’Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨å¤šä¸ªè´¦æˆ·**
```python
REDDIT_ACCOUNTS = [
    {"client_id": "id1", "client_secret": "secret1"},
    {"client_id": "id2", "client_secret": "secret2"}
]
```

**æ–¹æ¡ˆ 2ï¼šé™æµ**
```python
import time

def rate_limit_delay():
    """
    é™æµå»¶è¿Ÿ
    """
    # 60 è¯·æ±‚/åˆ†é’Ÿ = 1 è¯·æ±‚/ç§’
    time.sleep(1)
```

### 5.3 è‡ªåŠ¨åŒ–è¾¹ç•Œ

#### 5.3.1 ä»€ä¹ˆæ—¶å€™éœ€è¦äººå·¥ä»‹å…¥ï¼Ÿ

**éœ€è¦äººå·¥ä»‹å…¥çš„æƒ…å†µ**ï¼š

1. **è´¨é‡è¯„ä¼°**
   - è¯„åˆ†åœ¨ 60-70 ä¹‹é—´çš„æç¤ºè¯
   - AI è¯„ä¼°ç»“æœä¸æ˜ç¡®çš„å†…å®¹
   - äº‰è®®æ€§æˆ–æ•æ„Ÿå†…å®¹

2. **Skill è½¬æ¢**
   - å¤æ‚çš„å¤šæ­¥éª¤æç¤ºè¯
   - éœ€è¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†çš„æç¤ºè¯
   - åŒ…å«ä»£ç æˆ–é…ç½®æ–‡ä»¶çš„æç¤ºè¯

3. **å‘å¸ƒå†³ç­–**
   - è¯„åˆ†ä½äº 60 çš„å†…å®¹æ˜¯å¦å‘å¸ƒ
   - äº‰è®®æ€§å†…å®¹æ˜¯å¦å‘å¸ƒ
   - é‡å¤å†…å®¹å¦‚ä½•å¤„ç†

4. **å®šä»·ç­–ç•¥**
   - ç‰¹æ®ŠæŠ€èƒ½çš„å®šä»·
   - ä¿ƒé”€æ´»åŠ¨çš„å†³ç­–
   - å¸‚åœºåé¦ˆåçš„ä»·æ ¼è°ƒæ•´

#### 5.3.2 äººå·¥å®¡æ ¸æµç¨‹

**æ­¥éª¤ 1ï¼šç­›é€‰éœ€è¦å®¡æ ¸çš„å†…å®¹**

```bash
# ç­›é€‰ 60-70 åˆ†çš„æç¤ºè¯
jq -r 'select(.total_score >= 60 and .total_score < 70)' \
    /root/clawd/data/evaluation/scored-prompts-20260131.jsonl > \
    /root/clawd/data/needs-review.jsonl
```

**æ­¥éª¤ 2ï¼šäººå·¥å®¡æ ¸**

```bash
# æŸ¥çœ‹éœ€è¦å®¡æ ¸çš„å†…å®¹
cat /root/clawd/data/needs-review.jsonl | jq -r '.content' | less
```

**æ­¥éª¤ 3ï¼šè®°å½•å®¡æ ¸ç»“æœ**

```json
{
  "content": "æç¤ºè¯å†…å®¹",
  "total_score": 65,
  "human_review": {
    "approved": true,
    "reason": "è™½ç„¶è¯„åˆ†ä¸é«˜ï¼Œä½†å†…å®¹å®ç”¨",
    "adjustments": {
      "total_score": 70,
      "grade": "B"
    },
    "reviewer": "jack happy",
    "reviewed_at": "2026-01-31T10:00:00Z"
  }
}
```

---

## é™„å½•ï¼šå¸¸è§é—®é¢˜

### Q1: Twitter API é€Ÿç‡é™åˆ¶æ€ä¹ˆåŠï¼Ÿ

**A**: æœ‰å‡ ç§è§£å†³æ–¹æ¡ˆï¼š

1. **å‡çº§ä»˜è´¹è®¡åˆ’**ï¼šè·å¾—æ›´é«˜çš„ API é…é¢
2. **ä½¿ç”¨å¤šä¸ª API Key**ï¼šè½®æ¢ä½¿ç”¨ä¸åŒçš„ key
3. **ä½¿ç”¨ RSS ç«¯ç‚¹**ï¼šé€šè¿‡ Nitter å®ä¾‹è·å–æ•°æ®ï¼ˆæ—  API key é™åˆ¶ï¼‰
4. **ç¼“å­˜å’Œå»é‡**ï¼šé¿å…é‡å¤è¯·æ±‚ç›¸åŒçš„å†…å®¹

### Q2: å¦‚ä½•æé«˜æ•°æ®è´¨é‡ï¼Ÿ

**A**:

1. **å¤šè½®æ¸…æ´—**ï¼šè¿‡æ»¤ã€å»é‡ã€AI è¯„ä¼°
2. **äººå·¥æŠ½æŸ¥**ï¼šå®šæœŸäººå·¥éªŒè¯ 10-20 æ¡ç»“æœ
3. **å¤šæ•°æ®æº**ï¼šæ•´åˆå¤šä¸ªé«˜è´¨é‡æ•°æ®æº
4. **è°ƒæ•´è¯„åˆ†æƒé‡**ï¼šæ ¹æ®å¸‚åœºåé¦ˆä¼˜åŒ–è¯„åˆ†ç³»ç»Ÿ

### Q3: Skill è½¬æ¢å¤±è´¥ç‡é«˜æ€ä¹ˆåŠï¼Ÿ

**A**:

1. **æé«˜è¯„åˆ†é˜ˆå€¼**ï¼šåªè½¬æ¢ 70 åˆ†ä»¥ä¸Šçš„æç¤ºè¯
2. **ä¼˜åŒ–è½¬æ¢è§„åˆ™**ï¼šæ”¹è¿›æ¨¡æ¿åŒ¹é…å’Œå†…å®¹ç”Ÿæˆ
3. **äººå·¥è¾…åŠ©**ï¼šå¯¹å¤æ‚æç¤ºè¯è¿›è¡Œæ‰‹åŠ¨ä¼˜åŒ–
4. **æŒç»­è¿­ä»£**ï¼šæ ¹æ®è½¬æ¢ç»“æœè°ƒæ•´ç®—æ³•

### Q4: å¦‚ä½•é€‰æ‹©æ•°æ®æºï¼Ÿ

**A**:

**Tier 1ï¼ˆé«˜è´¨é‡ï¼‰**ï¼š
- GitHub awesome ä»“åº“
- ä¸“ä¸šæç¤ºè¯ç½‘ç«™ï¼ˆPromptBaseï¼‰

**Tier 2ï¼ˆä¸­ç­‰è´¨é‡ï¼‰**ï¼š
- Reddit é«˜è´¨é‡å­ç‰ˆå—
- æŠ€æœ¯åšå®¢

**Tier 3ï¼ˆè¡¥å……ï¼‰**ï¼š
- Twitter/X
- SearXNG ç½‘ç»œæœç´¢

### Q5: å¦‚ä½•ç›‘æ§è‡ªåŠ¨åŒ–æµç¨‹ï¼Ÿ

**A**:

1. **æ—¥å¿—è®°å½•**ï¼šæ‰€æœ‰è„šæœ¬éƒ½è¾“å‡ºè¯¦ç»†æ—¥å¿—
2. **é”™è¯¯æŠ¥è­¦**ï¼šå…³é”®å¤±è´¥æ—¶å‘é€é€šçŸ¥ï¼ˆSlack/Feishuï¼‰
3. **å®šæœŸæŠ¥å‘Š**ï¼šç”Ÿæˆæ¯æ—¥/æ¯å‘¨æŠ¥å‘Š
4. **æ‰‹åŠ¨æ£€æŸ¥**ï¼šå®šæœŸäººå·¥æŠ½æŸ¥ç»“æœ

### Q6: å¦‚ä½•å®šä»·ï¼Ÿ

**A**:

æ ¹æ®è¯„åˆ†å®šä»·ï¼š
- A+ (90-100): $9.99
- A (85-89): $4.99
- B+ (80-84): $2.99
- B (70-79): $1.99
- C+ (60-69): $0.99
- C (50-59): å…è´¹
- D (0-49): ä¸å‘å¸ƒ

æ ¹æ®å¸‚åœºåé¦ˆåŠ¨æ€è°ƒæ•´ä»·æ ¼ã€‚

### Q7: å¦‚ä½•é¿å…ç‰ˆæƒé—®é¢˜ï¼Ÿ

**A**:

1. **æ³¨æ˜æ¥æº**ï¼šåœ¨ SKILL.md ä¸­æ³¨æ˜åŸå§‹æ¥æºå’Œä½œè€…
2. **ä¸ç›´æ¥å¤åˆ¶**ï¼šåŸºäºæç¤ºè¯ç”Ÿæˆæ–°çš„ Skillï¼Œè€Œä¸æ˜¯ç›´æ¥å¤åˆ¶
3. **å°Šé‡è®¸å¯**ï¼šæ£€æŸ¥åŸå§‹å†…å®¹çš„è®¸å¯åè®®
4. **ç¤¾åŒºè´¡çŒ®**ï¼šé¼“åŠ±ç”¨æˆ·è´¡çŒ®å’Œåé¦ˆ

### Q8: å¦‚ä½•æå‡ Skill çš„ä¸‹è½½é‡ï¼Ÿ

**A**:

1. **ä¼˜åŒ–æ ‡é¢˜å’Œæè¿°**ï¼šä½¿ç”¨æ¸…æ™°ã€å¸å¼•äººçš„æ ‡é¢˜
2. **æä¾›ä¸°å¯Œçš„ç¤ºä¾‹**ï¼šå±•ç¤º Skill çš„å®é™…æ•ˆæœ
3. **æ”¶é›†ç”¨æˆ·åé¦ˆ**ï¼šæ ¹æ®åé¦ˆæ”¹è¿› Skill
4. **è¥é”€æ¨å¹¿**ï¼šåœ¨ç¤¾äº¤åª’ä½“ã€ç¤¾åŒºæ¨å¹¿ Skill
5. **å…è´¹è¯•ç”¨**ï¼šæä¾›å…è´¹ Skill å¼•æµ

---

## æ€»ç»“

è¿™ä»½å®æˆ˜æ•™ç¨‹æ¶µç›–äº†ä»é›¶å¼€å§‹å»ºç«‹å®Œæ•´çš„ AI æç¤ºè¯å•†ä¸šåŒ–æµç¨‹çš„æ‰€æœ‰å…³é”®æ­¥éª¤ï¼š

1. **æ•°æ®æ”¶é›†**ï¼šå¤šæºé‡‡é›†ï¼ˆTwitterã€Redditã€GitHubã€SearXNGï¼‰
2. **è´¨é‡è¯„ä¼°**ï¼š5 ç»´åº¦è¯„åˆ†ç³»ç»Ÿ + AI è¯­ä¹‰è¯„ä¼°
3. **æç¤ºè¯è½¬æ¢**ï¼šè‡ªåŠ¨è½¬æ¢ä¸º Clawdbot Skill æ ¼å¼
4. **å‘å¸ƒåˆ° ClawdHub**ï¼šæ‰“åŒ…ã€éªŒè¯ã€å‘å¸ƒã€å®šä»·
5. **ç»éªŒæ•™è®­**ï¼šé¿å…å¸¸è§é™·é˜±ï¼Œå¤„ç† API é™åˆ¶ï¼Œäººå·¥ä»‹å…¥è¾¹ç•Œ

**å…³é”®è¦ç‚¹**ï¼š
- âœ… è´¨é‡å¤§äºæ•°é‡
- âœ… è‡ªåŠ¨åŒ–éœ€è¦äººå·¥ç›‘æ§
- âœ… å¤šæ•°æ®æºæ•´åˆæé«˜è´¨é‡
- âœ… æŒç»­è¿­ä»£å’Œä¼˜åŒ–

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼š
1. é…ç½®ç¯å¢ƒï¼ˆAPI keysã€å·¥å…·ï¼‰
2. è¿è¡Œæ•°æ®æ”¶é›†è„šæœ¬
3. è¯„ä¼°å’Œæ¸…æ´—æ•°æ®
4. è½¬æ¢ä¸º Skills
5. å‘å¸ƒåˆ° ClawdHub

ç¥ä½ åœ¨ AI æç¤ºè¯å•†ä¸šåŒ–é“è·¯ä¸Šå–å¾—æˆåŠŸï¼ğŸš€

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¶é—´**: 2026-01-31
**æœ€åæ›´æ–°**: 2026-01-31
**ä½œè€…**: Clawdbot Community
**è®¸å¯**: MIT
