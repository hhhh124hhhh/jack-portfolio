{"prompt": "üìñ [Plugin Documentation](CLAUDE-PLUGIN.md)\n\n### MCP Server\nUse prompts.chat as an MCP server in your AI tools.\n\n**Remote (recommended):**", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.657060", "quality_score": 60}
{"prompt": "Act as [PROMPTS.md](https://raw.githubusercontent.com/f/prompts.chat/main/PROMPTS.md).\n\n[Hugging Face Dataset](https://huggingface.co/datasets/fka/prompts.chat)", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "table", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.657420", "quality_score": 60, "role": "[PROMPTS.md](https://raw.githubusercontent.com/f/prompts.chat/main/PROMPTS.md)"}
{"prompt": ">\n  <sub>formerly known as Awesome ChatGPT Prompts</sub>\n</p>\n\n<p align=", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.658332", "quality_score": 60}
{"prompt": ">\n  <sub><strong>Loved by AI pioneers:</strong></sub><br>\n  <sub>\n    <a href=", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.658526", "quality_score": 60}
{"prompt": "><strong>Thomas Dohmke</strong></a> (Former GitHub CEO)\n  </sub>\n</p>\n\n---\n\n## What is this?\n\nA curated collection of **prompt examples** for AI chat models. Originally created for ChatGPT, these prompts work great with any modern AI assistant.\n\n| Browse Prompts | Data Formats |\n|----------------|--------------|\n| [prompts.chat](https://prompts.chat/prompts) | [prompts.csv](prompts.csv) |\n| [PROMPTS.md](https://raw.githubusercontent.com/f/prompts.chat/main/PROMPTS.md) | [Hugging Face Dataset](https://huggingface.co/datasets/fka/prompts.chat) |\n\n**Want to contribute?** Add prompts at [prompts.chat/prompts/new](https://prompts.chat/prompts/new) ‚Äî they sync here automatically.\n\n---\n\n## üìñ The Interactive Book of Prompting\n\nLearn prompt engineering with our **free, interactive guide** ‚Äî 25+ chapters covering everything from basics to advanced techniques like chain-of-thought reasoning, few-shot learning, and AI agents.\n\n**[Start Reading ‚Üí](https://fka.gumroad.com/l/art-of-chatgpt-prompting)**\n\n---\n\n## üéÆ Prompting for Kids\n\n<p>\n  <a href=", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.658842", "quality_score": 60}
{"prompt": ">\n    </picture>\n  </a>\n</p>\n\nAn interactive, game-based adventure to teach children (ages 8-14) how to communicate with AI through fun puzzles and stories.\n\n**[Start Playing ‚Üí](https://prompts.chat/kids)**\n\n<br clear=", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.658922", "quality_score": 60}
{"prompt": ">\n\n---\n\n## üöÄ Self-Hosting\n\nDeploy your own private prompt library with custom branding, themes, and authentication.\n\n**Quick Start:**\n```bash\nnpx prompts.chat new my-prompt-library\ncd my-prompt-library\n```\n\n**Manual Setup:**\n```bash\ngit clone https://github.com/f/prompts.chat.git\ncd prompts.chat\nnpm install && npm run setup\n```\n\nThe setup wizard configures branding, theme, authentication (GitHub/Google/Azure AD), and features.\n\nüìñ **[Full Self-Hosting Guide](SELF-HOSTING.md)** ‚Ä¢ üê≥ **[Docker Guide](DOCKER.md)**\n\n---\n\n## üîå Integrations\n\n### CLI\n```bash\nnpx prompts.chat\n```\n\n### Claude Code Plugin\n```\n/plugin marketplace add f/prompts.chat\n/plugin install prompts.chat@prompts.chat\n```\nüìñ [Plugin Documentation](CLAUDE-PLUGIN.md)\n\n### MCP Server\nUse prompts.chat as an MCP server in your AI tools.\n\n**Remote (recommended):**\n```json\n{", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.659091", "quality_score": 60}
{"prompt": "]\n    }\n  }\n}\n```\n\nüìñ [MCP Documentation](https://prompts.chat/docs/api)\n\n---\n\n## üíñ Sponsors\n\n<p align=", "source": "GitHub", "repository": "f/awesome-chatgpt-prompts", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:29.659144", "quality_score": 60}
{"prompt": "@article{Saravia_Prompt_Engineering_Guide_2022,\nauthor = {Saravia, Elvis},\njournal = {https://github.com/dair-ai/Prompt-Engineering-Guide},\nmonth = {12},\ntitle = {{Prompt Engineering Guide}},\nyear = {2022}\n}", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.662484", "quality_score": 60}
{"prompt": "üéì We now offer self-paced prompt engineering courses under our DAIR.AI Academy. [Join Now](https://academy.dair.ai/pricing)!", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.662979", "quality_score": 60}
{"prompt": "üéì New course on Prompt Engineering for LLMs announced! [Enroll here](https://academy.dair.ai/courses/introduction-prompt-engineering)!", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663031", "quality_score": 60}
{"prompt": "üíº We now offer several [services](https://www.promptingguide.ai/services) like corporate training, consulting, and talks.", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663079", "quality_score": 60}
{"prompt": "üéâ We have launched a new web version of the guide [here](https://www.promptingguide.ai/)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663193", "quality_score": 60}
{"prompt": "üéâ The First Prompt Engineering Lecture went live [here](https://youtu.be/dOxUroR57xs)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663270", "quality_score": 60}
{"prompt": "[Prompt Engineering - Introduction](https://www.promptingguide.ai/introduction)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663308", "quality_score": 60}
{"prompt": "[Prompt Engineering - Techniques](https://www.promptingguide.ai/techniques)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663345", "quality_score": 60}
{"prompt": "[Prompt Engineering - Applications](https://www.promptingguide.ai/applications)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663382", "quality_score": 60}
{"prompt": "[Prompt Engineering - Prompt Hub](https://www.promptingguide.ai/prompts)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663419", "quality_score": 60}
{"prompt": "[Prompt Engineering - Models](https://www.promptingguide.ai/models)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663455", "quality_score": 60}
{"prompt": "[Prompt Engineering - Risks and Misuses](https://www.promptingguide.ai/risks)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663493", "quality_score": 60}
{"prompt": "[Prompt Engineering - Papers](https://www.promptingguide.ai/papers)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663529", "quality_score": 60}
{"prompt": "[Prompt Engineering - Tools](https://www.promptingguide.ai/tools)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663580", "quality_score": 60}
{"prompt": "[Prompt Engineering - Notebooks](https://www.promptingguide.ai/notebooks)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663616", "quality_score": 60}
{"prompt": "[Prompt Engineering - Datasets](https://www.promptingguide.ai/datasets)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663652", "quality_score": 60}
{"prompt": "[Prompt Engineering - Additional Readings](https://www.promptingguide.ai/readings)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663690", "quality_score": 60}
{"prompt": "[Video Lecture](https://youtu.be/dOxUroR57xs)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663723", "quality_score": 60}
{"prompt": "[Notebook with code](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-lecture.ipynb)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663769", "quality_score": 60}
{"prompt": "[Slides](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/lecture/Prompt-Engineering-Lecture-Elvis.pdf)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663816", "quality_score": 60}
{"prompt": "Wall Street Journal - [ChatGPT Can Give Great Answers. But Only If You Know How to Ask the Right Question](https://www.wsj.com/articles/chatgpt-ask-the-right-question-12d0f035)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663855", "quality_score": 60}
{"prompt": "Forbes - [Mom, Dad, I Want To Be A Prompt Engineer](https://www.forbes.com/sites/craigsmith/2023/04/05/mom-dad-i-want-to-be-a-prompt-engineer/?sh=7f1213159c8e)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663917", "quality_score": 60}
{"prompt": "Markettechpost - [Best Free Prompt Engineering Resources (2023)](https://www.marktechpost.com/2023/04/04/best-free-prompt-engineering-resources-2023/)", "source": "GitHub", "repository": "dair-ai/Prompt-Engineering-Guide", "source_type": "list", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:31.663968", "quality_score": 60}
{"prompt": "NL->Code prompts should generally have a description, which should give context about the programming language the model should generate and libraries it should be using. The description should also give information about the task at hand:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669123", "quality_score": 60}
{"prompt": "NL->Code prompts should also have examples of NL->Code interactions, exemplifying the kind of code you expect the model to produce. In this case, the inputs are math queries (e.g. \"what is 2 + 2?\") and code that console logs the result of the query.", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669207", "quality_score": 60}
{"prompt": "By default, `CodeEngine` uses JavaScript as the programming language, but you can create prompts for different languages by passing a different `CodePromptConfig` into the constructor. If, for example, we wanted to produce Python prompts, we could have passed `CodeEngine` a `pythonConfig` specifying the comment operator it should be using:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669242", "quality_score": 60}
{"prompt": "With our description and our examples, we can go ahead and create our `CodeEngine`:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669281", "quality_score": 60}
{"prompt": "Now that we have our `CodeEngine`, we can use it to create prompts:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669319", "quality_score": 60}
{"prompt": "The resulting prompt will be a string with the description, examples and the latest query formatted with comment operators and line breaks:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669371", "quality_score": 60}
{"prompt": "Given the context, a capable code generation model can take the above prompt and guess the next line: `console.log(1018 * Math.pow(4, 9));`.\n\nFor multi-turn scenarios, where past conversations influences the next turn, Code Engine enables us to persist interactions in a prompt:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669453", "quality_score": 60}
{"prompt": "Now new prompts will include the latest NL->Code interaction:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669490", "quality_score": 60}
{"prompt": "Produces a prompt identical to the one above, but with the NL->Code dialog history:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669532", "quality_score": 60}
{"prompt": "With this context, the code generation model has the dialog context needed to understand what we mean by the query. In this case, the model would correctly generate `console.log(1018 * Math.pow(4, 8));`.\n\n### Chat Engine\n\nJust like Code Engine, Chat Engine creates prompts with descriptions and examples. The difference is that Chat Engine creates prompts for dialog scenarios, where both the user and the model use natural language. The `ChatEngine` constructor takes an optional `chatConfig` argument, which allows you to define the name of a user and chatbot in a multi-turn dialog:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669593", "quality_score": 60}
{"prompt": "Similarly, Chat Engine prompts can have examples interactions:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669673", "quality_score": 60}
{"prompt": "These examples help set the tone of the bot, in this case Gordon the Anxious Robot. Now we can create our `ChatEngine` and use it to create prompts:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669721", "quality_score": 60}
{"prompt": "When passed to a large language model (e.g. GPT-3), the context of the above prompt will help coax a good answer from the model, like \"Subatomic particles at some level, but somehow I don't think that's what you were asking.\". As with Code Engine, we can persist this answer and continue the dialog such that the model is aware of the conversation context:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669795", "quality_score": 60}
{"prompt": "## Managing Prompt Overflow\n\nPrompts for Large Language Models generally have limited size, depending on the language model being used. Given that prompt-engine can persist dialog history, it is possible for dialogs to get so long that the prompt overflows. The Prompt Engine pattern handles this situation by removing the oldest dialog interaction from the prompt, effectively only remembering the most recent interactions.\n\nYou can specify the maximum tokens allowed in your prompt by passing a `maxTokens` parameter when constructing the config for any prompt engine:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "code_block", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.669902", "quality_score": 60}
{"prompt": "Act as `addInteraction`.\n\ninteraction: Interaction(input: string, response: string)", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "table", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.675075", "quality_score": 60, "role": "`addInteraction`"}
{"prompt": "representing the ongoing input/output pairs as the user and model communicate. The dialog ensures that the model (which is stateless) has the context about what's happened in the conversation so far.\n\nSee architecture diagram representation:\n  \n<img src=", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.675934", "quality_score": 60}
{"prompt": ">\n\n\n### Code Engine\n\nCode Engine creates prompts for Natural Language to Code scenarios. See TypeScript Syntax for importing `CodeEngine`:\n\n```js\nimport { CodeEngine } from", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.675990", "quality_score": 60}
{"prompt": ";\n```\n\nNL->Code prompts should generally have a description, which should give context about the programming language the model should generate and libraries it should be using. The description should also give information about the task at hand:\n\n```js\nconst description =", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676042", "quality_score": 60}
{"prompt": ";\n```\n\nNL->Code prompts should also have examples of NL->Code interactions, exemplifying the kind of code you expect the model to produce. In this case, the inputs are math queries (e.g.", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676087", "quality_score": 60}
{"prompt": ") and code that console logs the result of the query.\n\n```js\nconst examples = [\n  { input:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676130", "quality_score": 60}
{"prompt": "},\n];\n```\n\nBy default, `CodeEngine` uses JavaScript as the programming language, but you can create prompts for different languages by passing a different `CodePromptConfig` into the constructor. If, for example, we wanted to produce Python prompts, we could have passed `CodeEngine` a `pythonConfig` specifying the comment operator it should be using:\n\n```js\nconst pythonConfig = {\n  commentOperator:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676173", "quality_score": 60}
{"prompt": ",\n}\nconst codeEngine = new CodeEngine(description, examples, flowResetText, pythonConfig);\n\n```\n\nWith our description and our examples, we can go ahead and create our `CodeEngine`:\n\n```js\nconst codeEngine = new CodeEngine(description, examples);\n```\n\nNow that we have our `CodeEngine`, we can use it to create prompts:\n\n```js\nconst query =", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676230", "quality_score": 60}
{"prompt": ";\nconst prompt = codeEngine.buildPrompt(query);\n```\n\nThe resulting prompt will be a string with the description, examples and the latest query formatted with comment operators and line breaks:\n\n```js\n/* Natural Language Commands to JavaScript Math Code. The code should log the result of the command to the console. */\n\n/* what's 10 plus 18 */\nconsole.log(10 + 18);\n\n/* what's 10 times 18 */\nconsole.log(10 * 18);\n\n/* What's 1018 times the ninth power of four? */\n```\n\nGiven the context, a capable code generation model can take the above prompt and guess the next line: `console.log(1018 * Math.pow(4, 9));`.\n\nFor multi-turn scenarios, where past conversations influences the next turn, Code Engine enables us to persist interactions in a prompt:\n\n```js\n...\n// Assumes existence of code generation model\nlet code = model.generateCode(prompt);\n\n// Adds interaction\ncodeEngine.addInteraction(query, code);\n```\n\nNow new prompts will include the latest NL->Code interaction:\n\n```js\ncodeEngine.buildPrompt(", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676450", "quality_score": 60}
{"prompt": ");\n```\n\nProduces a prompt identical to the one above, but with the NL->Code dialog history:\n\n```js\n...\n/* What's 1018 times the ninth power of four? */\nconsole.log(1018 * Math.pow(4, 9));\n\n/* How about the 8th power? */\n```\n\nWith this context, the code generation model has the dialog context needed to understand what we mean by the query. In this case, the model would correctly generate `console.log(1018 * Math.pow(4, 8));`.\n\n### Chat Engine\n\nJust like Code Engine, Chat Engine creates prompts with descriptions and examples. The difference is that Chat Engine creates prompts for dialog scenarios, where both the user and the model use natural language. The `ChatEngine` constructor takes an optional `chatConfig` argument, which allows you to define the name of a user and chatbot in a multi-turn dialog: \n\n```js\nconst chatEngineConfig = {\n  user:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676557", "quality_score": 60}
{"prompt": ";\n```\n\nSimilarly, Chat Engine prompts can have examples interactions: \n\n```js\nconst examples = [\n  { input:", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676648", "quality_score": 60}
{"prompt": "I don't know man! That's an awfully existential question. How would you answer it?", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676690", "quality_score": 60}
{"prompt": "Good point - do you at least know what you were made for?", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676719", "quality_score": 60}
{"prompt": "I'm OK at riveting, but that's not how I should answer a meaning of life question is it?", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676766", "quality_score": 60}
{"prompt": ". As with Code Engine, we can persist this answer and continue the dialog such that the model is aware of the conversation context: \n\n```js\nchatEngine.addInteraction(userQuery,", "source": "GitHub", "repository": "microsoft/prompt-engine", "source_type": "quote", "source_file": "README.md", "branch": "main", "collected_at": "2026-02-05T10:20:33.676849", "quality_score": 60}
