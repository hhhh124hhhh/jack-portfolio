{"source": "reddit", "source_id": "reddit-1qp6s3c", "title": "[D] Examples of self taught people who made significant contributions in ML/AI", "content": "Most high profile work income across seems to be from people with PhDs, either in academia or industry. There's also a hiring bias towards formal degrees. \n\nThere has been a surplus of good quality online learning material and guides about choosing the right books, etc, that a committed and disciplined person can self learn a significant amount. \n\nIt sounds good in principle, but has it happened in practice? Are there people with basically a BS/MS in CS or engineering who self taught themselves all the math and ML theory, and went on to build fundamentally new things or made significant contributions to this field? \n\nMore personally, I fall in this bucket, and while I'm making good progress with the math, I'd like to know, based on examples of others, how far I can actually go. If self teaching and laboring through a lot of material will be worth it. ", "full_text": "Most high profile work income across seems to be from people with PhDs, either in academia or industry. There's also a hiring bias towards formal degrees. \n\nThere has been a surplus of good quality online learning material and guides about choosing the right books, etc, that a committed and disciplined person can self learn a significant amount. \n\nIt sounds good in principle, but has it happened in practice? Are there people with basically a BS/MS in CS or engineering who self taught themselves all the math and ML theory, and went on to build fundamentally new things or made significant contributions to this field? \n\nMore personally, I fall in this bucket, and while I'm making good progress with the math, I'd like to know, based on examples of others, how far I can actually go. If self teaching and laboring through a lot of material will be worth it. ", "url": "https://www.reddit.com/r/MachineLearning/comments/1qp6s3c/d_examples_of_self_taught_people_who_made/", "author": "datashri", "metrics": {"upvotes": 83, "comments": 39, "created_utc": 1769592523.0}, "subreddit": "machinelearning", "flair": "Discussion", "quality_score": 72.7208671582886, "collected_at": "2026-01-30T15:20:36.123832"}
{"source": "reddit", "source_id": "reddit-1qqp5ux", "title": "Asked ChatGPT to turn me and itself into animals. This happened", "content": "cute ğŸ˜‡. \n\n[PROMPT]\n\nBased on our past conversations, pick a real animal that best represents me, and preferably a different real animal that best represents you as an AI. Then create an image of those two animals taking a cute selfie together.", "full_text": "cute ğŸ˜‡. \n\n[PROMPT]\n\nBased on our past conversations, pick a real animal that best represents me, and preferably a different real animal that best represents you as an AI. Then create an image of those two animals taking a cute selfie together.", "url": "https://www.reddit.com/r/ChatGPT/comments/1qqp5ux/asked_chatgpt_to_turn_me_and_itself_into_animals/", "author": "one_flow_to_bit", "metrics": {"upvotes": 440, "comments": 242, "created_utc": 1769730372.0}, "subreddit": "ChatGPT", "flair": "Funny ", "quality_score": 65, "collected_at": "2026-01-30T15:20:34.130917"}
{"source": "reddit", "source_id": "reddit-1qqdmoq", "title": "Moltbot is exploding. 100K Github Stars in weeks. But what can we actually do with it, and why so much hype? And how to avoid the security concerns?", "content": "Hey everyone.  \n  \nI Just published a breakdown on Moltbot: the self-hosted, open-source personal AI assistant that's gone massively viral.  \nThe article discusses the main points of my own questions about Moltbot ( what it really is, what are its capabilities, why is therean insane growth... ).\n\nOk, now the only con I have for this project is security draw backs ( not really dove deep into this at all in the article ) : broad system access is given to Moltbot and it is pretty easy to do prompt injection with vulnerabilities if exposed. Which I'd point out is actually easy to misconfigured if not careful.\n\nI'd love to get some of my own personal tasks automated ( I love saving time ), but security concerns has me hesitant to experiement.\n\nIf anyone has methods to ensure full security with this project feel free to let me know, I might even update the blog article with how to avoid the security concerns as for real it is the only thing making me hesitant in trying it myself.\n\n", "full_text": "Hey everyone.  \n  \nI Just published a breakdown on Moltbot: the self-hosted, open-source personal AI assistant that's gone massively viral.  \nThe article discusses the main points of my own questions about Moltbot ( what it really is, what are its capabilities, why is therean insane growth... ).\n\nOk, now the only con I have for this project is security draw backs ( not really dove deep into this at all in the article ) : broad system access is given to Moltbot and it is pretty easy to do prompt injection with vulnerabilities if exposed. Which I'd point out is actually easy to misconfigured if not careful.\n\nI'd love to get some of my own personal tasks automated ( I love saving time ), but security concerns has me hesitant to experiement.\n\nIf anyone has methods to ensure full security with this project feel free to let me know, I might even update the blog article with how to avoid the security concerns as for real it is the only thing making me hesitant in trying it myself.\n\n", "url": "https://www.reddit.com/r/artificial/comments/1qqdmoq/moltbot_is_exploding_100k_github_stars_in_weeks/", "author": "TheEnormous", "metrics": {"upvotes": 79, "comments": 78, "created_utc": 1769704812.0}, "subreddit": "artificial", "flair": "Discussion", "quality_score": 62.77638883463118, "collected_at": "2026-01-30T15:20:34.996068"}
{"source": "reddit", "source_id": "reddit-1qoaq6r", "title": "[D] Who should get co-authorship? Need advice for ICML", "content": "Around April 2025, I started working on a paper for ICLR. The plan was to collaborate (equally) with one of my PhD supervisor's students, but as time went on, I took on most of the responsibility and ended up writing the entire paper + coding all the main results and ablations. The other student ran some baselines, but the results had mistakes. So I had to re-implement and correct the baselines. In the final version, everything including writing, code, plots, figures, etc., was my own work.\n\nWhile I was busy with this work, the other student was working on another paper using my code (without including me as a co-author). To be clear: they took my code as a starting point and implemented something on top. I think this was really unfair. Given that we were supposed to collaborate equally, they decided instead to do the minimum to be part of the work while working to get a second paper. My PhD supervisor wasn't involved in most of this process--they usually schedule meetings \\~2 weeks be", "full_text": "Around April 2025, I started working on a paper for ICLR. The plan was to collaborate (equally) with one of my PhD supervisor's students, but as time went on, I took on most of the responsibility and ended up writing the entire paper + coding all the main results and ablations. The other student ran some baselines, but the results had mistakes. So I had to re-implement and correct the baselines. In the final version, everything including writing, code, plots, figures, etc., was my own work.\n\nWhile I was busy with this work, the other student was working on another paper using my code (without including me as a co-author). To be clear: they took my code as a starting point and implemented something on top. I think this was really unfair. Given that we were supposed to collaborate equally, they decided instead to do the minimum to be part of the work while working to get a second paper. My PhD supervisor wasn't involved in most of this process--they usually schedule meetings \\~2 weeks before conference deadlines to see what I have ready to submit. I also think this is unfair: I spend hundreds of hours working on a paper, and they get co-authorship by reviewing the abstract.\n\nWho should get co-authorship here?\n\nFrom September, I started working on a paper for ICML. I spent so much time on this paper, not taking Christmas holiday, etc. I was expecting the same request for a meeting two weeks before the deadline, but this time, one day before the Abstract deadline, my supervisor asks me \"What are we submitting to ICML?\" Keep in mind, we haven't spoken since the ICLR deadline and they have no idea what I have been working on. I wasn't sure what to do, but I ended up adding them as a co-author. I really regret this decision.\n\nShould they get co-authorship just for being a supervisor? If there was an option to remove them, for example, by emailing PCs, should I do it?", "url": "https://www.reddit.com/r/MachineLearning/comments/1qoaq6r/d_who_should_get_coauthorship_need_advice_for_icml/", "author": "NumberGenerator", "metrics": {"upvotes": 30, "comments": 32, "created_utc": 1769511369.0}, "subreddit": "machinelearning", "flair": "Discussion", "quality_score": 61.954451150103324, "collected_at": "2026-01-30T15:20:36.124075"}
{"source": "reddit", "source_id": "reddit-1qovjyh", "title": "[D] How do you actually track which data transformations went into your trained models?", "content": "I keep running into this problem and wondering if I'm just disorganized or if this is a real gap:\n\n**The scenario:**\n- Train a model in January, get 94% accuracy\n- Write paper, submit to conference\n- Reviewer in March asks: \"Can you reproduce this with different random seeds?\"\n- I go back to my code and... which dataset version did I use? Which preprocessing script? Did I merge the demographic data before or after normalization?\n\n**What I've tried:**\n- Git commits (but I forget to commit datasets)\n- MLflow (tracks experiments, not data transformations)\n- Detailed comments in notebooks (works until I have 50 notebooks)\n- \"Just being more disciplined\" (lol)\n\n**My question:**\nHow do you handle this? Do you:\n1. Use a specific tool that tracks data lineage well?\n2. Have a workflow/discipline that just works?\n3. Also struggle with this and wing it every time?\n\nI'm especially curious about people doing LLM fine-tuning - with multiple dataset versions, prompts, and preprocessing steps, how do ", "full_text": "I keep running into this problem and wondering if I'm just disorganized or if this is a real gap:\n\n**The scenario:**\n- Train a model in January, get 94% accuracy\n- Write paper, submit to conference\n- Reviewer in March asks: \"Can you reproduce this with different random seeds?\"\n- I go back to my code and... which dataset version did I use? Which preprocessing script? Did I merge the demographic data before or after normalization?\n\n**What I've tried:**\n- Git commits (but I forget to commit datasets)\n- MLflow (tracks experiments, not data transformations)\n- Detailed comments in notebooks (works until I have 50 notebooks)\n- \"Just being more disciplined\" (lol)\n\n**My question:**\nHow do you handle this? Do you:\n1. Use a specific tool that tracks data lineage well?\n2. Have a workflow/discipline that just works?\n3. Also struggle with this and wing it every time?\n\nI'm especially curious about people doing LLM fine-tuning - with multiple dataset versions, prompts, and preprocessing steps, how do you keep track of what went where?\n\nNot looking for perfect solutions - just want to know I'm not alone or if there's something obvious I'm missing.\n\nWhat's your workflow?", "url": "https://www.reddit.com/r/MachineLearning/comments/1qovjyh/d_how_do_you_actually_track_which_data/", "author": "Achilles_411", "metrics": {"upvotes": 24, "comments": 25, "created_utc": 1769559284.0}, "subreddit": "machinelearning", "flair": "Research", "quality_score": 57.297958971132715, "collected_at": "2026-01-30T15:20:36.123941"}
{"source": "reddit", "source_id": "reddit-1qqp1f2", "title": "Anyone else noticed ChatGPT loves \"staccato rhythm\" recently?", "content": "For example:\n\n\"Jim loved going to the park. Concrete paths. Wet benches. Dogs everywhere.\"\n\n\"Glass back. Sharp edges. Bright screen. Loud speakers. Battery already anxious.\"\n\nI fucking hate that it does this so much. I tell it not to and of course it goes ahead and does it anyway. For me, this staccato thing as well as the rule of three are the new em-dash tell (it seems to have finally stopped using em dashes all the time, thank God).", "full_text": "For example:\n\n\"Jim loved going to the park. Concrete paths. Wet benches. Dogs everywhere.\"\n\n\"Glass back. Sharp edges. Bright screen. Loud speakers. Battery already anxious.\"\n\nI fucking hate that it does this so much. I tell it not to and of course it goes ahead and does it anyway. For me, this staccato thing as well as the rule of three are the new em-dash tell (it seems to have finally stopped using em dashes all the time, thank God).", "url": "https://www.reddit.com/r/ChatGPT/comments/1qqp1f2/anyone_else_noticed_chatgpt_loves_staccato_rhythm/", "author": "PrideProfessional556", "metrics": {"upvotes": 49, "comments": 16, "created_utc": 1769730071.0}, "subreddit": "ChatGPT", "flair": "Prompt engineering ", "quality_score": 57.0, "collected_at": "2026-01-30T15:20:34.131030"}
{"source": "reddit", "source_id": "reddit-1qpbrgp", "title": "[D] Why isn't uncertainty estimation implemented in more models?", "content": "I have a feeling there must be an obvious answer here. I just came across gaussian process here:\n\nhttps://www.sciencedirect.com/science/article/pii/S2405471220303641\n\nFrom my understanding, a model that provides a prediction with an uncertainty estimate (that is properly tuned/calibrated for OOD) is immensely useful for the enrichment of results via an acquisition function from screening (for example over the drug perturbation space in a given cell line). \n\nIn that paper, they suggest a hybrid approach of GP + MLP. \\*what drawbacks would this have, other than a slightly higher MSE?\\* \n\nAlthough this is not what I'm going for, another application is continued learning:\n\nhttps://www.cell.com/cell-reports-methods/fulltext/S2667-2375(23)00251-5\n\nTheir paper doesn't train a highly general drug-drug synergy model, but certianly shows that uncertainty works in practice.\n\nI've implemented (deep) ensemble learning before, but this seems more practical than having to train 5 identical models at ", "full_text": "I have a feeling there must be an obvious answer here. I just came across gaussian process here:\n\nhttps://www.sciencedirect.com/science/article/pii/S2405471220303641\n\nFrom my understanding, a model that provides a prediction with an uncertainty estimate (that is properly tuned/calibrated for OOD) is immensely useful for the enrichment of results via an acquisition function from screening (for example over the drug perturbation space in a given cell line). \n\nIn that paper, they suggest a hybrid approach of GP + MLP. \\*what drawbacks would this have, other than a slightly higher MSE?\\* \n\nAlthough this is not what I'm going for, another application is continued learning:\n\nhttps://www.cell.com/cell-reports-methods/fulltext/S2667-2375(23)00251-5\n\nTheir paper doesn't train a highly general drug-drug synergy model, but certianly shows that uncertainty works in practice.\n\nI've implemented (deep) ensemble learning before, but this seems more practical than having to train 5 identical models at different initialization parameters - although I may be wrong.\n\nCan someone with experience please explain the reason for there not being wisespread adoption? Most (biological) predictive studies don't even mention using it. ", "url": "https://www.reddit.com/r/MachineLearning/comments/1qpbrgp/d_why_isnt_uncertainty_estimation_implemented_in/", "author": "dp3471", "metrics": {"upvotes": 30, "comments": 18, "created_utc": 1769607956.0}, "subreddit": "machinelearning", "flair": "Discussion", "quality_score": 54.954451150103324, "collected_at": "2026-01-30T15:20:36.123864"}
{"source": "reddit", "source_id": "reddit-1mf7igt", "title": "The AI Spam has been overwhelming - conversations with ChatGPT and psuedo-research are now bannable offences. Please help the sub by reporting the spam!", "content": "Psuedo-research AI conversations about prompt engineering and recursion have been testing all of our patience, and I know we've seen a massive dip in legitimate activity because of it.\n\n**Effective today, AI-generated posts &amp; psuedo-research will be a bannable offense.**\n\nI'm trying to keep up with post removals with automod rules, but the bots are constantly adjusting to it and the human offenders are constantly trying to appeal post removals.\n\nPlease report any rule breakers, which will flag the post for removal and mod review.", "full_text": "Psuedo-research AI conversations about prompt engineering and recursion have been testing all of our patience, and I know we've seen a massive dip in legitimate activity because of it.\n\n**Effective today, AI-generated posts &amp; psuedo-research will be a bannable offense.**\n\nI'm trying to keep up with post removals with automod rules, but the bots are constantly adjusting to it and the human offenders are constantly trying to appeal post removals.\n\nPlease report any rule breakers, which will flag the post for removal and mod review.", "url": "https://www.reddit.com/r/LanguageTechnology/comments/1mf7igt/the_ai_spam_has_been_overwhelming_conversations/", "author": "BeginnerDragon", "metrics": {"upvotes": 48, "comments": 11, "created_utc": 1754080522.0}, "subreddit": "LanguageTechnology", "flair": null, "quality_score": 54.356406460551014, "collected_at": "2026-01-30T15:20:37.400485"}
{"source": "reddit", "source_id": "reddit-1qpc4ap", "title": "[R] We open-sourced FASHN VTON v1.5: a pixel-space, maskless virtual try-on model trained from scratch (972M params, Apache-2.0)", "content": "We just open-sourced FASHN VTON v1.5, a virtual try-on model that generates photorealistic images of people wearing garments directly in pixel space. We trained this from scratch (not fine-tuned from an existing diffusion model), and have been running it as an API for the past year. Now we're releasing the weights and inference code.\n\n# Why we're releasing this\n\nMost open-source VTON models are either research prototypes that require significant engineering to deploy, or they're locked behind restrictive licenses. As state-of-the-art capabilities consolidate into massive generalist models, we think there's value in releasing focused, efficient models that researchers and developers can actually own, study, and extend commercially.\n\nWe also want to demonstrate that competitive results in this domain don't require massive compute budgets. Total training cost was in the $5-10k range on rented A100s.\n\nThis follows our [human parser release](https://www.reddit.com/r/MachineLearning/comments", "full_text": "We just open-sourced FASHN VTON v1.5, a virtual try-on model that generates photorealistic images of people wearing garments directly in pixel space. We trained this from scratch (not fine-tuned from an existing diffusion model), and have been running it as an API for the past year. Now we're releasing the weights and inference code.\n\n# Why we're releasing this\n\nMost open-source VTON models are either research prototypes that require significant engineering to deploy, or they're locked behind restrictive licenses. As state-of-the-art capabilities consolidate into massive generalist models, we think there's value in releasing focused, efficient models that researchers and developers can actually own, study, and extend commercially.\n\nWe also want to demonstrate that competitive results in this domain don't require massive compute budgets. Total training cost was in the $5-10k range on rented A100s.\n\nThis follows our [human parser release](https://www.reddit.com/r/MachineLearning/comments/1qax221/p_opensourcing_a_human_parsing_model_trained_on/) from a couple weeks ago.\n\n# Architecture\n\n* **Core:** MMDiT (Multi-Modal Diffusion Transformer) with 972M parameters\n* **Block structure:** 4 patch-mixer + 8 double-stream + 16 single-stream transformer blocks\n* **Sampling:** Rectified Flow (linear interpolation between noise and data)\n* **Conditioning:** Person image, garment image, and category (tops/bottoms/one-piece)\n\n# Key differentiators\n\n**Pixel-space operation:** Unlike most diffusion models that work in VAE latent space, we operate directly on RGB pixels. This avoids lossy VAE encoding/decoding that can blur fine garment details like textures, patterns, and text.\n\n**Maskless inference:** No segmentation mask is required on the target person. This improves body preservation (no mask leakage artifacts) and allows unconstrained garment volume. The model learns where clothing boundaries should be rather than being told.\n\n# Practical details\n\n* **Inference:** \\~5 seconds on H100, runs on consumer GPUs (RTX 30xx/40xx)\n* **Memory:** \\~8GB VRAM minimum\n* **License:** Apache-2.0\n\n# Links\n\n* **GitHub:** [fashn-AI/fashn-vton-1.5](https://github.com/fashn-AI/fashn-vton-1.5)\n* **HuggingFace:** [fashn-ai/fashn-vton-1.5](https://huggingface.co/fashn-ai/fashn-vton-1.5)\n* **Project page:** [fashn.ai/research/vton-1-5](https://fashn.ai/research/vton-1-5)\n\n# Quick example\n\n    from fashn_vton import TryOnPipeline\n    from PIL import Image\n    \n    pipeline = TryOnPipeline(weights_dir=\"./weights\")\n    person = Image.open(\"person.jpg\").convert(\"RGB\")\n    garment = Image.open(\"garment.jpg\").convert(\"RGB\")\n    \n    result = pipeline(\n        person_image=person,\n        garment_image=garment,\n        category=\"tops\",\n    )\n    result.images[0].save(\"output.png\")\n\n# Coming soon\n\n* **HuggingFace Space:** Online demo\n* **Technical paper:** Architecture decisions, training methodology, and design rationale\n\nHappy to answer questions about the architecture, training, or implementation.", "url": "https://www.reddit.com/r/MachineLearning/comments/1qpc4ap/r_we_opensourced_fashn_vton_v15_a_pixelspace/", "author": "JYP_Scouter", "metrics": {"upvotes": 72, "comments": 18, "created_utc": 1769608833.0}, "subreddit": "machinelearning", "flair": "Research", "quality_score": 50.970562748477136, "collected_at": "2026-01-30T15:20:36.123786"}
{"source": "reddit", "source_id": "reddit-1qjrir4", "title": "What are the most important problems in NLP in 2026, in both academia and industry?", "content": "What are the most important problems in this space in academia and industry?\n\n  \nI'm not an NLP researcher, but someone who has worked in industry in adjacent fields. I will give two examples of problems that seem important at a practical level that I've come across:\n\n* NLP and speech models for low-resource languages. Many people would like to use LLMs for various purposes (asking questions about crops, creating health or education-applications) but cannot do so because models do not perform well for their regional language. It seems important to gather data, train models, and build applications that enable native speakers of these languages to benefit from the technology.\n* Improving \"conversational AI\" systems in terms of latency, naturalness, handling different types of interruptions and filler words, etc. I don't know how this subreddit feels about this topic, but it is a huge focus in industry.\n\nThat being said, the examples I gave are very much shaped by experience, and I do not", "full_text": "What are the most important problems in this space in academia and industry?\n\n  \nI'm not an NLP researcher, but someone who has worked in industry in adjacent fields. I will give two examples of problems that seem important at a practical level that I've come across:\n\n* NLP and speech models for low-resource languages. Many people would like to use LLMs for various purposes (asking questions about crops, creating health or education-applications) but cannot do so because models do not perform well for their regional language. It seems important to gather data, train models, and build applications that enable native speakers of these languages to benefit from the technology.\n* Improving \"conversational AI\" systems in terms of latency, naturalness, handling different types of interruptions and filler words, etc. I don't know how this subreddit feels about this topic, but it is a huge focus in industry.\n\nThat being said, the examples I gave are very much shaped by experience, and I do not have a breadth of knowledge in this area. I would be interested to hear what other people think are the most important problems, including both theoretical problems in academia and practical problems in both academia and industry.", "url": "https://www.reddit.com/r/LanguageTechnology/comments/1qjrir4/what_are_the_most_important_problems_in_nlp_in/", "author": "medium_squirrell", "metrics": {"upvotes": 18, "comments": 10, "created_utc": 1769079272.0}, "subreddit": "LanguageTechnology", "flair": null, "quality_score": 48.48528137423857, "collected_at": "2026-01-30T15:20:37.400579"}
{"source": "reddit", "source_id": "reddit-1qfe2tv", "title": "Statistical NLP: Question on Bayesian disambiguation for feature structures", "content": "Hello r/LanguageTechnology,\n\nI'm not as familiar with statistics as I am with formal linguistics, so I apologize if this comes across as overly simple. I've been working on an Akkadian noun analyzer. It uses regexes to extract features from surface forms. Example:\n\n    {\n    Â  Â  r\"\\w+[^t]um?$\": {\n    Â  Â  Â  Â  'type':'nominal_noun',\n    Â  Â  Â  Â  'gender':'masculine',\n    Â  Â  Â  Â  'number':'singular',\n    Â  Â  Â  Â  'case':'nominative',\n    Â  Â  Â  Â  'state':'governed'\n    Â  Â  }\n\nI hit a wall with zero-marking, as nouns can be either in the absolute or construct states, as seen here:\n\n    Â  Â  r\"\\w+[^ÄÄ«Ä“aie]$\": {\n    Â  Â  Â  Â  'type':'nominal_noun',\n    Â  Â  Â  Â  'gender':'masculine',\n    Â  Â  Â  Â  'number':'singular',\n    Â  Â  Â  Â  'case':'nominative',\n    Â  Â  Â  Â  'state':'absolute/construct'\n    Â  Â  }Â  \n\nSince the state is unknown, it's left as \"absolute/construct\".\n\nI have a disambiguator function which takes each word's (words are objects, by the way) feature structures in a list and checks for certa", "full_text": "Hello r/LanguageTechnology,\n\nI'm not as familiar with statistics as I am with formal linguistics, so I apologize if this comes across as overly simple. I've been working on an Akkadian noun analyzer. It uses regexes to extract features from surface forms. Example:\n\n    {\n    Â  Â  r\"\\w+[^t]um?$\": {\n    Â  Â  Â  Â  'type':'nominal_noun',\n    Â  Â  Â  Â  'gender':'masculine',\n    Â  Â  Â  Â  'number':'singular',\n    Â  Â  Â  Â  'case':'nominative',\n    Â  Â  Â  Â  'state':'governed'\n    Â  Â  }\n\nI hit a wall with zero-marking, as nouns can be either in the absolute or construct states, as seen here:\n\n    Â  Â  r\"\\w+[^ÄÄ«Ä“aie]$\": {\n    Â  Â  Â  Â  'type':'nominal_noun',\n    Â  Â  Â  Â  'gender':'masculine',\n    Â  Â  Â  Â  'number':'singular',\n    Â  Â  Â  Â  'case':'nominative',\n    Â  Â  Â  Â  'state':'absolute/construct'\n    Â  Â  }Â  \n\nSince the state is unknown, it's left as \"absolute/construct\".\n\nI have a disambiguator function which takes each word's (words are objects, by the way) feature structures in a list and checks for certain things.\n\n    class Phrase:\n    Â  Â  def __init__(self, obj_list):\n    Â  Â  Â  Â  self.obj_list = obj_list\n    Â  Â  def disambiguate(self):\n    Â  Â  Â  Â  for i, obj in enumerate(self.obj_list):\n    Â  Â  Â  Â  Â  Â  if i + 1 &gt;= len(self.obj_list): \n    Â  Â  Â  Â  Â  Â  Â  Â  # Because when it reaches the end of the object list, there is no next object. \n    Â  Â  Â  Â  Â  Â  Â  Â  continue\n    Â  Â  Â  Â  Â  Â  next_obj = self.obj_list[i+1] \n    Â  Â  Â  Â  Â  Â  if obj.features.get(\"state\") == \"absolute/construct\" and next_obj.features.get(\"case\") == \"genitive\": \n    Â  Â  Â  Â  Â  Â  Â  Â  # .get() because self.features can be of None type\n    Â  Â  Â  Â  Â  Â  Â  Â  obj.features[\"state\"] = \"construct\" \n    Â  Â  Â  Â  Â  Â  Â  Â  # Genitive in specific because the construct relates to possession. \n    Â  Â  Â  Â  Â  Â  elif next_obj.features.get(\"state\") == \"absolute/construct\" and obj.features.get(\"case\") == \"nominative\":\n    Â  Â  Â  Â  Â  Â  Â  Â  next_obj.features[\"state\"] = \"absolute\" \n    Â  Â  Â  Â  Â  Â  Â  Â  # In this regard, it's known to be a predicate (one of the few extant uses of the absolute state in Akkadian)\n\nSo, it checks for adjacent words' states for disambiguation, in short. Now, I realize that this could work like Bayesian updating (the adjacent words being new information), and this would also allow for less granularity (less very specific deterministic rules for disambiguation).\n\nI plan on working on some old Indo-European languages (my eyes are set on Gothic for the moment) and IE languages generally have more difficult ambiguity resolution (stem extraction, exact same surface forms for different cases/genders/persons). I'm interested in learning about more proper statistical methods to resolve ambiguity.\n\nMore specifically, I'd like to have the surface form extractor have multiple potential feature structures with changing weights depending on other words, those weights I could assign by hand or perhaps work it through an Akkadian corpus. But I'm trying to make the jump from finding probabilities to them actually having an effect on parses. So, I'd like it to hybridize a symbolic constraint-based and a probabilistic/statistical approach.\n\nWhat seems the best is a maximum entropy model for feature structures, though I'd love to get further into statistical programming and am pretty new to it. I wouldn't like to bloat my codebase with heavy corpora or a bunch of hard-coded rules either, which is why I wanted a symbolic and probabilistic hybrid approach over just one of them.\n\nIf you've done something similar, how have you resolved this? What did you need to learn? Any external resources?\n\nI'd also like to say that I didn't want to use NLTK because I'm interested in implementing analyzers and parsers on my own either with Python's standard libraries or with something extra like maybe SciPy.\n\nLooking forward to any responses.\n\nMM27", "url": "https://www.reddit.com/r/LanguageTechnology/comments/1qfe2tv/statistical_nlp_question_on_bayesian/", "author": "metalmimiga27", "metrics": {"upvotes": 7, "comments": 5, "created_utc": 1768658802.0}, "subreddit": "LanguageTechnology", "flair": null, "quality_score": 42.79150262212918, "collected_at": "2026-01-30T15:20:37.400704"}
{"source": "reddit", "source_id": "reddit-1qqueq3", "title": "Why chatgpt keep repeating responses across multiple prompts?", "content": "I noticed, chatgpt clings on to responses and keep repeating them in every new prompt, let's say i ask a question and it responds and then I ask further questions and it keeps putting the response from 1st question before answerering newer questions, why is it getting so dumb? And it's responses are not too structured and to the point. It's like very verbose ..I am noticing great improvements with gemini compared to chatgpt", "full_text": "I noticed, chatgpt clings on to responses and keep repeating them in every new prompt, let's say i ask a question and it responds and then I ask further questions and it keeps putting the response from 1st question before answerering newer questions, why is it getting so dumb? And it's responses are not too structured and to the point. It's like very verbose ..I am noticing great improvements with gemini compared to chatgpt", "url": "https://www.reddit.com/r/ChatGPT/comments/1qqueq3/why_chatgpt_keep_repeating_responses_across/", "author": "syedali1337", "metrics": {"upvotes": 6, "comments": 7, "created_utc": 1769744115.0}, "subreddit": "ChatGPT", "flair": "Other ", "quality_score": 33.39897948556636, "collected_at": "2026-01-30T15:20:34.131277"}
{"source": "reddit", "source_id": "reddit-1qqv0bh", "title": "If heaven and hell had a modern minimalistic corporate logo, how would they look?", "content": "Full prompt: If heaven/hell had a modern minimalistic corporate logo, how would they look? Make an image, Logos on white background.", "full_text": "Full prompt: If heaven/hell had a modern minimalistic corporate logo, how would they look? Make an image, Logos on white background.", "url": "https://www.reddit.com/r/ChatGPT/comments/1qqv0bh/if_heaven_and_hell_had_a_modern_minimalistic/", "author": "floku85", "metrics": {"upvotes": 6, "comments": 4, "created_utc": 1769745806.0}, "subreddit": "ChatGPT", "flair": "Funny ", "quality_score": 21.898979485566358, "collected_at": "2026-01-30T15:20:34.131243"}
{"source": "reddit", "source_id": "reddit-1q02m19", "title": "[D] Monthly Who's Hiring and Who wants to be Hired?", "content": "**For Job Postings** please use this template\n\n&gt;Hiring: \\[Location\\], Salary:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]    and \\[Brief overview, what you're looking for\\]\n\n**For Those looking for jobs** please use this template\n\n&gt;Want to be Hired: \\[Location\\], Salary Expectation:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]  Resume: \\[Link to resume\\] and \\[Brief overview, what you're looking for\\]\n\n&amp;#x200B;\n\nPlease remember that this community is geared towards those with experience.", "full_text": "**For Job Postings** please use this template\n\n&gt;Hiring: \\[Location\\], Salary:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]    and \\[Brief overview, what you're looking for\\]\n\n**For Those looking for jobs** please use this template\n\n&gt;Want to be Hired: \\[Location\\], Salary Expectation:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]  Resume: \\[Link to resume\\] and \\[Brief overview, what you're looking for\\]\n\n&amp;#x200B;\n\nPlease remember that this community is geared towards those with experience.", "url": "https://www.reddit.com/r/MachineLearning/comments/1q02m19/d_monthly_whos_hiring_and_who_wants_to_be_hired/", "author": "AutoModerator", "metrics": {"upvotes": 5, "comments": 8, "created_utc": 1767151829.0}, "subreddit": "machinelearning", "flair": "Discussion", "quality_score": 43.47213595499958, "collected_at": "2026-01-30T15:46:34.369664"}
