#!/bin/bash
# ä½¿ç”¨ Twitter API æ”¶é›† AI æç¤ºè¯

set -e

# é…ç½®
DATE=$(date +%Y-%m-%d)
TIME=$(date +%H%M)
OUTPUT_FILE="/root/clawd/data/prompts/twitter-prompts.jsonl"

# Twitter API Key (ä»ç¯å¢ƒå˜é‡åŠ è½½)
export TWITTER_API_KEY="${TWITTER_API_KEY:-new1_1f191206d7234ac883f47640b933792a}"

# æœç´¢æŸ¥è¯¢ï¼ˆä¸­è‹±æ–‡ï¼‰
QUERIES=(
    # è‹±æ–‡æŸ¥è¯¢
    "AI prompt engineering"
    "ChatGPT prompts"
    "Claude prompts"
    "midjourney prompts"
    "AI art prompts"
    "prompt engineering tips"
    "best AI prompts"
    "prompt templates"
    # ä¸­æ–‡æŸ¥è¯¢
    "AI æç¤ºè¯"
    "ChatGPT æŒ‡ä»¤"
    "AI ç»˜ç”»æç¤ºè¯"
    "æç¤ºè¯å·¥ç¨‹"
)

# ä¸´æ—¶æ–‡ä»¶
TMP_DIR="/tmp/twitter-prompt-collect-${DATE}-${TIME}"
mkdir -p "$TMP_DIR"

# é¢œè‰²
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date '+%H:%M:%S')]${NC} $1"
}

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ bird CLI æ˜¯å¦å®‰è£…
if ! command -v bird &> /dev/null; then
    log_error "bird CLI æœªå®‰è£…"
    log_info "è¯·è¿è¡Œ: npm install -g @sugarcube/cli"
    exit 1
fi

log "=========================================="
log "Twitter AI æç¤ºè¯æ”¶é›†"
log "=========================================="

# ç»Ÿè®¡
TOTAL_TWEETS=0
TOTAL_PROMPTS=0

# ç¡®ä¿ Python å¯ç”¨
if ! command -v python3 &> /dev/null; then
    log_error "python3 æœªå®‰è£…"
    exit 1
fi

# åˆ›å»º Python è„šæœ¬æ¥å¤„ç†æ•°æ®
cat > "$TMP_DIR/process-tweets.py" << 'PYTHON_SCRIPT'
#!/usr/bin/env python3
import json
import re
from datetime import datetime
import sys

def extract_prompts_from_tweet(text):
    """ä»æ¨æ–‡ä¸­æå–å¯èƒ½çš„æç¤ºè¯"""
    prompts = []

    # æŸ¥æ‰¾ä»£ç å—
    code_blocks = re.findall(r'```(?:python|javascript|json)?\n(.*?)```', text, re.DOTALL)
    for block in code_blocks:
        block = block.strip()
        if len(block) > 20:
            prompts.append(block)

    # æŸ¥æ‰¾å¼•ç”¨æ–‡æœ¬
    quoted = re.findall(r'"([^"]{30,300})"', text)
    for quote in quoted:
        if any(word in quote.lower() for word in ['prompt', 'act as', 'please', 'å¸®æˆ‘', 'æ‰®æ¼”']):
            prompts.append(quote)

    # æŸ¥æ‰¾ä»¥å†’å·å¼€å¤´çš„æŒ‡ä»¤
    instructions = re.findall(r'([A-Z][^.!?]{20,150})', text)
    for instr in instructions[:2]:
        prompts.append(instr)

    return list(set(prompts))[:3]  # æœ€å¤šè¿”å› 3 ä¸ª

def process_tweet_data(raw_data, query):
    """å¤„ç†åŸå§‹æ¨æ–‡æ•°æ®"""
    try:
        data = json.loads(raw_data)

        if isinstance(data, dict):
            # å•ä¸ªæ¨æ–‡
            data = [data]
        elif isinstance(data, list):
            pass  # å·²ç»æ˜¯åˆ—è¡¨
        else:
            return []

        processed = []

        for item in data:
            # å°è¯•ä¸åŒçš„æ•°æ®ç»“æ„
            if isinstance(item, dict):
                tweet = item.get('data', item) if 'data' in item else item

                # è·å–æ¨æ–‡å†…å®¹
                text = ""
                if 'text' in tweet:
                    text = tweet['text']
                elif 'full_text' in tweet:
                    text = tweet['full_text']
                elif 'body' in tweet:
                    text = tweet['body']

                if not text:
                    continue

                # æå–æç¤ºè¯
                prompts = extract_prompts_from_tweet(text)

                author_info = tweet.get('user', tweet.get('author', {}))
                author_name = author_info.get('name', author_info.get('username', 'Unknown'))
                author_handle = author_info.get('screen_name', author_info.get('username', ''))

                # è·å– URL
                tweet_id = tweet.get('id', tweet.get('id_str', ''))
                tweet_url = f"https://twitter.com/{author_handle}/status/{tweet_id}" if tweet_id else ""

                processed.append({
                    "timestamp": datetime.now().isoformat(),
                    "source": "twitter",
                    "search_query": query,
                    "tweet_id": tweet_id,
                    "tweet_url": tweet_url,
                    "author_name": author_name,
                    "author_handle": author_handle,
                    "text": text[:500],  # é™åˆ¶é•¿åº¦
                    "prompts_found": len(prompts),
                    "prompts": prompts,
                    "likes": tweet.get('favorite_count', 0),
                    "retweets": tweet.get('retweet_count', 0),
                    "replies": tweet.get('reply_count', 0)
                })

        return processed

    except Exception as e:
        print(f"Error processing data: {e}", file=sys.stderr)
        return []

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: process-tweets.py <query> <raw_data_file>")
        sys.exit(1)

    query = sys.argv[1]
    data_file = sys.argv[2]

    with open(data_file, 'r') as f:
        raw_data = f.read()

    processed = process_tweet_data(raw_data, query)

    for item in processed:
        print(json.dumps(item, ensure_ascii=False))
PYTHON_SCRIPT

chmod +x "$TMP_DIR/process-tweets.py"

# å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæœç´¢
log ""
log "å¼€å§‹æœç´¢ Twitter..."
log ""

QUERY_INDEX=0
for query in "${QUERIES[@]}"; do
    QUERY_INDEX=$((QUERY_INDEX + 1))
    log "[$QUERY_INDEX/${#QUERIES[@]}] æœç´¢: $query"

    # ä½¿ç”¨ bird CLI æœç´¢
    SEARCH_FILE="$TMP_DIR/search-${QUERY_INDEX}.json"

    if bird search -c 10 -f json "$query" > "$SEARCH_FILE" 2>&1; then
        log_info "  âœ… æœç´¢æˆåŠŸ"

        # å¤„ç†æ•°æ®
        PROMPT_COUNT=$(python3 "$TMP_DIR/process-tweets.py" "$query" "$SEARCH_FILE" | tee -a "$TMP_DIR/processed.jsonl" | wc -l)

        TOTAL_TWEETS=$((TOTAL_TWEETS + PROMPT_COUNT))

        if [ "$PROMPT_COUNT" -gt 0 ]; then
            log_info "  ğŸ“ å¤„ç†äº† $PROMPT_COUNT æ¡æ¨æ–‡"
        fi
    else
        log_warn "  âš ï¸  æœç´¢å¤±è´¥æˆ–æ— ç»“æœ"
    fi

    sleep 1
done

log ""
log "=========================================="
log "åˆå¹¶æ•°æ®..."
log "=========================================="

# è¯»å–ç°æœ‰æ•°æ®
if [ -f "$OUTPUT_FILE" ]; then
    cp "$OUTPUT_FILE" "$TMP_DIR/existing.jsonl"
else
    touch "$TMP_DIR/existing.jsonl"
fi

# åˆå¹¶æ‰€æœ‰å¤„ç†çš„æ•°æ®
cat "$TMP_DIR/processed.jsonl" "$TMP_DIR/existing.jsonl" | sort -u > "$OUTPUT_FILE"

# ç»Ÿè®¡æœ€ç»ˆç»“æœ
FINAL_COUNT=$(wc -l < "$OUTPUT_FILE")
NEW_COUNT=$(wc -l < "$TMP_DIR/processed.jsonl")

# è®¡ç®—æå–çš„æç¤ºè¯æ€»æ•°
TOTAL_PROMPTS=$(python3 -c "
import json
count = 0
with open('$OUTPUT_FILE', 'r') as f:
    for line in f:
        try:
            data = json.loads(line)
            count += data.get('prompts_found', 0)
        except:
            pass
print(count)
" 2>/dev/null || echo "0")

log ""
log "=========================================="
log "âœ… æ”¶é›†å®Œæˆï¼"
log "=========================================="
log ""
log "ğŸ“Š ç»Ÿè®¡:"
log "  â€¢ å¤„ç†çš„æ¨æ–‡: $TOTAL_TWEETS æ¡"
log "  â€¢ æ–°å¢æ•°æ®: $NEW_COUNT æ¡"
log "  â€¢ æ€»æ•°æ®é‡: $FINAL_COUNT æ¡"
log "  â€¢ æå–çš„æç¤ºè¯: $TOTAL_PROMPTS ä¸ª"
log ""
log "ğŸ“ æ–‡ä»¶: $OUTPUT_FILE"

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
# rm -rf "$TMP_DIR"

exit 0
