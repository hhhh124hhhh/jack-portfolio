#!/usr/bin/env python3
"""
ä» GitHub ä»“åº“æ”¶é›†æç¤ºè¯

æ”¯æŒä»“åº“:
- f/awesome-chatgpt-prompts
- dair-ai/Prompt-Engineering-Guide
- microsoft/prompt-engine
- anthropics/prompt-engineering-interactive-tutorial
"""

import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import logging
import hashlib

try:
    import yaml
except ImportError:
    print("âš ï¸  è¯·å®‰è£… PyYAML: pip install pyyaml")
    sys.exit(1)

try:
    import requests
except ImportError:
    print("âš ï¸  è¯·å®‰è£… requests: pip install requests")
    sys.exit(1)

# æ—¥å¿—é…ç½®
def setup_logging(log_dir: str = "/root/clawd/logs") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "collect-github-prompts.log")

    logger = logging.getLogger("collect_github_prompts")
    logger.setLevel(logging.INFO)

    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)

    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

logger = setup_logging()


class Config:
    """é…ç½®ç®¡ç†"""

    def __init__(self, config_path: str = "/root/clawd/config/prompts-config.yaml"):
        self.config_path = config_path
        self.config = self._load_config()

    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_path):
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._default_config()

        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _default_config(self) -> Dict:
        """é»˜è®¤é…ç½®"""
        return {
            'github': {
                'api_endpoint': 'https://api.github.com',
                'cache_dir': '/root/clawd/cache/github',
                'cache_ttl_hours': 72,
                'repositories': [
                    {
                        'owner': 'f',
                        'repo': 'awesome-chatgpt-prompts',
                        'branch': 'main',
                        'files': ['README.md']
                    }
                ]
            },
            'output': {
                'data_dir': '/root/clawd/data/prompts',
                'format': 'jsonl'
            }
        }

    @property
    def github_api_endpoint(self) -> str:
        return self.config['github']['api_endpoint']

    @property
    def repositories(self) -> List[Dict]:
        return self.config['github'].get('repositories', [])

    @property
    def cache_dir(self) -> str:
        return self.config['github']['cache_dir']

    @property
    def cache_ttl_hours(self) -> int:
        return self.config['github']['cache_ttl_hours']

    @property
    def output_dir(self) -> str:
        return self.config['output']['data_dir']


class CacheManager:
    """GitHub å†…å®¹ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, cache_dir: str, ttl_hours: int):
        self.cache_dir = Path(cache_dir)
        self.ttl_hours = ttl_hours
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_cache_key(self, url: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(url.encode()).hexdigest()

    def _get_cache_path(self, url: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{self._get_cache_key(url)}.json"

    def get(self, url: str) -> Optional[Dict]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        cache_path = self._get_cache_path(url)

        if not cache_path.exists():
            return None

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        cache_age = datetime.now() - datetime.fromtimestamp(cache_path.stat().st_mtime)
        if cache_age > timedelta(hours=self.ttl_hours):
            logger.info(f"ç¼“å­˜è¿‡æœŸ: {url}")
            cache_path.unlink()
            return None

        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None

    def set(self, url: str, data: Dict):
        """å†™å…¥ç¼“å­˜"""
        cache_path = self._get_cache_path(url)

        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False)
            logger.info(f"å†™å…¥ç¼“å­˜: {url}")
        except Exception as e:
            logger.error(f"å†™å…¥ç¼“å­˜å¤±è´¥: {e}")


from datetime import timedelta


class GitHubClient:
    """GitHub API å®¢æˆ·ç«¯"""

    def __init__(self, config: Config):
        self.config = config
        self.cache = CacheManager(config.cache_dir, config.cache_ttl_hours)
        self.session = requests.Session()
        self.session.headers.update({
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'clawd-prompt-collector'
        })

        # æ·»åŠ  GitHub Tokenï¼ˆå¦‚æœæœ‰ï¼‰
        token = os.getenv('GITHUB_TOKEN')
        if token:
            self.session.headers.update({
                'Authorization': f'token {token}'
            })

    def get_file_content(self, owner: str, repo: str, path: str, ref: str = 'main') -> Optional[str]:
        """è·å–æ–‡ä»¶å†…å®¹"""
        url = f"{self.config.github_api_endpoint}/repos/{owner}/{repo}/contents/{path}"

        params = {'ref': ref} if ref else {}

        # æ£€æŸ¥ç¼“å­˜
        cached = self.cache.get(url)
        if cached:
            content = cached.get('content')
            if content:
                import base64
                return base64.b64decode(content).decode('utf-8')

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if data.get('type') != 'file':
                logger.warning(f"ä¸æ˜¯æ–‡ä»¶: {path}")
                return None

            # å†™å…¥ç¼“å­˜
            self.cache.set(url, data)

            # è§£ç å†…å®¹
            import base64
            content = base64.b64decode(data['content']).decode('utf-8')

            return content

        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤±è´¥ {owner}/{repo}/{path}: {e}")
            return None

    def get_directory_contents(self, owner: str, repo: str, path: str, ref: str = 'main') -> List[Dict]:
        """è·å–ç›®å½•å†…å®¹"""
        url = f"{self.config.github_api_endpoint}/repos/{owner}/{repo}/contents/{path}"

        params = {'ref': ref} if ref else {}

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if isinstance(data, dict) and data.get('type') == 'file':
                return [data]

            if isinstance(data, list):
                return data

            return []

        except Exception as e:
            logger.error(f"è·å–ç›®å½•å¤±è´¥ {owner}/{repo}/{path}: {e}")
            return []


class PromptExtractor:
    """æç¤ºè¯æå–å™¨"""

    def extract_from_readme(self, content: str, repo_info: Dict) -> List[Dict]:
        """ä» README.md ä¸­æå–æç¤ºè¯"""
        prompts = []

        # å°è¯•ä¸åŒçš„æå–æ¨¡å¼

        # 1. ä»£ç å—ä¸­çš„æç¤ºè¯
        code_blocks = re.findall(r'```(?:markdown|text)?\n(.*?)```', content, re.DOTALL)
        for block in code_blocks:
            if self._is_valid_prompt(block):
                prompts.append(self._create_prompt_data(block, repo_info, 'code_block'))

        # 2. Markdown è¡¨æ ¼ä¸­çš„æç¤ºè¯ï¼ˆå¸¸è§äº awesome-chatgpt-promptsï¼‰
        table_rows = re.findall(r'\|\s*([^|]+)\s*\|\s*([^|]+)\s*\|', content)
        for role, prompt_text in table_rows:
            role = role.strip()
            prompt_text = prompt_text.strip()

            if self._is_valid_prompt(prompt_text):
                # åˆå¹¶è§’è‰²å’Œæç¤ºè¯
                full_prompt = f"Act as {role}.\n\n{prompt_text}"
                prompts.append(self._create_prompt_data(full_prompt, repo_info, 'table', extra={'role': role}))

        # 3. åˆ—è¡¨é¡¹ä¸­çš„æç¤ºè¯
        list_items = re.findall(r'^[-*]\s+(.+)$', content, re.MULTILINE)
        for item in list_items:
            if self._is_valid_prompt(item):
                prompts.append(self._create_prompt_data(item, repo_info, 'list'))

        # 4. å¼•å·ä¸­çš„å†…å®¹
        quotes = re.findall(r'"([^"]{50,})"', content)
        for quote in quotes:
            if self._is_valid_prompt(quote):
                prompts.append(self._create_prompt_data(quote, repo_info, 'quote'))

        # å»é‡
        unique_prompts = []
        seen = set()

        for prompt in prompts:
            key = prompt['prompt'][:100]  # ä½¿ç”¨å‰100å­—ç¬¦ä½œä¸ºé”®
            if key not in seen:
                seen.add(key)
                unique_prompts.append(prompt)

        logger.info(f"ä» README.md æå– {len(unique_prompts)} ä¸ªæç¤ºè¯")
        return unique_prompts

    def extract_from_docs(self, content: str, repo_info: Dict, file_path: str) -> List[Dict]:
        """ä»æ–‡æ¡£æ–‡ä»¶ä¸­æå–æç¤ºè¯"""
        prompts = []

        # æŸ¥æ‰¾ç¤ºä¾‹æç¤ºè¯éƒ¨åˆ†
        example_patterns = [
            r'(?:Example|ç¤ºä¾‹)[:ï¼š]\s*\n(.*?)(?:\n\n|$)',
            r'(?:Prompt|æç¤ºè¯)[:ï¼š]\s*\n(.*?)(?:\n\n|$)',
            r'```(?:markdown)?\n(.*?)```'
        ]

        for pattern in example_patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches:
                if self._is_valid_prompt(match):
                    prompts.append(self._create_prompt_data(match, repo_info, 'doc_example', extra={'source_file': file_path}))

        return prompts

    def _is_valid_prompt(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æç¤ºè¯"""
        text = text.strip()

        # é•¿åº¦æ£€æŸ¥
        if len(text) < 30 or len(text) > 2000:
            return False

        # æ’é™¤å¸¸è§çš„éæç¤ºè¯å†…å®¹
        exclude_patterns = [
            r'^[A-Z\s]+$',  # å…¨å¤§å†™æ ‡é¢˜
            r'^\d+\.\s*$',  # çº¯æ•°å­—
            r'^[_\-\*]+$',  # çº¯ç¬¦å·
            r'^https?://',  # URL
            r'^\[.*\]$',  # Markdown é“¾æ¥
        ]

        for pattern in exclude_patterns:
            if re.match(pattern, text):
                return False

        # åŒ…å«æç¤ºè¯ç‰¹å¾
        prompt_indicators = [
            r'\b(please|you|act|as|role|task|create|write|generate)\b',
            r':',  # å†’å·
            r'\?',  # é—®å·
        ]

        score = sum(1 for pattern in prompt_indicators if re.search(pattern, text, re.IGNORECASE))
        return score >= 1

    def _create_prompt_data(self, prompt_text: str, repo_info: Dict, source_type: str, extra: Optional[Dict] = None) -> Dict:
        """åˆ›å»ºæç¤ºè¯æ•°æ®ç»“æ„"""
        data = {
            "prompt": prompt_text.strip(),
            "source": "GitHub",
            "repository": f"{repo_info['owner']}/{repo_info['repo']}",
            "source_type": source_type,
            "source_file": repo_info.get('file', 'README.md'),
            "branch": repo_info.get('branch', 'main'),
            "collected_at": datetime.now().isoformat(),
            "quality_score": 60  # é»˜è®¤åˆ†æ•°ï¼Œå¾… LLM è¯„ä¼°
        }

        if extra:
            data.update(extra)

        return data


class GitHubPromptCollector:
    """GitHub æç¤ºè¯æ”¶é›†å™¨"""

    def __init__(self, config: Config):
        self.config = config
        self.client = GitHubClient(config)
        self.extractor = PromptExtractor()

    def collect_from_repository(self, repo_config: Dict) -> List[Dict]:
        """ä»å•ä¸ªä»“åº“æ”¶é›†æç¤ºè¯"""
        owner = repo_config['owner']
        repo = repo_config['repo']
        branch = repo_config.get('branch', 'main')
        files = repo_config.get('files', ['README.md'])

        logger.info(f"æ”¶é›†ä»“åº“: {owner}/{repo} (branch: {branch})")

        repo_info = {
            'owner': owner,
            'repo': repo,
            'branch': branch
        }

        all_prompts = []

        for file_path in files:
            logger.info(f"  å¤„ç†æ–‡ä»¶: {file_path}")

            repo_info['file'] = file_path

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•
            if file_path.endswith('/'):
                # è·å–ç›®å½•å†…å®¹
                contents = self.client.get_directory_contents(owner, repo, file_path.rstrip('/'), branch)

                for item in contents:
                    if item.get('type') == 'file' and item.get('name', '').endswith('.md'):
                        content = self.client.get_file_content(
                            owner, repo,
                            f"{file_path.rstrip('/')}/{item['name']}",
                            branch
                        )

                        if content:
                            prompts = self.extractor.extract_from_docs(content, repo_info, item['name'])
                            all_prompts.extend(prompts)
            else:
                # è·å–å•ä¸ªæ–‡ä»¶
                content = self.client.get_file_content(owner, repo, file_path, branch)

                if content:
                    if file_path.lower() == 'readme.md':
                        prompts = self.extractor.extract_from_readme(content, repo_info)
                    else:
                        prompts = self.extractor.extract_from_docs(content, repo_info, file_path)

                    all_prompts.extend(prompts)

        logger.info(f"  ä» {owner}/{repo} æ”¶é›†åˆ° {len(all_prompts)} ä¸ªæç¤ºè¯")

        return all_prompts

    def collect_all(self) -> List[Dict]:
        """ä»æ‰€æœ‰é…ç½®çš„ä»“åº“æ”¶é›†"""
        all_prompts = []

        for i, repo_config in enumerate(self.config.repositories, 1):
            logger.info(f"[{i}/{len(self.config.repositories)}] å¼€å§‹æ”¶é›†ä»“åº“")

            try:
                prompts = self.collect_from_repository(repo_config)
                all_prompts.extend(prompts)
            except Exception as e:
                logger.error(f"æ”¶é›†ä»“åº“å¤±è´¥: {e}")

            # é¿å…è§¦å‘ GitHub API é™æµ
            if i < len(self.config.repositories):
                logger.info("ç­‰å¾… 2 ç§’åç»§ç»­...")
                import time
                time.sleep(2)

        return all_prompts


def save_jsonl(data: List[Dict], filepath: str):
    """ä¿å­˜ JSONL æ ¼å¼æ•°æ®"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    with open(filepath, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    logger.info(f"ä¿å­˜ {len(data)} æ¡æ•°æ®åˆ°: {filepath}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("ğŸ“¦ å¼€å§‹ä» GitHub æ”¶é›†æç¤ºè¯")
    logger.info("=" * 80)

    # åŠ è½½é…ç½®
    config = Config()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = config.output_dir
    os.makedirs(output_dir, exist_ok=True)

    # æ”¶é›†å™¨
    collector = GitHubPromptCollector(config)

    # æ”¶é›†æ‰€æœ‰ä»“åº“
    logger.info(f"é…ç½®çš„ä»“åº“æ•°é‡: {len(config.repositories)}")

    all_prompts = collector.collect_all()

    # ä¿å­˜ç»“æœ
    output_file = os.path.join(output_dir, "github-prompts.jsonl")
    save_jsonl(all_prompts, output_file)

    # ç”ŸæˆæŠ¥å‘Š
    repo_counts = {}
    for prompt in all_prompts:
        repo = prompt.get('repository', 'unknown')
        repo_counts[repo] = repo_counts.get(repo, 0) + 1

    report = {
        "timestamp": datetime.now().isoformat(),
        "repositories_processed": len(config.repositories),
        "total_prompts_collected": len(all_prompts),
        "prompts_by_repository": repo_counts,
        "output_file": output_file
    }

    report_file = os.path.join(
        config.output_dir,
        f"github-collection-report-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
    )

    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    logger.info("=" * 80)
    logger.info("âœ… æ”¶é›†å®Œæˆï¼")
    logger.info("=" * 80)
    logger.info(f"ğŸ“Š ç»Ÿè®¡:")
    logger.info(f"  å¤„ç†ä»“åº“: {report['repositories_processed']} ä¸ª")
    logger.info(f"  æ”¶é›†æç¤ºè¯: {report['total_prompts_collected']} ä¸ª")
    logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"  æç¤ºè¯: {output_file}")
    logger.info(f"  æŠ¥å‘Š: {report_file}")
    logger.info(f"ğŸ“¦ å„ä»“åº“è´¡çŒ®:")
    for repo, count in repo_counts.items():
        logger.info(f"  {repo}: {count} ä¸ª")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\nâ¸ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
