#!/usr/bin/env python3
"""
Reddit AI æç¤ºè¯æ”¶é›†è„šæœ¬
ä» r/prompts, r/ChatGPT, r/artificial ç­‰å­ç‰ˆå—æ”¶é›†é«˜è´¨é‡ prompt
"""

import json
import requests
from datetime import datetime
from collections import Counter

# é…ç½®
SUBREDDITS = [
    "prompts",
    "ChatGPT",
    "artificial",
    "machinelearning",
    "LanguageTechnology"
]

MAX_POSTS_PER_SUBREDDIT = 25  # æ¯ä¸ª subreddit æœ€å¤š 25 æ¡
OUTPUT_FILE = "/root/clawd/data/prompts/reddit-prompts.jsonl"
MIN_UPVOTES = 5  # æœ€å°‘ 5 ä¸ªèµ

# Reddit API (ä¸éœ€è¦ API keyï¼Œä½¿ç”¨å…¬å…± APIï¼‰
REDDIT_API = "https://www.reddit.com"

def get_hot_posts(subreddit: str, limit: int = MAX_POSTS_PER_SUBREDDIT) -> list:
    """è·å–çƒ­é—¨å¸–å­"""
    url = f"{REDDIT_API}/r/{subreddit}/hot.json?limit={limit}"
    headers = {
        "User-Agent": "Clawdbot-Prompt-Collector/1.0"
    }

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()

        posts = []
        for item in data.get("data", {}).get("children", []):
            post = item.get("data", {})
            posts.append({
                "id": post.get("id"),
                "title": post.get("title", ""),
                "selftext": post.get("selftext", ""),
                "url": post.get("url", ""),
                "permalink": f"{REDDIT_API}{post.get('permalink', '')}",
                "author": post.get("author", ""),
                "subreddit": subreddit,
                "upvotes": post.get("ups", 0),
                "num_comments": post.get("num_comments", 0),
                "created_utc": post.get("created_utc", 0),
                "link_flair_text": post.get("link_flair_text", ""),
                "is_self": post.get("is_self", False)
            })
        return posts
    except Exception as e:
        print(f"âš ï¸  è·å– {subreddit} å¤±è´¥: {e}")
        return []

def is_prompt_related(post: dict) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸º prompt ç›¸å…³å†…å®¹"""
    title = post.get("title", "").lower()
    text = post.get("selftext", "").lower()

    # Prompt ç›¸å…³å…³é”®è¯
    prompt_keywords = [
        "prompt", "template", "system message",
        "instruction", "guideline", "example",
        "prompt engineering", "llm prompt"
    ]

    # æ£€æŸ¥æ ‡é¢˜æˆ–å†…å®¹æ˜¯å¦åŒ…å«å…³é”®è¯
    for keyword in prompt_keywords:
        if keyword in title or keyword in text:
            return True

    return False

def extract_prompt_from_post(post: dict) -> str:
    """ä»å¸–å­ä¸­æå– prompt å†…å®¹"""
    text = post.get("selftext", "")
    if not text:
        return ""

    # å°è¯•æå–ä»£ç å—
    import re
    code_blocks = re.findall(r'```[\s\S]*?```', text)
    if code_blocks:
        return code_blocks[0]

    # å°è¯•æå–å¼•å·ä¸­çš„å†…å®¹
    if '""' in text or "'''" in text:
        if '""' in text:
            parts = text.split('""')
            if len(parts) > 1:
                return parts[1]
        else:
            parts = text.split("'''")
            if len(parts) > 1:
                return parts[1]

    # è¿”å›ä¸»è¦å†…å®¹ï¼ˆå‰ 1000 å­—ç¬¦ï¼‰
    return text[:1000]

def calculate_quality_score(post: dict) -> int:
    """è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°ï¼ˆ0-100ï¼‰"""
    score = 0

    # ç‚¹èµæ•°è¯„åˆ†ï¼ˆå¯¹æ•°åˆ»åº¦ï¼Œé¿å…æç«¯å€¼ï¼‰
    upvotes = post.get("upvotes", 0)
    if upvotes > 0:
        score += min(30, (upvotes ** 0.5) * 2)

    # è¯„è®ºæ•°è¯„åˆ†
    comments = post.get("num_comments", 0)
    score += min(20, comments * 0.5)

    # æ–‡æœ¬é•¿åº¦è¯„åˆ†
    text = post.get("selftext", "")
    if len(text) > 100:
        score += 10
    if len(text) > 500:
        score += 10

    # æ˜¯å¦åŒ…å«ä»£ç å—
    if '```' in text or '``' in text:
        score += 20

    # æ ‡é¢˜é•¿åº¦
    title = post.get("title", "")
    if 50 < len(title) < 200:
        score += 5

    # æ˜¯å¦æ˜¯ self postï¼ˆæ–‡æœ¬å¸–ï¼‰
    if post.get("is_self", False):
        score += 10

    # æ ‡ç­¾
    flair = (post.get("link_flair_text") or "").lower()
    if "prompt" in flair or "template" in flair:
        score += 10

    return min(100, score)

def main():
    print(f"\n{'='*60}")
    print(f"ğŸ” Reddit AI æç¤ºè¯æ”¶é›† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    all_posts = []

    # æ”¶é›†æ‰€æœ‰ subreddits çš„å¸–å­
    for subreddit in SUBREDDITS:
        print(f"ğŸ“‚ r/{subreddit}...", end='', flush=True)

        posts = get_hot_posts(subreddit)
        print(f" {len(posts)} æ¡")

        # è¿‡æ»¤å’Œè¯„åˆ†
        for post in posts:
            # è¿‡æ»¤ä½è´¨é‡å¸–å­
            if post.get("upvotes", 0) < MIN_UPVOTES:
                continue

            # æ£€æŸ¥æ˜¯å¦ä¸º prompt ç›¸å…³
            if not is_prompt_related(post):
                continue

            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = calculate_quality_score(post)

            # æå– prompt å†…å®¹
            prompt_content = extract_prompt_from_post(post)

            # æ ‡å‡†åŒ–æ•°æ®
            entry = {
                "source": "reddit",
                "source_id": f"reddit-{post['id']}",
                "title": post.get("title", ""),
                "content": prompt_content or post.get("selftext", "")[:1000],
                "full_text": post.get("selftext", ""),
                "url": post.get("permalink", ""),
                "author": post.get("author", ""),
                "metrics": {
                    "upvotes": post.get("upvotes", 0),
                    "comments": post.get("num_comments", 0),
                    "created_utc": post.get("created_utc", 0)
                },
                "subreddit": subreddit,
                "flair": post.get("link_flair_text", ""),
                "quality_score": quality_score,
                "collected_at": datetime.now().isoformat()
            }

            all_posts.append(entry)

    print(f"\nğŸ“Š æ€»å…±æ”¶é›†: {len(all_posts)} æ¡é«˜è´¨é‡ prompt")

    if not all_posts:
        print("âš ï¸  æ²¡æœ‰æ”¶é›†åˆ°æ•°æ®")
        return

    # æŒ‰è´¨é‡åˆ†æ•°æ’åº
    all_posts.sort(key=lambda x: x["quality_score"], reverse=True)

    # ç»Ÿè®¡ä¿¡æ¯
    avg_score = sum(p["quality_score"] for p in all_posts) / len(all_posts)
    subreddits_count = Counter(p["subreddit"] for p in all_posts)

    print(f"\nğŸ“ˆ è´¨é‡ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†æ•°: {avg_score:.1f}")
    print(f"  åˆ†æ•° >= 80: {sum(1 for p in all_posts if p['quality_score'] >= 80)} æ¡")
    print(f"  åˆ†æ•° >= 60: {sum(1 for p in all_posts if p['quality_score'] >= 60)} æ¡")

    print(f"\nğŸ“‚ æ¥æºåˆ†å¸ƒ:")
    for sub, count in subreddits_count.most_common():
        print(f"  r/{sub}: {count} æ¡")

    # ä¿å­˜æ•°æ®
    import os
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

    # è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶
    existing_entries = []
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    existing_entries.append(json.loads(line))

    # åˆå¹¶å¹¶å»é‡ï¼ˆåŸºäº source_idï¼‰
    existing_ids = {e["source_id"] for e in existing_entries}
    new_entries = [e for e in all_posts if e["source_id"] not in existing_ids]

    all_data = existing_entries + new_entries

    # å†™å›æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for entry in all_data:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

    print(f"\nğŸ’¾ æ•°æ®ä¿å­˜:")
    print(f"  æ–°å¢: {len(new_entries)} æ¡")
    print(f"  æ€»è®¡: {len(all_data)} æ¡")
    print(f"  æ–‡ä»¶: {OUTPUT_FILE}")

    # ç”Ÿæˆç®€è¦æŠ¥å‘Š
    print(f"\nğŸ† Top 10 Prompt:")
    for i, post in enumerate(all_posts[:10], 1):
        print(f"\n{i}. [{post['quality_score']}] {post['title'][:60]}...")
        print(f"   æ¥æº: r/{post['subreddit']} | ä½œè€…: @{post['author']}")
        print(f"   èµæ•°: {post['metrics']['upvotes']} | è¯„è®º: {post['metrics']['comments']}")
        print(f"   é“¾æ¥: {post['url']}")

    print(f"\n{'='*60}")
    print(f"âœ… Reddit æ”¶é›†å®Œæˆï¼")
    print(f"{'='*60}\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
