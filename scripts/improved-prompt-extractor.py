#!/usr/bin/env python3
"""
æ”¹è¿›çš„æç¤ºè¯æå–å™¨
æ”¯æŒä¸“é—¨è§£æ awesome-chatgpt-prompts æ ¼å¼ï¼Œå¹¶ä½¿ç”¨ LLM éªŒè¯æç¤ºè¯è´¨é‡
"""

import json
import logging
import os
import re
from datetime import datetime
from typing import Dict, List, Optional
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ImprovedPromptExtractor:
    """æ”¹è¿›çš„æç¤ºè¯æå–å™¨"""

    def __init__(self, use_llm_validation: bool = True):
        """
        åˆå§‹åŒ–æå–å™¨

        Args:
            use_llm_validation: æ˜¯å¦ä½¿ç”¨ LLM éªŒè¯æç¤ºè¯è´¨é‡
        """
        self.use_llm_validation = use_llm_validation
        self.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")

        # awesome-chatgpt-prompts çš„ GitHub URL
        self.prompts_repo = "https://raw.githubusercontent.com/f/prompts.chat/main/PROMPTS.md"

    def extract_from_awesome_chatgpt_prompts(self) -> List[Dict]:
        """
        ä» awesome-chatgpt-prompts ä»“åº“æå–æç¤ºè¯

        Returns:
            æç¤ºè¯åˆ—è¡¨
        """
        logger.info(f"Fetching prompts from {self.prompts_repo}")

        try:
            # ä¸‹è½½ PROMPTS.md
            response = requests.get(self.prompts_repo, timeout=30)
            response.raise_for_status()
            content = response.text

            # è§£ææç¤ºè¯
            prompts = self._parse_awesome_chatgpt_format(content)

            logger.info(f"Extracted {len(prompts)} prompts from awesome-chatgpt-prompts")
            return prompts

        except Exception as e:
            logger.error(f"Failed to fetch from awesome-chatgpt-prompts: {e}")
            return []

    def _parse_awesome_chatgpt_format(self, content: str) -> List[Dict]:
        """
        è§£æ awesome-chatgpt-prompts æ ¼å¼

        Args:
            content: PROMPTS.md æ–‡ä»¶å†…å®¹

        Returns:
            æç¤ºè¯åˆ—è¡¨
        """
        prompts = []

        # åŒ¹é… <details> å—
        details_pattern = r'<details>.*?</details>'
        details_blocks = re.findall(details_pattern, content, re.DOTALL)

        logger.info(f"Found {len(details_blocks)} detail blocks")

        for block in details_blocks:
            try:
                # æå–è§’è‰²åç§°ï¼ˆä» summaryï¼‰
                summary_match = re.search(r'<summary><strong>([^<]+)</strong></summary>', block)
                role_name = summary_match.group(1).strip() if summary_match else "Unknown"

                # æå–è´¡çŒ®è€…
                contributor_match = re.search(r'Contributed by \[@([^\]]+)\]', block)
                contributor = contributor_match.group(1) if contributor_match else "Unknown"

                # æå–å®é™…æç¤ºè¯ï¼ˆä» markdown ä»£ç å—ï¼‰
                prompt_match = re.search(r'```md\n(.*?)\n```', block, re.DOTALL)
                if not prompt_match:
                    prompt_match = re.search(r'```\n(.*?)\n```', block, re.DOTALL)

                prompt_text = prompt_match.group(1).strip() if prompt_match else None

                if prompt_text and len(prompt_text) >= 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                    prompt = {
                        "role": role_name,
                        "contributor": contributor,
                        "prompt": prompt_text,
                        "source": "awesome-chatgpt-prompts",
                        "extracted_at": datetime.now().isoformat(),
                        "length": len(prompt_text)
                    }
                    prompts.append(prompt)
                    logger.debug(f"Extracted prompt: {role_name} ({len(prompt_text)} chars)")

            except Exception as e:
                logger.debug(f"Failed to parse block: {e}")
                continue

        return prompts

    def validate_with_llm(self, prompts: List[Dict], limit: int = 50) -> List[Dict]:
        """
        ä½¿ç”¨ LLM éªŒè¯æç¤ºè¯è´¨é‡

        Args:
            prompts: æç¤ºè¯åˆ—è¡¨
            limit: æœ€å¤šéªŒè¯çš„æ•°é‡

        Returns:
            éªŒè¯åçš„æç¤ºè¯åˆ—è¡¨ï¼ˆæ·»åŠ è´¨é‡è¯„åˆ†ï¼‰
        """
        if not self.use_llm_validation or not self.anthropic_api_key:
            logger.warning("LLM validation disabled or API key not available")
            return prompts

        logger.info(f"Validating {min(len(prompts), limit)} prompts with LLM...")

        # è¿™é‡Œå¯ä»¥é›†æˆ Claude API è¿›è¡ŒéªŒè¯
        # æš‚æ—¶æ·»åŠ åŸºç¡€è´¨é‡æ£€æŸ¥
        for i, prompt in enumerate(prompts[:limit]):
            # åŸºç¡€è´¨é‡è¯„åˆ†
            score = self._calculate_base_quality_score(prompt)
            prompt["quality_score"] = score
            prompt["validated_at"] = datetime.now().isoformat()

        return prompts

    def _calculate_base_quality_score(self, prompt: Dict) -> float:
        """
        è®¡ç®—åŸºç¡€è´¨é‡è¯„åˆ†ï¼ˆ0-100ï¼‰

        Args:
            prompt: æç¤ºè¯å­—å…¸

        Returns:
            è´¨é‡åˆ†æ•°
        """
        prompt_text = prompt["prompt"]
        score = 50.0  # åŸºç¡€åˆ†

        # é•¿åº¦è¯„åˆ†ï¼ˆ500-1500 å­—ç¬¦ä¸ºæœ€ä½³ï¼‰
        length = prompt_text["length"] if isinstance(prompt_text, dict) else len(prompt_text)
        if 500 <= length <= 1500:
            score += 20
        elif 300 <= length <= 2000:
            score += 10

        # åŒ…å« "act as" é€šå¸¸è¡¨ç¤ºæ˜¯è§’è‰²æ‰®æ¼”æç¤ºè¯
        if "act as" in prompt_text.lower():
            score += 15

        # åŒ…å«å…·ä½“æŒ‡ä»¤ï¼ˆå¦‚ "I want you to", "You will"ï¼‰
        if any(phrase in prompt_text.lower() for phrase in ["i want you to", "you will", "your task"]):
            score += 15

        # é¿å…è¿‡äºç®€å•çš„æç¤ºè¯
        if len(prompt_text.split()) < 20:
            score -= 30

        # é™åˆ¶åœ¨ 0-100 èŒƒå›´å†…
        return max(0.0, min(100.0, score))

    def extract_from_text(self, text: str) -> List[str]:
        """
        ä»é€šç”¨æ–‡æœ¬ä¸­æå–å¯èƒ½çš„æç¤ºè¯ï¼ˆæ”¹è¿›ç‰ˆï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            æå–çš„æç¤ºè¯åˆ—è¡¨
        """
        candidates = []

        # æ¨¡å¼1: "I want you to act as" å¼€å¤´çš„æ®µè½
        pattern1 = r'I want you to act as [^.!?]+[.!?](.*?)(?=\n\n|$)'
        matches = re.findall(pattern1, text, re.DOTALL | re.IGNORECASE)
        candidates.extend(matches)

        # æ¨¡å¼2: "Act as" å¼€å¤´çš„æŒ‡ä»¤
        pattern2 = r'Act as [^.!?]+[.!?](.*?)(?=\n\n|$)'
        matches = re.findall(pattern2, text, re.DOTALL | re.IGNORECASE)
        candidates.extend(matches)

        # æ¨¡å¼3: åŒ…å« "you will" çš„æŒ‡ä»¤æ®µè½
        pattern3 = r'You will [^.!?]+[.!?](.*?)(?=\n\n|$)'
        matches = re.findall(pattern3, text, re.DOTALL | re.IGNORECASE)
        candidates.extend(matches)

        # è¿‡æ»¤å’Œå»é‡
        unique_prompts = []
        seen = set()

        for candidate in candidates:
            candidate = candidate.strip()

            # é•¿åº¦æ£€æŸ¥
            if len(candidate) < 50 or len(candidate) > 2000:
                continue

            # å»é‡
            normalized = candidate.lower()[:100]
            if normalized in seen:
                continue
            seen.add(normalized)

            unique_prompts.append(candidate)

        logger.info(f"Extracted {len(unique_prompts)} candidate prompts from text")
        return unique_prompts

    def save_prompts(self, prompts: List[Dict], output_file: str):
        """
        ä¿å­˜æç¤ºè¯åˆ°æ–‡ä»¶

        Args:
            prompts: æç¤ºè¯åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else ".", exist_ok=True)

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(prompts, f, ensure_ascii=False, indent=2)

            logger.info(f"Saved {len(prompts)} prompts to {output_file}")

            # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            stats = self._generate_statistics(prompts)
            stats_file = output_file.replace(".json", "_stats.json")
            with open(stats_file, "w", encoding="utf-8") as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            logger.info(f"Saved statistics to {stats_file}")

        except Exception as e:
            logger.error(f"Failed to save prompts: {e}")

    def _generate_statistics(self, prompts: List[Dict]) -> Dict:
        """
        ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯

        Args:
            prompts: æç¤ºè¯åˆ—è¡¨

        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        stats = {
            "total_count": len(prompts),
            "extracted_at": datetime.now().isoformat(),
            "source": "awesome-chatgpt-prompts"
        }

        # é•¿åº¦åˆ†å¸ƒ
        lengths = [p.get("length", len(p.get("prompt", ""))) for p in prompts]
        if lengths:
            stats["length_stats"] = {
                "min": min(lengths),
                "max": max(lengths),
                "avg": sum(lengths) / len(lengths)
            }

        # è´¨é‡åˆ†æ•°åˆ†å¸ƒ
        quality_scores = [p.get("quality_score", 0) for p in prompts if "quality_score" in p]
        if quality_scores:
            stats["quality_stats"] = {
                "min": min(quality_scores),
                "max": max(quality_scores),
                "avg": sum(quality_scores) / len(quality_scores)
            }

        # è´¡çŒ®è€…ç»Ÿè®¡
        contributors = {}
        for p in prompts:
            contributor = p.get("contributor", "Unknown")
            contributors[contributor] = contributors.get(contributor, 0) + 1

        stats["top_contributors"] = sorted(
            contributors.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]

        return stats


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ”¹è¿›çš„æç¤ºè¯æå–å™¨")
    parser.add_argument(
        "--output", "-o",
        default="/root/clawd/data/prompts/awesome-chatgpt-prompts.json",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--no-llm-validation",
        action="store_true",
        help="ç¦ç”¨ LLM éªŒè¯"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶æå–æ•°é‡"
    )

    args = parser.parse_args()

    # åˆ›å»ºæå–å™¨
    extractor = ImprovedPromptExtractor(use_llm_validation=not args.no_llm_validation)

    # ä» awesome-chatgpt-prompts æå–
    prompts = extractor.extract_from_awesome_chatgpt_prompts()

    if args.limit:
        prompts = prompts[:args.limit]

    # ä¿å­˜ç»“æœ
    extractor.save_prompts(prompts, args.output)

    # æ‰“å°æ‘˜è¦
    print(f"\nâœ… æå–å®Œæˆï¼")
    print(f"   æç¤ºè¯æ•°é‡: {len(prompts)}")
    print(f"   è¾“å‡ºæ–‡ä»¶: {args.output}")

    # æ˜¾ç¤ºå‰3ä¸ªæç¤ºè¯é¢„è§ˆ
    print(f"\nğŸ“‹ å‰3ä¸ªæç¤ºè¯é¢„è§ˆ:")
    for i, prompt in enumerate(prompts[:3], 1):
        role = prompt.get("role", "Unknown")
        preview = prompt.get("prompt", "")[:100] + "..."
        quality = prompt.get("quality_score", "N/A")
        print(f"\n{i}. {role} (è´¨é‡: {quality})")
        print(f"   {preview}")


if __name__ == "__main__":
    main()
